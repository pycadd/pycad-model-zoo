
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-11-01 21:25:47.573943: do_dummy_2d_data_aug: True 
2024-11-01 21:25:47.574452: Creating new 5-fold cross-validation split... 
2024-11-01 21:25:47.575326: Desired fold for training: 0 
2024-11-01 21:25:47.575348: This split has 240 training and 60 validation cases. 
2024-11-01 21:25:48.717320: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [20, 256, 224], 'median_image_size_in_voxels': [18.0, 236.0, 213.0], 'spacing': [5.0, 1.5234400033950806, 1.5234400033950806], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset100_HEART', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [10.0, 1.5234400033950806, 1.5234400033950806], 'original_median_shape_after_transp': [10, 256, 216], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1488.0, 'mean': 113.99404907226562, 'median': 96.0, 'min': 0.0, 'percentile_00_5': 25.0, 'percentile_99_5': 558.0, 'std': 80.54434967041016}}} 
 
2024-11-01 21:25:49.169098: unpacking dataset... 
2024-11-01 21:25:51.447812: unpacking done... 
2024-11-01 21:25:51.448186: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-11-01 21:25:51.452250:  
2024-11-01 21:25:51.452277: Epoch 0 
2024-11-01 21:25:51.452323: Current learning rate: 0.01 
2024-11-01 21:27:25.646272: train_loss -0.0118 
2024-11-01 21:27:25.646348: val_loss -0.391 
2024-11-01 21:27:25.646380: Pseudo dice [0.4464, 0.2661, 0.732] 
2024-11-01 21:27:25.646412: Epoch time: 94.19 s 
2024-11-01 21:27:25.646432: Yayy! New best EMA pseudo Dice: 0.4815 
2024-11-01 21:27:26.171610:  
2024-11-01 21:27:26.171654: Epoch 1 
2024-11-01 21:27:26.171695: Current learning rate: 0.00996 
2024-11-01 21:28:23.142145: train_loss -0.5748 
2024-11-01 21:28:23.142224: val_loss -0.6628 
2024-11-01 21:28:23.142257: Pseudo dice [0.7447, 0.6945, 0.8582] 
2024-11-01 21:28:23.142285: Epoch time: 56.97 s 
2024-11-01 21:28:23.142305: Yayy! New best EMA pseudo Dice: 0.5099 
2024-11-01 21:28:23.734544:  
2024-11-01 21:28:23.734591: Epoch 2 
2024-11-01 21:28:23.734627: Current learning rate: 0.00993 
2024-11-01 21:29:20.746108: train_loss -0.7185 
2024-11-01 21:29:20.746201: val_loss -0.7433 
2024-11-01 21:29:20.746234: Pseudo dice [0.8123, 0.7625, 0.9] 
2024-11-01 21:29:20.746261: Epoch time: 57.01 s 
2024-11-01 21:29:20.746278: Yayy! New best EMA pseudo Dice: 0.5414 
2024-11-01 21:29:21.365757:  
2024-11-01 21:29:21.365801: Epoch 3 
2024-11-01 21:29:21.365834: Current learning rate: 0.00989 
2024-11-01 21:30:18.383721: train_loss -0.771 
2024-11-01 21:30:18.383795: val_loss -0.795 
2024-11-01 21:30:18.383823: Pseudo dice [0.8497, 0.8053, 0.9252] 
2024-11-01 21:30:18.383845: Epoch time: 57.02 s 
2024-11-01 21:30:18.383860: Yayy! New best EMA pseudo Dice: 0.5733 
2024-11-01 21:30:18.983836:  
2024-11-01 21:30:18.983921: Epoch 4 
2024-11-01 21:30:18.983961: Current learning rate: 0.00986 
2024-11-01 21:31:15.954280: train_loss -0.8028 
2024-11-01 21:31:15.954355: val_loss -0.8098 
2024-11-01 21:31:15.954388: Pseudo dice [0.8674, 0.81, 0.9329] 
2024-11-01 21:31:15.954421: Epoch time: 56.97 s 
2024-11-01 21:31:15.954442: Yayy! New best EMA pseudo Dice: 0.603 
2024-11-01 21:31:16.575380:  
2024-11-01 21:31:16.575446: Epoch 5 
2024-11-01 21:31:16.575483: Current learning rate: 0.00982 
2024-11-01 21:32:13.593544: train_loss -0.8177 
2024-11-01 21:32:13.593649: val_loss -0.8159 
2024-11-01 21:32:13.593681: Pseudo dice [0.8679, 0.833, 0.9396] 
2024-11-01 21:32:13.593704: Epoch time: 57.02 s 
2024-11-01 21:32:13.593719: Yayy! New best EMA pseudo Dice: 0.6307 
2024-11-01 21:32:14.191513:  
2024-11-01 21:32:14.191581: Epoch 6 
2024-11-01 21:32:14.191629: Current learning rate: 0.00978 
2024-11-01 21:33:11.208980: train_loss -0.8362 
2024-11-01 21:33:11.209049: val_loss -0.8353 
2024-11-01 21:33:11.209076: Pseudo dice [0.8839, 0.8493, 0.9399] 
2024-11-01 21:33:11.209100: Epoch time: 57.02 s 
2024-11-01 21:33:11.209117: Yayy! New best EMA pseudo Dice: 0.6567 
2024-11-01 21:33:11.796659:  
2024-11-01 21:33:11.796715: Epoch 7 
2024-11-01 21:33:11.796756: Current learning rate: 0.00975 
2024-11-01 21:34:08.755507: train_loss -0.8422 
2024-11-01 21:34:08.755580: val_loss -0.8341 
2024-11-01 21:34:08.755613: Pseudo dice [0.8802, 0.8492, 0.9403] 
2024-11-01 21:34:08.755643: Epoch time: 56.96 s 
2024-11-01 21:34:08.755669: Yayy! New best EMA pseudo Dice: 0.6801 
2024-11-01 21:34:09.355063:  
2024-11-01 21:34:09.355114: Epoch 8 
2024-11-01 21:34:09.355153: Current learning rate: 0.00971 
2024-11-01 21:35:06.380656: train_loss -0.8509 
2024-11-01 21:35:06.380727: val_loss -0.8448 
2024-11-01 21:35:06.380758: Pseudo dice [0.8849, 0.8604, 0.9445] 
2024-11-01 21:35:06.380785: Epoch time: 57.03 s 
2024-11-01 21:35:06.380802: Yayy! New best EMA pseudo Dice: 0.7017 
2024-11-01 21:35:06.987010:  
2024-11-01 21:35:06.987054: Epoch 9 
2024-11-01 21:35:06.987089: Current learning rate: 0.00968 
2024-11-01 21:36:03.981383: train_loss -0.8583 
2024-11-01 21:36:03.981456: val_loss -0.8533 
2024-11-01 21:36:03.981487: Pseudo dice [0.903, 0.8596, 0.9478] 
2024-11-01 21:36:03.981515: Epoch time: 56.99 s 
2024-11-01 21:36:03.981530: Yayy! New best EMA pseudo Dice: 0.7219 
2024-11-01 21:36:04.559471:  
2024-11-01 21:36:04.559528: Epoch 10 
2024-11-01 21:36:04.559564: Current learning rate: 0.00964 
2024-11-01 21:37:01.536174: train_loss -0.8621 
2024-11-01 21:37:01.536248: val_loss -0.8458 
2024-11-01 21:37:01.536286: Pseudo dice [0.8957, 0.8647, 0.9442] 
2024-11-01 21:37:01.536315: Epoch time: 56.98 s 
2024-11-01 21:37:01.536335: Yayy! New best EMA pseudo Dice: 0.7399 
2024-11-01 21:37:02.122789:  
2024-11-01 21:37:02.122835: Epoch 11 
2024-11-01 21:37:02.122870: Current learning rate: 0.0096 
2024-11-01 21:37:59.106986: train_loss -0.8627 
2024-11-01 21:37:59.107059: val_loss -0.8568 
2024-11-01 21:37:59.107084: Pseudo dice [0.8918, 0.8741, 0.9482] 
2024-11-01 21:37:59.107106: Epoch time: 56.98 s 
2024-11-01 21:37:59.107121: Yayy! New best EMA pseudo Dice: 0.7563 
2024-11-01 21:37:59.929299:  
2024-11-01 21:37:59.929361: Epoch 12 
2024-11-01 21:37:59.929404: Current learning rate: 0.00957 
2024-11-01 21:38:56.966970: train_loss -0.8701 
2024-11-01 21:38:56.967047: val_loss -0.8624 
2024-11-01 21:38:56.967080: Pseudo dice [0.898, 0.8696, 0.9508] 
2024-11-01 21:38:56.967108: Epoch time: 57.04 s 
2024-11-01 21:38:56.967127: Yayy! New best EMA pseudo Dice: 0.7713 
2024-11-01 21:38:57.554830:  
2024-11-01 21:38:57.554878: Epoch 13 
2024-11-01 21:38:57.554914: Current learning rate: 0.00953 
2024-11-01 21:39:54.530557: train_loss -0.8763 
2024-11-01 21:39:54.530632: val_loss -0.8626 
2024-11-01 21:39:54.530664: Pseudo dice [0.9056, 0.8736, 0.9489] 
2024-11-01 21:39:54.530691: Epoch time: 56.98 s 
2024-11-01 21:39:54.530711: Yayy! New best EMA pseudo Dice: 0.7851 
2024-11-01 21:39:55.120228:  
2024-11-01 21:39:55.120286: Epoch 14 
2024-11-01 21:39:55.120323: Current learning rate: 0.00949 
2024-11-01 21:40:52.398617: train_loss -0.8778 
2024-11-01 21:40:52.398686: val_loss -0.8533 
2024-11-01 21:40:52.398712: Pseudo dice [0.8858, 0.8706, 0.9485] 
2024-11-01 21:40:52.398735: Epoch time: 57.28 s 
2024-11-01 21:40:52.398750: Yayy! New best EMA pseudo Dice: 0.7968 
2024-11-01 21:40:52.997060:  
2024-11-01 21:40:52.997124: Epoch 15 
2024-11-01 21:40:52.997160: Current learning rate: 0.00946 
2024-11-01 21:41:49.988491: train_loss -0.8765 
2024-11-01 21:41:49.988565: val_loss -0.8625 
2024-11-01 21:41:49.988597: Pseudo dice [0.9077, 0.8741, 0.9478] 
2024-11-01 21:41:49.988626: Epoch time: 56.99 s 
2024-11-01 21:41:49.988646: Yayy! New best EMA pseudo Dice: 0.8081 
2024-11-01 21:41:50.587970:  
2024-11-01 21:41:50.588063: Epoch 16 
2024-11-01 21:41:50.588099: Current learning rate: 0.00942 
2024-11-01 21:42:47.640382: train_loss -0.8792 
2024-11-01 21:42:47.640455: val_loss -0.8581 
2024-11-01 21:42:47.640483: Pseudo dice [0.8953, 0.8767, 0.9501] 
2024-11-01 21:42:47.640505: Epoch time: 57.05 s 
2024-11-01 21:42:47.640522: Yayy! New best EMA pseudo Dice: 0.818 
2024-11-01 21:42:48.251138:  
2024-11-01 21:42:48.251199: Epoch 17 
2024-11-01 21:42:48.251243: Current learning rate: 0.00939 
2024-11-01 21:43:45.309138: train_loss -0.8859 
2024-11-01 21:43:45.309212: val_loss -0.868 
2024-11-01 21:43:45.309237: Pseudo dice [0.9065, 0.8831, 0.95] 
2024-11-01 21:43:45.309259: Epoch time: 57.06 s 
2024-11-01 21:43:45.309277: Yayy! New best EMA pseudo Dice: 0.8275 
2024-11-01 21:43:45.911211:  
2024-11-01 21:43:45.911272: Epoch 18 
2024-11-01 21:43:45.911315: Current learning rate: 0.00935 
2024-11-01 21:44:42.968826: train_loss -0.8893 
2024-11-01 21:44:42.968900: val_loss -0.8681 
2024-11-01 21:44:42.968933: Pseudo dice [0.9047, 0.8828, 0.9526] 
2024-11-01 21:44:42.968961: Epoch time: 57.06 s 
2024-11-01 21:44:42.968981: Yayy! New best EMA pseudo Dice: 0.8361 
2024-11-01 21:44:43.571251:  
2024-11-01 21:44:43.571306: Epoch 19 
2024-11-01 21:44:43.571342: Current learning rate: 0.00931 
2024-11-01 21:45:40.622224: train_loss -0.8896 
2024-11-01 21:45:40.622300: val_loss -0.8703 
2024-11-01 21:45:40.622332: Pseudo dice [0.9068, 0.8837, 0.9508] 
2024-11-01 21:45:40.622358: Epoch time: 57.05 s 
2024-11-01 21:45:40.622374: Yayy! New best EMA pseudo Dice: 0.8439 
2024-11-01 21:45:41.229021:  
2024-11-01 21:45:41.229069: Epoch 20 
2024-11-01 21:45:41.229109: Current learning rate: 0.00928 
2024-11-01 21:46:38.281922: train_loss -0.8904 
2024-11-01 21:46:38.281997: val_loss -0.8731 
2024-11-01 21:46:38.282032: Pseudo dice [0.9159, 0.8845, 0.9541] 
2024-11-01 21:46:38.282060: Epoch time: 57.05 s 
2024-11-01 21:46:38.282079: Yayy! New best EMA pseudo Dice: 0.8513 
2024-11-01 21:46:38.889001:  
2024-11-01 21:46:38.889057: Epoch 21 
2024-11-01 21:46:38.889097: Current learning rate: 0.00924 
2024-11-01 21:47:36.061908: train_loss -0.8928 
2024-11-01 21:47:36.061987: val_loss -0.8736 
2024-11-01 21:47:36.062015: Pseudo dice [0.9057, 0.8843, 0.9524] 
2024-11-01 21:47:36.062038: Epoch time: 57.17 s 
2024-11-01 21:47:36.062054: Yayy! New best EMA pseudo Dice: 0.8576 
2024-11-01 21:47:36.643352:  
2024-11-01 21:47:36.643411: Epoch 22 
2024-11-01 21:47:36.643455: Current learning rate: 0.0092 
2024-11-01 21:48:33.669615: train_loss -0.8964 
2024-11-01 21:48:33.669704: val_loss -0.8709 
2024-11-01 21:48:33.669729: Pseudo dice [0.9068, 0.8843, 0.9518] 
2024-11-01 21:48:33.669752: Epoch time: 57.03 s 
2024-11-01 21:48:33.669773: Yayy! New best EMA pseudo Dice: 0.8633 
2024-11-01 21:48:34.250740:  
2024-11-01 21:48:34.250786: Epoch 23 
2024-11-01 21:48:34.250822: Current learning rate: 0.00917 
2024-11-01 21:49:31.286518: train_loss -0.8968 
2024-11-01 21:49:31.286593: val_loss -0.8742 
2024-11-01 21:49:31.286629: Pseudo dice [0.9135, 0.8884, 0.9537] 
2024-11-01 21:49:31.286657: Epoch time: 57.04 s 
2024-11-01 21:49:31.286676: Yayy! New best EMA pseudo Dice: 0.8688 
2024-11-01 21:49:31.864335:  
2024-11-01 21:49:31.864410: Epoch 24 
2024-11-01 21:49:31.864459: Current learning rate: 0.00913 
2024-11-01 21:50:28.908960: train_loss -0.8994 
2024-11-01 21:50:28.909035: val_loss -0.8783 
2024-11-01 21:50:28.909068: Pseudo dice [0.9167, 0.8848, 0.9562] 
2024-11-01 21:50:28.909096: Epoch time: 57.05 s 
2024-11-01 21:50:28.909112: Yayy! New best EMA pseudo Dice: 0.8738 
2024-11-01 21:50:29.492675:  
2024-11-01 21:50:29.492719: Epoch 25 
2024-11-01 21:50:29.492758: Current learning rate: 0.0091 
2024-11-01 21:51:26.480872: train_loss -0.8996 
2024-11-01 21:51:26.480953: val_loss -0.8756 
2024-11-01 21:51:26.480987: Pseudo dice [0.9023, 0.8897, 0.9516] 
2024-11-01 21:51:26.481017: Epoch time: 56.99 s 
2024-11-01 21:51:26.481037: Yayy! New best EMA pseudo Dice: 0.8779 
2024-11-01 21:51:27.065926:  
2024-11-01 21:51:27.065991: Epoch 26 
2024-11-01 21:51:27.066027: Current learning rate: 0.00906 
2024-11-01 21:52:24.114540: train_loss -0.8994 
2024-11-01 21:52:24.114612: val_loss -0.8848 
2024-11-01 21:52:24.114644: Pseudo dice [0.9255, 0.8882, 0.9574] 
2024-11-01 21:52:24.114672: Epoch time: 57.05 s 
2024-11-01 21:52:24.114692: Yayy! New best EMA pseudo Dice: 0.8825 
2024-11-01 21:52:24.697695:  
2024-11-01 21:52:24.697738: Epoch 27 
2024-11-01 21:52:24.697779: Current learning rate: 0.00902 
2024-11-01 21:53:21.743944: train_loss -0.9036 
2024-11-01 21:53:21.744016: val_loss -0.8864 
2024-11-01 21:53:21.744047: Pseudo dice [0.9244, 0.8895, 0.957] 
2024-11-01 21:53:21.744074: Epoch time: 57.05 s 
2024-11-01 21:53:21.744095: Yayy! New best EMA pseudo Dice: 0.8866 
2024-11-01 21:53:22.330910:  
2024-11-01 21:53:22.330955: Epoch 28 
2024-11-01 21:53:22.330994: Current learning rate: 0.00899 
2024-11-01 21:54:19.367805: train_loss -0.9059 
2024-11-01 21:54:19.367878: val_loss -0.8852 
2024-11-01 21:54:19.367909: Pseudo dice [0.9192, 0.8894, 0.9582] 
2024-11-01 21:54:19.367935: Epoch time: 57.04 s 
2024-11-01 21:54:19.367956: Yayy! New best EMA pseudo Dice: 0.8902 
2024-11-01 21:54:19.950462:  
2024-11-01 21:54:19.950507: Epoch 29 
2024-11-01 21:54:19.950542: Current learning rate: 0.00895 
2024-11-01 21:55:17.001051: train_loss -0.904 
2024-11-01 21:55:17.001129: val_loss -0.8807 
2024-11-01 21:55:17.001160: Pseudo dice [0.9082, 0.8934, 0.956] 
2024-11-01 21:55:17.001187: Epoch time: 57.05 s 
2024-11-01 21:55:17.001202: Yayy! New best EMA pseudo Dice: 0.8931 
2024-11-01 21:55:17.595309:  
2024-11-01 21:55:17.595353: Epoch 30 
2024-11-01 21:55:17.595392: Current learning rate: 0.00891 
2024-11-01 21:56:14.635939: train_loss -0.9078 
2024-11-01 21:56:14.636019: val_loss -0.8816 
2024-11-01 21:56:14.636052: Pseudo dice [0.9222, 0.8869, 0.955] 
2024-11-01 21:56:14.636088: Epoch time: 57.04 s 
2024-11-01 21:56:14.636105: Yayy! New best EMA pseudo Dice: 0.8959 
2024-11-01 21:56:15.492557:  
2024-11-01 21:56:15.492608: Epoch 31 
2024-11-01 21:56:15.492645: Current learning rate: 0.00888 
2024-11-01 21:57:12.507564: train_loss -0.9056 
2024-11-01 21:57:12.507640: val_loss -0.8799 
2024-11-01 21:57:12.507667: Pseudo dice [0.9105, 0.8898, 0.9534] 
2024-11-01 21:57:12.507690: Epoch time: 57.02 s 
2024-11-01 21:57:12.507706: Yayy! New best EMA pseudo Dice: 0.8981 
2024-11-01 21:57:13.100561:  
2024-11-01 21:57:13.100651: Epoch 32 
2024-11-01 21:57:13.100692: Current learning rate: 0.00884 
2024-11-01 21:58:10.123852: train_loss -0.9069 
2024-11-01 21:58:10.123926: val_loss -0.8795 
2024-11-01 21:58:10.123972: Pseudo dice [0.9027, 0.8937, 0.9569] 
2024-11-01 21:58:10.124001: Epoch time: 57.02 s 
2024-11-01 21:58:10.124017: Yayy! New best EMA pseudo Dice: 0.9001 
2024-11-01 21:58:10.722054:  
2024-11-01 21:58:10.722112: Epoch 33 
2024-11-01 21:58:10.722155: Current learning rate: 0.0088 
2024-11-01 21:59:07.783517: train_loss -0.9082 
2024-11-01 21:59:07.783593: val_loss -0.8785 
2024-11-01 21:59:07.783618: Pseudo dice [0.9122, 0.8851, 0.9569] 
2024-11-01 21:59:07.783648: Epoch time: 57.06 s 
2024-11-01 21:59:07.783664: Yayy! New best EMA pseudo Dice: 0.9019 
2024-11-01 21:59:08.380535:  
2024-11-01 21:59:08.380589: Epoch 34 
2024-11-01 21:59:08.380662: Current learning rate: 0.00877 
2024-11-01 22:00:05.390733: train_loss -0.9075 
2024-11-01 22:00:05.390812: val_loss -0.8821 
2024-11-01 22:00:05.390842: Pseudo dice [0.9121, 0.8892, 0.9547] 
2024-11-01 22:00:05.390866: Epoch time: 57.01 s 
2024-11-01 22:00:05.390882: Yayy! New best EMA pseudo Dice: 0.9035 
2024-11-01 22:00:05.994988:  
2024-11-01 22:00:05.995038: Epoch 35 
2024-11-01 22:00:05.995103: Current learning rate: 0.00873 
2024-11-01 22:01:03.050215: train_loss -0.9062 
2024-11-01 22:01:03.050290: val_loss -0.8804 
2024-11-01 22:01:03.050327: Pseudo dice [0.9102, 0.8904, 0.9586] 
2024-11-01 22:01:03.050355: Epoch time: 57.06 s 
2024-11-01 22:01:03.050375: Yayy! New best EMA pseudo Dice: 0.9052 
2024-11-01 22:01:03.654267:  
2024-11-01 22:01:03.654318: Epoch 36 
2024-11-01 22:01:03.654375: Current learning rate: 0.00869 
2024-11-01 22:02:00.951266: train_loss -0.9068 
2024-11-01 22:02:00.951359: val_loss -0.8807 
2024-11-01 22:02:00.951403: Pseudo dice [0.9099, 0.89, 0.9549] 
2024-11-01 22:02:00.951433: Epoch time: 57.3 s 
2024-11-01 22:02:00.951457: Yayy! New best EMA pseudo Dice: 0.9065 
2024-11-01 22:02:01.555187:  
2024-11-01 22:02:01.555243: Epoch 37 
2024-11-01 22:02:01.555285: Current learning rate: 0.00866 
2024-11-01 22:02:58.565688: train_loss -0.9072 
2024-11-01 22:02:58.565763: val_loss -0.8779 
2024-11-01 22:02:58.565791: Pseudo dice [0.9103, 0.8896, 0.9553] 
2024-11-01 22:02:58.565814: Epoch time: 57.01 s 
2024-11-01 22:02:58.565829: Yayy! New best EMA pseudo Dice: 0.9077 
2024-11-01 22:02:59.171950:  
2024-11-01 22:02:59.172026: Epoch 38 
2024-11-01 22:02:59.172065: Current learning rate: 0.00862 
2024-11-01 22:03:56.231547: train_loss -0.9106 
2024-11-01 22:03:56.231623: val_loss -0.886 
2024-11-01 22:03:56.231657: Pseudo dice [0.917, 0.8942, 0.957] 
2024-11-01 22:03:56.231690: Epoch time: 57.06 s 
2024-11-01 22:03:56.231712: Yayy! New best EMA pseudo Dice: 0.9092 
2024-11-01 22:03:56.835633:  
2024-11-01 22:03:56.835692: Epoch 39 
2024-11-01 22:03:56.835733: Current learning rate: 0.00858 
2024-11-01 22:04:53.895081: train_loss -0.9123 
2024-11-01 22:04:53.895154: val_loss -0.8806 
2024-11-01 22:04:53.895179: Pseudo dice [0.9167, 0.8899, 0.9563] 
2024-11-01 22:04:53.895202: Epoch time: 57.06 s 
2024-11-01 22:04:53.895231: Yayy! New best EMA pseudo Dice: 0.9103 
2024-11-01 22:04:54.512648:  
2024-11-01 22:04:54.512742: Epoch 40 
2024-11-01 22:04:54.512783: Current learning rate: 0.00855 
2024-11-01 22:05:51.565864: train_loss -0.9146 
2024-11-01 22:05:51.565938: val_loss -0.8886 
2024-11-01 22:05:51.565966: Pseudo dice [0.9201, 0.8958, 0.9568] 
2024-11-01 22:05:51.565988: Epoch time: 57.05 s 
2024-11-01 22:05:51.566003: Yayy! New best EMA pseudo Dice: 0.9117 
2024-11-01 22:05:52.177790:  
2024-11-01 22:05:52.177849: Epoch 41 
2024-11-01 22:05:52.177887: Current learning rate: 0.00851 
2024-11-01 22:06:49.234921: train_loss -0.914 
2024-11-01 22:06:49.234996: val_loss -0.8799 
2024-11-01 22:06:49.235021: Pseudo dice [0.9045, 0.8951, 0.9578] 
2024-11-01 22:06:49.235044: Epoch time: 57.06 s 
2024-11-01 22:06:49.235060: Yayy! New best EMA pseudo Dice: 0.9125 
2024-11-01 22:06:49.815333:  
2024-11-01 22:06:49.815378: Epoch 42 
2024-11-01 22:06:49.815426: Current learning rate: 0.00847 
2024-11-01 22:07:46.871282: train_loss -0.9129 
2024-11-01 22:07:46.871357: val_loss -0.8811 
2024-11-01 22:07:46.871399: Pseudo dice [0.9133, 0.8954, 0.9594] 
2024-11-01 22:07:46.871433: Epoch time: 57.06 s 
2024-11-01 22:07:46.871450: Yayy! New best EMA pseudo Dice: 0.9135 
2024-11-01 22:07:47.455778:  
2024-11-01 22:07:47.455837: Epoch 43 
2024-11-01 22:07:47.455873: Current learning rate: 0.00844 
2024-11-01 22:08:44.465169: train_loss -0.9139 
2024-11-01 22:08:44.465242: val_loss -0.8858 
2024-11-01 22:08:44.465276: Pseudo dice [0.9165, 0.8948, 0.9577] 
2024-11-01 22:08:44.465325: Epoch time: 57.01 s 
2024-11-01 22:08:44.465481: Yayy! New best EMA pseudo Dice: 0.9144 
2024-11-01 22:08:45.046674:  
2024-11-01 22:08:45.046758: Epoch 44 
2024-11-01 22:08:45.046798: Current learning rate: 0.0084 
2024-11-01 22:09:42.055062: train_loss -0.9144 
2024-11-01 22:09:42.055149: val_loss -0.8829 
2024-11-01 22:09:42.055187: Pseudo dice [0.9158, 0.8949, 0.9566] 
2024-11-01 22:09:42.055228: Epoch time: 57.01 s 
2024-11-01 22:09:42.055246: Yayy! New best EMA pseudo Dice: 0.9152 
2024-11-01 22:09:42.636843:  
2024-11-01 22:09:42.636889: Epoch 45 
2024-11-01 22:09:42.636928: Current learning rate: 0.00836 
2024-11-01 22:10:39.652648: train_loss -0.9154 
2024-11-01 22:10:39.652723: val_loss -0.8853 
2024-11-01 22:10:39.652754: Pseudo dice [0.9078, 0.8945, 0.9579] 
2024-11-01 22:10:39.652781: Epoch time: 57.02 s 
2024-11-01 22:10:39.652800: Yayy! New best EMA pseudo Dice: 0.9157 
2024-11-01 22:10:40.235617:  
2024-11-01 22:10:40.235688: Epoch 46 
2024-11-01 22:10:40.235725: Current learning rate: 0.00833 
2024-11-01 22:11:37.246431: train_loss -0.9152 
2024-11-01 22:11:37.246511: val_loss -0.8902 
2024-11-01 22:11:37.246543: Pseudo dice [0.9215, 0.8981, 0.9568] 
2024-11-01 22:11:37.246566: Epoch time: 57.01 s 
2024-11-01 22:11:37.246582: Yayy! New best EMA pseudo Dice: 0.9167 
2024-11-01 22:11:37.827330:  
2024-11-01 22:11:37.827375: Epoch 47 
2024-11-01 22:11:37.827413: Current learning rate: 0.00829 
2024-11-01 22:12:34.895719: train_loss -0.9161 
2024-11-01 22:12:34.895789: val_loss -0.8882 
2024-11-01 22:12:34.895814: Pseudo dice [0.9196, 0.897, 0.9597] 
2024-11-01 22:12:34.895841: Epoch time: 57.07 s 
2024-11-01 22:12:34.895857: Yayy! New best EMA pseudo Dice: 0.9176 
2024-11-01 22:12:35.479279:  
2024-11-01 22:12:35.479355: Epoch 48 
2024-11-01 22:12:35.479396: Current learning rate: 0.00825 
2024-11-01 22:13:32.486236: train_loss -0.9169 
2024-11-01 22:13:32.486308: val_loss -0.8834 
2024-11-01 22:13:32.486339: Pseudo dice [0.913, 0.8958, 0.9569] 
2024-11-01 22:13:32.486361: Epoch time: 57.01 s 
2024-11-01 22:13:32.486377: Yayy! New best EMA pseudo Dice: 0.918 
2024-11-01 22:13:33.337821:  
2024-11-01 22:13:33.337880: Epoch 49 
2024-11-01 22:13:33.337917: Current learning rate: 0.00822 
2024-11-01 22:14:30.410784: train_loss -0.917 
2024-11-01 22:14:30.410859: val_loss -0.8917 
2024-11-01 22:14:30.410884: Pseudo dice [0.9231, 0.8982, 0.96] 
2024-11-01 22:14:30.410907: Epoch time: 57.07 s 
2024-11-01 22:14:30.520928: Yayy! New best EMA pseudo Dice: 0.9189 
2024-11-01 22:14:31.107998:  
2024-11-01 22:14:31.108048: Epoch 50 
2024-11-01 22:14:31.108081: Current learning rate: 0.00818 
2024-11-01 22:15:28.130533: train_loss -0.9192 
2024-11-01 22:15:28.130607: val_loss -0.8984 
2024-11-01 22:15:28.130633: Pseudo dice [0.9278, 0.9028, 0.9609] 
2024-11-01 22:15:28.130656: Epoch time: 57.02 s 
2024-11-01 22:15:28.130672: Yayy! New best EMA pseudo Dice: 0.9201 
2024-11-01 22:15:28.720705:  
2024-11-01 22:15:28.720754: Epoch 51 
2024-11-01 22:15:28.720791: Current learning rate: 0.00814 
2024-11-01 22:16:25.779835: train_loss -0.9201 
2024-11-01 22:16:25.779906: val_loss -0.8935 
2024-11-01 22:16:25.779932: Pseudo dice [0.9266, 0.8974, 0.9616] 
2024-11-01 22:16:25.779953: Epoch time: 57.06 s 
2024-11-01 22:16:25.779969: Yayy! New best EMA pseudo Dice: 0.9209 
2024-11-01 22:16:26.365798:  
2024-11-01 22:16:26.365851: Epoch 52 
2024-11-01 22:16:26.365892: Current learning rate: 0.00811 
2024-11-01 22:17:23.364277: train_loss -0.9192 
2024-11-01 22:17:23.364362: val_loss -0.8873 
2024-11-01 22:17:23.364394: Pseudo dice [0.9148, 0.8996, 0.959] 
2024-11-01 22:17:23.364423: Epoch time: 57.0 s 
2024-11-01 22:17:23.364465: Yayy! New best EMA pseudo Dice: 0.9213 
2024-11-01 22:17:23.953954:  
2024-11-01 22:17:23.954005: Epoch 53 
2024-11-01 22:17:23.954043: Current learning rate: 0.00807 
2024-11-01 22:18:20.734713: train_loss -0.9192 
2024-11-01 22:18:20.734798: val_loss -0.891 
2024-11-01 22:18:20.734851: Pseudo dice [0.9192, 0.8994, 0.9593] 
2024-11-01 22:18:20.734875: Epoch time: 56.78 s 
2024-11-01 22:18:20.734891: Yayy! New best EMA pseudo Dice: 0.9218 
2024-11-01 22:18:21.325197:  
2024-11-01 22:18:21.325294: Epoch 54 
2024-11-01 22:18:21.325330: Current learning rate: 0.00803 
2024-11-01 22:19:18.150624: train_loss -0.919 
2024-11-01 22:19:18.150715: val_loss -0.8838 
2024-11-01 22:19:18.150747: Pseudo dice [0.9188, 0.8888, 0.9563] 
2024-11-01 22:19:18.150781: Epoch time: 56.83 s 
2024-11-01 22:19:18.616109:  
2024-11-01 22:19:18.616172: Epoch 55 
2024-11-01 22:19:18.616211: Current learning rate: 0.008 
2024-11-01 22:20:15.405708: train_loss -0.9207 
2024-11-01 22:20:15.405778: val_loss -0.8954 
2024-11-01 22:20:15.405802: Pseudo dice [0.927, 0.8991, 0.9585] 
2024-11-01 22:20:15.405824: Epoch time: 56.79 s 
2024-11-01 22:20:15.405840: Yayy! New best EMA pseudo Dice: 0.9224 
2024-11-01 22:20:15.999975:  
2024-11-01 22:20:16.000026: Epoch 56 
2024-11-01 22:20:16.000071: Current learning rate: 0.00796 
2024-11-01 22:21:12.841152: train_loss -0.9217 
2024-11-01 22:21:12.841255: val_loss -0.8919 
2024-11-01 22:21:12.841281: Pseudo dice [0.9213, 0.8975, 0.961] 
2024-11-01 22:21:12.841305: Epoch time: 56.84 s 
2024-11-01 22:21:12.841320: Yayy! New best EMA pseudo Dice: 0.9228 
2024-11-01 22:21:13.435408:  
2024-11-01 22:21:13.435459: Epoch 57 
2024-11-01 22:21:13.435498: Current learning rate: 0.00792 
2024-11-01 22:22:10.219256: train_loss -0.9165 
2024-11-01 22:22:10.219339: val_loss -0.8828 
2024-11-01 22:22:10.219391: Pseudo dice [0.9062, 0.8933, 0.9578] 
2024-11-01 22:22:10.219420: Epoch time: 56.78 s 
2024-11-01 22:22:10.680419:  
2024-11-01 22:22:10.680498: Epoch 58 
2024-11-01 22:22:10.680535: Current learning rate: 0.00789 
2024-11-01 22:23:07.463402: train_loss -0.9168 
2024-11-01 22:23:07.463478: val_loss -0.8775 
2024-11-01 22:23:07.463511: Pseudo dice [0.9109, 0.8942, 0.9574] 
2024-11-01 22:23:07.463539: Epoch time: 56.78 s 
2024-11-01 22:23:07.934920:  
2024-11-01 22:23:07.934973: Epoch 59 
2024-11-01 22:23:07.935012: Current learning rate: 0.00785 
2024-11-01 22:24:04.735192: train_loss -0.919 
2024-11-01 22:24:04.735264: val_loss -0.8822 
2024-11-01 22:24:04.735291: Pseudo dice [0.9081, 0.8957, 0.9566] 
2024-11-01 22:24:04.735315: Epoch time: 56.8 s 
2024-11-01 22:24:05.205344:  
2024-11-01 22:24:05.205390: Epoch 60 
2024-11-01 22:24:05.205428: Current learning rate: 0.00781 
2024-11-01 22:25:02.031071: train_loss -0.9206 
2024-11-01 22:25:02.031147: val_loss -0.8878 
2024-11-01 22:25:02.031181: Pseudo dice [0.9216, 0.8956, 0.9571] 
2024-11-01 22:25:02.031210: Epoch time: 56.83 s 
2024-11-01 22:25:02.502000:  
2024-11-01 22:25:02.502048: Epoch 61 
2024-11-01 22:25:02.502088: Current learning rate: 0.00777 
2024-11-01 22:25:59.272904: train_loss -0.9208 
2024-11-01 22:25:59.272978: val_loss -0.8892 
2024-11-01 22:25:59.273008: Pseudo dice [0.9172, 0.8994, 0.9563] 
2024-11-01 22:25:59.273036: Epoch time: 56.77 s 
2024-11-01 22:25:59.741376:  
2024-11-01 22:25:59.741423: Epoch 62 
2024-11-01 22:25:59.741460: Current learning rate: 0.00774 
2024-11-01 22:26:56.506114: train_loss -0.9221 
2024-11-01 22:26:56.506189: val_loss -0.8851 
2024-11-01 22:26:56.506219: Pseudo dice [0.921, 0.894, 0.9554] 
2024-11-01 22:26:56.506243: Epoch time: 56.77 s 
2024-11-01 22:26:56.974957:  
2024-11-01 22:26:56.975004: Epoch 63 
2024-11-01 22:26:56.975037: Current learning rate: 0.0077 
2024-11-01 22:27:53.801474: train_loss -0.9217 
2024-11-01 22:27:53.801548: val_loss -0.8938 
2024-11-01 22:27:53.801585: Pseudo dice [0.9276, 0.9022, 0.9586] 
2024-11-01 22:27:53.801614: Epoch time: 56.83 s 
2024-11-01 22:27:53.801634: Yayy! New best EMA pseudo Dice: 0.9233 
2024-11-01 22:27:54.395297:  
2024-11-01 22:27:54.395350: Epoch 64 
2024-11-01 22:27:54.395388: Current learning rate: 0.00766 
2024-11-01 22:28:51.184955: train_loss -0.9222 
2024-11-01 22:28:51.185036: val_loss -0.8955 
2024-11-01 22:28:51.185068: Pseudo dice [0.9265, 0.8974, 0.9604] 
2024-11-01 22:28:51.185097: Epoch time: 56.79 s 
2024-11-01 22:28:51.185117: Yayy! New best EMA pseudo Dice: 0.9238 
2024-11-01 22:28:51.778550:  
2024-11-01 22:28:51.778598: Epoch 65 
2024-11-01 22:28:51.778636: Current learning rate: 0.00763 
2024-11-01 22:29:48.568648: train_loss -0.9243 
2024-11-01 22:29:48.568735: val_loss -0.8914 
2024-11-01 22:29:48.568768: Pseudo dice [0.9241, 0.8987, 0.9574] 
2024-11-01 22:29:48.568796: Epoch time: 56.79 s 
2024-11-01 22:29:48.568816: Yayy! New best EMA pseudo Dice: 0.9241 
2024-11-01 22:29:49.162081:  
2024-11-01 22:29:49.162125: Epoch 66 
2024-11-01 22:29:49.162161: Current learning rate: 0.00759 
2024-11-01 22:30:45.949022: train_loss -0.9249 
2024-11-01 22:30:45.949096: val_loss -0.8917 
2024-11-01 22:30:45.949124: Pseudo dice [0.9192, 0.8971, 0.963] 
2024-11-01 22:30:45.949149: Epoch time: 56.79 s 
2024-11-01 22:30:45.949166: Yayy! New best EMA pseudo Dice: 0.9243 
2024-11-01 22:30:46.542737:  
2024-11-01 22:30:46.542784: Epoch 67 
2024-11-01 22:30:46.542821: Current learning rate: 0.00755 
2024-11-01 22:31:43.377454: train_loss -0.9233 
2024-11-01 22:31:43.377526: val_loss -0.8954 
2024-11-01 22:31:43.377550: Pseudo dice [0.9283, 0.9012, 0.9613] 
2024-11-01 22:31:43.377572: Epoch time: 56.84 s 
2024-11-01 22:31:43.377588: Yayy! New best EMA pseudo Dice: 0.9249 
2024-11-01 22:31:44.252050:  
2024-11-01 22:31:44.252101: Epoch 68 
2024-11-01 22:31:44.252141: Current learning rate: 0.00751 
2024-11-01 22:32:41.064020: train_loss -0.9236 
2024-11-01 22:32:41.064098: val_loss -0.8949 
2024-11-01 22:32:41.064133: Pseudo dice [0.9176, 0.9018, 0.9628] 
2024-11-01 22:32:41.064161: Epoch time: 56.81 s 
2024-11-01 22:32:41.064180: Yayy! New best EMA pseudo Dice: 0.9252 
2024-11-01 22:32:41.666798:  
2024-11-01 22:32:41.666874: Epoch 69 
2024-11-01 22:32:41.666911: Current learning rate: 0.00748 
2024-11-01 22:33:38.464841: train_loss -0.9254 
2024-11-01 22:33:38.464923: val_loss -0.8962 
2024-11-01 22:33:38.464948: Pseudo dice [0.9266, 0.8999, 0.9612] 
2024-11-01 22:33:38.464972: Epoch time: 56.8 s 
2024-11-01 22:33:38.464987: Yayy! New best EMA pseudo Dice: 0.9256 
2024-11-01 22:33:39.068460:  
2024-11-01 22:33:39.068513: Epoch 70 
2024-11-01 22:33:39.068552: Current learning rate: 0.00744 
2024-11-01 22:34:35.859420: train_loss -0.9263 
2024-11-01 22:34:35.859499: val_loss -0.8816 
2024-11-01 22:34:35.859533: Pseudo dice [0.9147, 0.8987, 0.9553] 
2024-11-01 22:34:35.859560: Epoch time: 56.79 s 
2024-11-01 22:34:36.336801:  
2024-11-01 22:34:36.336856: Epoch 71 
2024-11-01 22:34:36.336893: Current learning rate: 0.0074 
2024-11-01 22:35:33.169118: train_loss -0.9255 
2024-11-01 22:35:33.169198: val_loss -0.8881 
2024-11-01 22:35:33.169230: Pseudo dice [0.9185, 0.8976, 0.9578] 
2024-11-01 22:35:33.169257: Epoch time: 56.83 s 
2024-11-01 22:35:33.649126:  
2024-11-01 22:35:33.649177: Epoch 72 
2024-11-01 22:35:33.649213: Current learning rate: 0.00737 
2024-11-01 22:36:30.490096: train_loss -0.9251 
2024-11-01 22:36:30.490171: val_loss -0.8895 
2024-11-01 22:36:30.490204: Pseudo dice [0.9162, 0.9007, 0.9612] 
2024-11-01 22:36:30.490233: Epoch time: 56.84 s 
2024-11-01 22:36:30.965702:  
2024-11-01 22:36:30.965757: Epoch 73 
2024-11-01 22:36:30.965797: Current learning rate: 0.00733 
2024-11-01 22:37:27.755185: train_loss -0.9256 
2024-11-01 22:37:27.755264: val_loss -0.8844 
2024-11-01 22:37:27.755351: Pseudo dice [0.9146, 0.8965, 0.9575] 
2024-11-01 22:37:27.755374: Epoch time: 56.79 s 
2024-11-01 22:37:28.238245:  
2024-11-01 22:37:28.238296: Epoch 74 
2024-11-01 22:37:28.238339: Current learning rate: 0.00729 
2024-11-01 22:38:25.073825: train_loss -0.9246 
2024-11-01 22:38:25.073903: val_loss -0.8957 
2024-11-01 22:38:25.073928: Pseudo dice [0.9206, 0.9055, 0.9631] 
2024-11-01 22:38:25.073951: Epoch time: 56.84 s 
2024-11-01 22:38:25.555420:  
2024-11-01 22:38:25.555479: Epoch 75 
2024-11-01 22:38:25.555515: Current learning rate: 0.00725 
2024-11-01 22:39:22.381036: train_loss -0.9254 
2024-11-01 22:39:22.381119: val_loss -0.8859 
2024-11-01 22:39:22.381148: Pseudo dice [0.9153, 0.8989, 0.9606] 
2024-11-01 22:39:22.381171: Epoch time: 56.83 s 
2024-11-01 22:39:22.860004:  
2024-11-01 22:39:22.860048: Epoch 76 
2024-11-01 22:39:22.860083: Current learning rate: 0.00722 
2024-11-01 22:40:19.700952: train_loss -0.9257 
2024-11-01 22:40:19.701043: val_loss -0.8935 
2024-11-01 22:40:19.701234: Pseudo dice [0.922, 0.9028, 0.9587] 
2024-11-01 22:40:19.701274: Epoch time: 56.84 s 
2024-11-01 22:40:19.701293: Yayy! New best EMA pseudo Dice: 0.9257 
2024-11-01 22:40:20.305408:  
2024-11-01 22:40:20.305457: Epoch 77 
2024-11-01 22:40:20.305492: Current learning rate: 0.00718 
2024-11-01 22:41:17.096625: train_loss -0.9267 
2024-11-01 22:41:17.096700: val_loss -0.8952 
2024-11-01 22:41:17.096731: Pseudo dice [0.9236, 0.9013, 0.9626] 
2024-11-01 22:41:17.096760: Epoch time: 56.79 s 
2024-11-01 22:41:17.096784: Yayy! New best EMA pseudo Dice: 0.9261 
2024-11-01 22:41:17.706472:  
2024-11-01 22:41:17.706523: Epoch 78 
2024-11-01 22:41:17.706574: Current learning rate: 0.00714 
2024-11-01 22:42:14.496310: train_loss -0.9268 
2024-11-01 22:42:14.496384: val_loss -0.8962 
2024-11-01 22:42:14.496409: Pseudo dice [0.929, 0.8982, 0.9598] 
2024-11-01 22:42:14.496430: Epoch time: 56.79 s 
2024-11-01 22:42:14.496445: Yayy! New best EMA pseudo Dice: 0.9264 
2024-11-01 22:42:15.109863:  
2024-11-01 22:42:15.109952: Epoch 79 
2024-11-01 22:42:15.110000: Current learning rate: 0.0071 
2024-11-01 22:43:11.879967: train_loss -0.9267 
2024-11-01 22:43:11.880047: val_loss -0.89 
2024-11-01 22:43:11.880079: Pseudo dice [0.9225, 0.9038, 0.9602] 
2024-11-01 22:43:11.880107: Epoch time: 56.77 s 
2024-11-01 22:43:11.880126: Yayy! New best EMA pseudo Dice: 0.9266 
2024-11-01 22:43:12.496382:  
2024-11-01 22:43:12.496430: Epoch 80 
2024-11-01 22:43:12.496466: Current learning rate: 0.00707 
2024-11-01 22:44:09.269604: train_loss -0.9266 
2024-11-01 22:44:09.269674: val_loss -0.8937 
2024-11-01 22:44:09.269700: Pseudo dice [0.9185, 0.9004, 0.9608] 
2024-11-01 22:44:09.269723: Epoch time: 56.77 s 
2024-11-01 22:44:09.753752:  
2024-11-01 22:44:09.753798: Epoch 81 
2024-11-01 22:44:09.753833: Current learning rate: 0.00703 
2024-11-01 22:45:06.536261: train_loss -0.9268 
2024-11-01 22:45:06.536339: val_loss -0.8854 
2024-11-01 22:45:06.536376: Pseudo dice [0.9146, 0.9032, 0.9577] 
2024-11-01 22:45:06.536407: Epoch time: 56.78 s 
2024-11-01 22:45:07.022546:  
2024-11-01 22:45:07.022591: Epoch 82 
2024-11-01 22:45:07.022626: Current learning rate: 0.00699 
2024-11-01 22:46:03.795278: train_loss -0.9277 
2024-11-01 22:46:03.795353: val_loss -0.8875 
2024-11-01 22:46:03.795393: Pseudo dice [0.9154, 0.9008, 0.96] 
2024-11-01 22:46:03.795421: Epoch time: 56.77 s 
2024-11-01 22:46:04.253394:  
2024-11-01 22:46:04.253439: Epoch 83 
2024-11-01 22:46:04.253474: Current learning rate: 0.00696 
2024-11-01 22:47:01.035135: train_loss -0.9286 
2024-11-01 22:47:01.035209: val_loss -0.8877 
2024-11-01 22:47:01.035236: Pseudo dice [0.9141, 0.8985, 0.9616] 
2024-11-01 22:47:01.035258: Epoch time: 56.78 s 
2024-11-01 22:47:01.489485:  
2024-11-01 22:47:01.489568: Epoch 84 
2024-11-01 22:47:01.489611: Current learning rate: 0.00692 
2024-11-01 22:47:58.313777: train_loss -0.9285 
2024-11-01 22:47:58.313871: val_loss -0.8865 
2024-11-01 22:47:58.313919: Pseudo dice [0.9115, 0.9024, 0.956] 
2024-11-01 22:47:58.313944: Epoch time: 56.82 s 
2024-11-01 22:47:58.769509:  
2024-11-01 22:47:58.769554: Epoch 85 
2024-11-01 22:47:58.769614: Current learning rate: 0.00688 
2024-11-01 22:48:55.596622: train_loss -0.9284 
2024-11-01 22:48:55.596698: val_loss -0.8953 
2024-11-01 22:48:55.596724: Pseudo dice [0.9212, 0.8989, 0.9634] 
2024-11-01 22:48:55.596746: Epoch time: 56.83 s 
2024-11-01 22:48:56.047182:  
2024-11-01 22:48:56.047248: Epoch 86 
2024-11-01 22:48:56.047291: Current learning rate: 0.00684 
2024-11-01 22:49:52.825176: train_loss -0.9293 
2024-11-01 22:49:52.825253: val_loss -0.8932 
2024-11-01 22:49:52.825281: Pseudo dice [0.922, 0.9009, 0.9623] 
2024-11-01 22:49:52.825306: Epoch time: 56.78 s 
2024-11-01 22:49:53.551032:  
2024-11-01 22:49:53.551154: Epoch 87 
2024-11-01 22:49:53.551193: Current learning rate: 0.0068 
2024-11-01 22:50:50.386439: train_loss -0.9293 
2024-11-01 22:50:50.386523: val_loss -0.8877 
2024-11-01 22:50:50.386557: Pseudo dice [0.9176, 0.8992, 0.957] 
2024-11-01 22:50:50.386585: Epoch time: 56.84 s 
2024-11-01 22:50:50.842016:  
2024-11-01 22:50:50.842077: Epoch 88 
2024-11-01 22:50:50.842116: Current learning rate: 0.00677 
2024-11-01 22:51:47.685446: train_loss -0.9275 
2024-11-01 22:51:47.685522: val_loss -0.8859 
2024-11-01 22:51:47.685565: Pseudo dice [0.9149, 0.9018, 0.9513] 
2024-11-01 22:51:47.685602: Epoch time: 56.84 s 
2024-11-01 22:51:48.140972:  
2024-11-01 22:51:48.141053: Epoch 89 
2024-11-01 22:51:48.141089: Current learning rate: 0.00673 
2024-11-01 22:52:44.923129: train_loss -0.9276 
2024-11-01 22:52:44.923203: val_loss -0.8921 
2024-11-01 22:52:44.923234: Pseudo dice [0.9251, 0.9018, 0.9554] 
2024-11-01 22:52:44.923263: Epoch time: 56.78 s 
2024-11-01 22:52:45.377704:  
2024-11-01 22:52:45.377758: Epoch 90 
2024-11-01 22:52:45.377791: Current learning rate: 0.00669 
2024-11-01 22:53:42.162397: train_loss -0.9313 
2024-11-01 22:53:42.162481: val_loss -0.8926 
2024-11-01 22:53:42.162513: Pseudo dice [0.9247, 0.9017, 0.9608] 
2024-11-01 22:53:42.162542: Epoch time: 56.79 s 
2024-11-01 22:53:42.620248:  
2024-11-01 22:53:42.620308: Epoch 91 
2024-11-01 22:53:42.620346: Current learning rate: 0.00665 
2024-11-01 22:54:39.407054: train_loss -0.9299 
2024-11-01 22:54:39.407126: val_loss -0.8944 
2024-11-01 22:54:39.407160: Pseudo dice [0.924, 0.9034, 0.9587] 
2024-11-01 22:54:39.407190: Epoch time: 56.79 s 
2024-11-01 22:54:39.866091:  
2024-11-01 22:54:39.866143: Epoch 92 
2024-11-01 22:54:39.866179: Current learning rate: 0.00662 
2024-11-01 22:55:36.636714: train_loss -0.9308 
2024-11-01 22:55:36.636795: val_loss -0.8832 
2024-11-01 22:55:36.636828: Pseudo dice [0.9166, 0.8966, 0.9546] 
2024-11-01 22:55:36.636856: Epoch time: 56.77 s 
2024-11-01 22:55:37.094338:  
2024-11-01 22:55:37.094417: Epoch 93 
2024-11-01 22:55:37.094497: Current learning rate: 0.00658 
2024-11-01 22:56:33.930075: train_loss -0.9324 
2024-11-01 22:56:33.930149: val_loss -0.8934 
2024-11-01 22:56:33.930180: Pseudo dice [0.9167, 0.9049, 0.9602] 
2024-11-01 22:56:33.930207: Epoch time: 56.84 s 
2024-11-01 22:56:34.389649:  
2024-11-01 22:56:34.389699: Epoch 94 
2024-11-01 22:56:34.389740: Current learning rate: 0.00654 
2024-11-01 22:57:31.223794: train_loss -0.9303 
2024-11-01 22:57:31.223866: val_loss -0.8896 
2024-11-01 22:57:31.223892: Pseudo dice [0.9241, 0.9001, 0.9603] 
2024-11-01 22:57:31.223914: Epoch time: 56.83 s 
2024-11-01 22:57:31.689239:  
2024-11-01 22:57:31.689293: Epoch 95 
2024-11-01 22:57:31.689334: Current learning rate: 0.0065 
2024-11-01 22:58:28.487403: train_loss -0.9305 
2024-11-01 22:58:28.487482: val_loss -0.8926 
2024-11-01 22:58:28.487514: Pseudo dice [0.9228, 0.8988, 0.9611] 
2024-11-01 22:58:28.487542: Epoch time: 56.8 s 
2024-11-01 22:58:28.945834:  
2024-11-01 22:58:28.945885: Epoch 96 
2024-11-01 22:58:28.945922: Current learning rate: 0.00647 
2024-11-01 22:59:25.764030: train_loss -0.9302 
2024-11-01 22:59:25.764099: val_loss -0.8923 
2024-11-01 22:59:25.764132: Pseudo dice [0.9212, 0.9036, 0.9613] 
2024-11-01 22:59:25.764161: Epoch time: 56.82 s 
2024-11-01 22:59:25.764183: Yayy! New best EMA pseudo Dice: 0.9268 
2024-11-01 22:59:26.354262:  
2024-11-01 22:59:26.354310: Epoch 97 
2024-11-01 22:59:26.354351: Current learning rate: 0.00643 
2024-11-01 23:00:23.151448: train_loss -0.9309 
2024-11-01 23:00:23.151529: val_loss -0.8879 
2024-11-01 23:00:23.151561: Pseudo dice [0.918, 0.9005, 0.96] 
2024-11-01 23:00:23.151589: Epoch time: 56.8 s 
2024-11-01 23:00:23.616182:  
2024-11-01 23:00:23.616228: Epoch 98 
2024-11-01 23:00:23.616265: Current learning rate: 0.00639 
2024-11-01 23:01:20.442952: train_loss -0.9314 
2024-11-01 23:01:20.443027: val_loss -0.8922 
2024-11-01 23:01:20.443053: Pseudo dice [0.9176, 0.9018, 0.9623] 
2024-11-01 23:01:20.443082: Epoch time: 56.83 s 
2024-11-01 23:01:20.907501:  
2024-11-01 23:01:20.907545: Epoch 99 
2024-11-01 23:01:20.907580: Current learning rate: 0.00635 
2024-11-01 23:02:17.684294: train_loss -0.931 
2024-11-01 23:02:17.684367: val_loss -0.8924 
2024-11-01 23:02:17.684400: Pseudo dice [0.9199, 0.8987, 0.9635] 
2024-11-01 23:02:17.684428: Epoch time: 56.78 s 
2024-11-01 23:02:17.807855: Yayy! New best EMA pseudo Dice: 0.9268 
2024-11-01 23:02:18.396229:  
2024-11-01 23:02:18.396282: Epoch 100 
2024-11-01 23:02:18.396317: Current learning rate: 0.00631 
2024-11-01 23:03:15.224619: train_loss -0.93 
2024-11-01 23:03:15.224694: val_loss -0.8916 
2024-11-01 23:03:15.224726: Pseudo dice [0.9197, 0.8996, 0.9594] 
2024-11-01 23:03:15.224754: Epoch time: 56.83 s 
2024-11-01 23:03:15.689172:  
2024-11-01 23:03:15.689216: Epoch 101 
2024-11-01 23:03:15.689252: Current learning rate: 0.00628 
2024-11-01 23:04:12.517566: train_loss -0.9297 
2024-11-01 23:04:12.517643: val_loss -0.8872 
2024-11-01 23:04:12.517675: Pseudo dice [0.9214, 0.8988, 0.9574] 
2024-11-01 23:04:12.517704: Epoch time: 56.83 s 
2024-11-01 23:04:12.989602:  
2024-11-01 23:04:12.989647: Epoch 102 
2024-11-01 23:04:12.989684: Current learning rate: 0.00624 
2024-11-01 23:05:09.754958: train_loss -0.9315 
2024-11-01 23:05:09.755038: val_loss -0.8955 
2024-11-01 23:05:09.755073: Pseudo dice [0.9227, 0.9033, 0.9607] 
2024-11-01 23:05:09.755096: Epoch time: 56.77 s 
2024-11-01 23:05:09.755112: Yayy! New best EMA pseudo Dice: 0.9269 
2024-11-01 23:05:10.344864:  
2024-11-01 23:05:10.344913: Epoch 103 
2024-11-01 23:05:10.344955: Current learning rate: 0.0062 
2024-11-01 23:06:07.172477: train_loss -0.9326 
2024-11-01 23:06:07.172550: val_loss -0.891 
2024-11-01 23:06:07.172574: Pseudo dice [0.9185, 0.8987, 0.9614] 
2024-11-01 23:06:07.172596: Epoch time: 56.83 s 
2024-11-01 23:06:07.636340:  
2024-11-01 23:06:07.636398: Epoch 104 
2024-11-01 23:06:07.636433: Current learning rate: 0.00616 
2024-11-01 23:07:04.409714: train_loss -0.9327 
2024-11-01 23:07:04.409790: val_loss -0.8859 
2024-11-01 23:07:04.409827: Pseudo dice [0.92, 0.9023, 0.9591] 
2024-11-01 23:07:04.409856: Epoch time: 56.77 s 
2024-11-01 23:07:04.875326:  
2024-11-01 23:07:04.875417: Epoch 105 
2024-11-01 23:07:04.875458: Current learning rate: 0.00612 
2024-11-01 23:08:01.658597: train_loss -0.9328 
2024-11-01 23:08:01.658669: val_loss -0.891 
2024-11-01 23:08:01.658695: Pseudo dice [0.9198, 0.9002, 0.959] 
2024-11-01 23:08:01.658719: Epoch time: 56.78 s 
2024-11-01 23:08:02.123888:  
2024-11-01 23:08:02.123955: Epoch 106 
2024-11-01 23:08:02.123993: Current learning rate: 0.00609 
2024-11-01 23:08:58.908789: train_loss -0.9334 
2024-11-01 23:08:58.908860: val_loss -0.8939 
2024-11-01 23:08:58.908886: Pseudo dice [0.9197, 0.9018, 0.9604] 
2024-11-01 23:08:58.908910: Epoch time: 56.79 s 
2024-11-01 23:08:59.654162:  
2024-11-01 23:08:59.654224: Epoch 107 
2024-11-01 23:08:59.654261: Current learning rate: 0.00605 
2024-11-01 23:09:56.453408: train_loss -0.9334 
2024-11-01 23:09:56.453483: val_loss -0.8932 
2024-11-01 23:09:56.453515: Pseudo dice [0.9207, 0.9009, 0.9628] 
2024-11-01 23:09:56.453539: Epoch time: 56.8 s 
2024-11-01 23:09:56.453555: Yayy! New best EMA pseudo Dice: 0.927 
2024-11-01 23:09:57.046730:  
2024-11-01 23:09:57.046778: Epoch 108 
2024-11-01 23:09:57.046818: Current learning rate: 0.00601 
2024-11-01 23:10:53.880548: train_loss -0.9335 
2024-11-01 23:10:53.880626: val_loss -0.894 
2024-11-01 23:10:53.880651: Pseudo dice [0.917, 0.905, 0.9597] 
2024-11-01 23:10:53.880675: Epoch time: 56.83 s 
2024-11-01 23:10:53.880691: Yayy! New best EMA pseudo Dice: 0.927 
2024-11-01 23:10:54.472128:  
2024-11-01 23:10:54.472189: Epoch 109 
2024-11-01 23:10:54.472226: Current learning rate: 0.00597 
2024-11-01 23:11:51.282687: train_loss -0.9346 
2024-11-01 23:11:51.282760: val_loss -0.8908 
2024-11-01 23:11:51.282792: Pseudo dice [0.9231, 0.9018, 0.9588] 
2024-11-01 23:11:51.282830: Epoch time: 56.81 s 
2024-11-01 23:11:51.282849: Yayy! New best EMA pseudo Dice: 0.9271 
2024-11-01 23:11:51.876447:  
2024-11-01 23:11:51.876517: Epoch 110 
2024-11-01 23:11:51.876560: Current learning rate: 0.00593 
2024-11-01 23:12:48.678436: train_loss -0.9348 
2024-11-01 23:12:48.678509: val_loss -0.8881 
2024-11-01 23:12:48.678540: Pseudo dice [0.9144, 0.9025, 0.9581] 
2024-11-01 23:12:48.678567: Epoch time: 56.8 s 
2024-11-01 23:12:49.142165:  
2024-11-01 23:12:49.142281: Epoch 111 
2024-11-01 23:12:49.142319: Current learning rate: 0.0059 
2024-11-01 23:13:45.915508: train_loss -0.9334 
2024-11-01 23:13:45.915589: val_loss -0.8887 
2024-11-01 23:13:45.915620: Pseudo dice [0.9188, 0.8985, 0.9596] 
2024-11-01 23:13:45.915648: Epoch time: 56.77 s 
2024-11-01 23:13:46.377304:  
2024-11-01 23:13:46.377362: Epoch 112 
2024-11-01 23:13:46.377403: Current learning rate: 0.00586 
2024-11-01 23:14:43.220131: train_loss -0.9334 
2024-11-01 23:14:43.220204: val_loss -0.8947 
2024-11-01 23:14:43.220235: Pseudo dice [0.9278, 0.9045, 0.9595] 
2024-11-01 23:14:43.220261: Epoch time: 56.84 s 
2024-11-01 23:14:43.220277: Yayy! New best EMA pseudo Dice: 0.9271 
2024-11-01 23:14:43.811373:  
2024-11-01 23:14:43.811429: Epoch 113 
2024-11-01 23:14:43.811465: Current learning rate: 0.00582 
2024-11-01 23:15:40.642643: train_loss -0.9347 
2024-11-01 23:15:40.642722: val_loss -0.8935 
2024-11-01 23:15:40.642750: Pseudo dice [0.9246, 0.9007, 0.9607] 
2024-11-01 23:15:40.642773: Epoch time: 56.83 s 
2024-11-01 23:15:40.642788: Yayy! New best EMA pseudo Dice: 0.9273 
2024-11-01 23:15:41.233092:  
2024-11-01 23:15:41.233144: Epoch 114 
2024-11-01 23:15:41.233179: Current learning rate: 0.00578 
2024-11-01 23:16:38.025509: train_loss -0.9342 
2024-11-01 23:16:38.025575: val_loss -0.8982 
2024-11-01 23:16:38.025600: Pseudo dice [0.9288, 0.8988, 0.963] 
2024-11-01 23:16:38.025624: Epoch time: 56.79 s 
2024-11-01 23:16:38.025639: Yayy! New best EMA pseudo Dice: 0.9276 
2024-11-01 23:16:38.616359:  
2024-11-01 23:16:38.616448: Epoch 115 
2024-11-01 23:16:38.616486: Current learning rate: 0.00574 
2024-11-01 23:17:35.458611: train_loss -0.9348 
2024-11-01 23:17:35.458714: val_loss -0.8974 
2024-11-01 23:17:35.458758: Pseudo dice [0.9306, 0.8982, 0.961] 
2024-11-01 23:17:35.458787: Epoch time: 56.84 s 
2024-11-01 23:17:35.458806: Yayy! New best EMA pseudo Dice: 0.9278 
2024-11-01 23:17:36.054337:  
2024-11-01 23:17:36.054392: Epoch 116 
2024-11-01 23:17:36.054428: Current learning rate: 0.0057 
2024-11-01 23:18:32.825285: train_loss -0.9342 
2024-11-01 23:18:32.825362: val_loss -0.8931 
2024-11-01 23:18:32.825387: Pseudo dice [0.9258, 0.8993, 0.9615] 
2024-11-01 23:18:32.825409: Epoch time: 56.77 s 
2024-11-01 23:18:32.825424: Yayy! New best EMA pseudo Dice: 0.9279 
2024-11-01 23:18:33.421172:  
2024-11-01 23:18:33.421221: Epoch 117 
2024-11-01 23:18:33.421256: Current learning rate: 0.00567 
2024-11-01 23:19:30.705940: train_loss -0.935 
2024-11-01 23:19:30.706020: val_loss -0.897 
2024-11-01 23:19:30.706051: Pseudo dice [0.9257, 0.9033, 0.9605] 
2024-11-01 23:19:30.706080: Epoch time: 57.29 s 
2024-11-01 23:19:30.706100: Yayy! New best EMA pseudo Dice: 0.9281 
2024-11-01 23:19:31.303143:  
2024-11-01 23:19:31.303193: Epoch 118 
2024-11-01 23:19:31.303229: Current learning rate: 0.00563 
2024-11-01 23:20:28.323603: train_loss -0.9354 
2024-11-01 23:20:28.323680: val_loss -0.8916 
2024-11-01 23:20:28.323716: Pseudo dice [0.9211, 0.9023, 0.9613] 
2024-11-01 23:20:28.323746: Epoch time: 57.02 s 
2024-11-01 23:20:28.323768: Yayy! New best EMA pseudo Dice: 0.9281 
2024-11-01 23:20:28.919247:  
2024-11-01 23:20:28.919300: Epoch 119 
2024-11-01 23:20:28.919342: Current learning rate: 0.00559 
2024-11-01 23:21:25.927677: train_loss -0.9349 
2024-11-01 23:21:25.927752: val_loss -0.8895 
2024-11-01 23:21:25.927777: Pseudo dice [0.9189, 0.9005, 0.9576] 
2024-11-01 23:21:25.927800: Epoch time: 57.01 s 
2024-11-01 23:21:26.395838:  
2024-11-01 23:21:26.395921: Epoch 120 
2024-11-01 23:21:26.395957: Current learning rate: 0.00555 
2024-11-01 23:22:23.447152: train_loss -0.9355 
2024-11-01 23:22:23.447239: val_loss -0.8899 
2024-11-01 23:22:23.447271: Pseudo dice [0.9201, 0.9, 0.9591] 
2024-11-01 23:22:23.447303: Epoch time: 57.05 s 
2024-11-01 23:22:23.916308:  
2024-11-01 23:22:23.916353: Epoch 121 
2024-11-01 23:22:23.916389: Current learning rate: 0.00551 
2024-11-01 23:23:20.978632: train_loss -0.9356 
2024-11-01 23:23:20.978705: val_loss -0.8922 
2024-11-01 23:23:20.978735: Pseudo dice [0.9186, 0.9035, 0.9611] 
2024-11-01 23:23:20.978763: Epoch time: 57.06 s 
2024-11-01 23:23:21.448333:  
2024-11-01 23:23:21.448378: Epoch 122 
2024-11-01 23:23:21.448415: Current learning rate: 0.00547 
2024-11-01 23:24:18.505201: train_loss -0.9366 
2024-11-01 23:24:18.505284: val_loss -0.8939 
2024-11-01 23:24:18.505317: Pseudo dice [0.9225, 0.904, 0.9617] 
2024-11-01 23:24:18.505346: Epoch time: 57.06 s 
2024-11-01 23:24:18.972649:  
2024-11-01 23:24:18.972692: Epoch 123 
2024-11-01 23:24:18.972728: Current learning rate: 0.00544 
2024-11-01 23:25:16.031578: train_loss -0.9373 
2024-11-01 23:25:16.031690: val_loss -0.8904 
2024-11-01 23:25:16.031722: Pseudo dice [0.9194, 0.8981, 0.9591] 
2024-11-01 23:25:16.031749: Epoch time: 57.06 s 
2024-11-01 23:25:16.497612:  
2024-11-01 23:25:16.497655: Epoch 124 
2024-11-01 23:25:16.497689: Current learning rate: 0.0054 
2024-11-01 23:26:13.556388: train_loss -0.9378 
2024-11-01 23:26:13.556464: val_loss -0.8949 
2024-11-01 23:26:13.556496: Pseudo dice [0.9275, 0.9045, 0.9571] 
2024-11-01 23:26:13.556518: Epoch time: 57.06 s 
2024-11-01 23:26:14.025036:  
2024-11-01 23:26:14.025081: Epoch 125 
2024-11-01 23:26:14.025116: Current learning rate: 0.00536 
2024-11-01 23:27:11.081167: train_loss -0.9378 
2024-11-01 23:27:11.081244: val_loss -0.8887 
2024-11-01 23:27:11.081291: Pseudo dice [0.9251, 0.8991, 0.9572] 
2024-11-01 23:27:11.081330: Epoch time: 57.06 s 
2024-11-01 23:27:11.826477:  
2024-11-01 23:27:11.826531: Epoch 126 
2024-11-01 23:27:11.826572: Current learning rate: 0.00532 
2024-11-01 23:28:08.873243: train_loss -0.9363 
2024-11-01 23:28:08.873322: val_loss -0.8933 
2024-11-01 23:28:08.873352: Pseudo dice [0.9226, 0.9, 0.9606] 
2024-11-01 23:28:08.873375: Epoch time: 57.05 s 
2024-11-01 23:28:09.340897:  
2024-11-01 23:28:09.340954: Epoch 127 
2024-11-01 23:28:09.340992: Current learning rate: 0.00528 
2024-11-01 23:29:06.424634: train_loss -0.9373 
2024-11-01 23:29:06.424719: val_loss -0.8891 
2024-11-01 23:29:06.424752: Pseudo dice [0.9188, 0.8997, 0.9583] 
2024-11-01 23:29:06.424778: Epoch time: 57.08 s 
2024-11-01 23:29:06.895301:  
2024-11-01 23:29:06.895343: Epoch 128 
2024-11-01 23:29:06.895388: Current learning rate: 0.00524 
2024-11-01 23:30:03.977799: train_loss -0.937 
2024-11-01 23:30:03.977879: val_loss -0.8916 
2024-11-01 23:30:03.977904: Pseudo dice [0.9176, 0.9047, 0.9604] 
2024-11-01 23:30:03.977927: Epoch time: 57.08 s 
2024-11-01 23:30:04.449898:  
2024-11-01 23:30:04.449970: Epoch 129 
2024-11-01 23:30:04.450011: Current learning rate: 0.0052 
2024-11-01 23:31:01.517478: train_loss -0.9381 
2024-11-01 23:31:01.517553: val_loss -0.8966 
2024-11-01 23:31:01.517583: Pseudo dice [0.9203, 0.9047, 0.9616] 
2024-11-01 23:31:01.517610: Epoch time: 57.07 s 
2024-11-01 23:31:01.986618:  
2024-11-01 23:31:01.986677: Epoch 130 
2024-11-01 23:31:01.986713: Current learning rate: 0.00517 
2024-11-01 23:31:59.056689: train_loss -0.9378 
2024-11-01 23:31:59.056771: val_loss -0.8908 
2024-11-01 23:31:59.056803: Pseudo dice [0.9232, 0.8979, 0.9607] 
2024-11-01 23:31:59.056838: Epoch time: 57.07 s 
2024-11-01 23:31:59.528122:  
2024-11-01 23:31:59.528190: Epoch 131 
2024-11-01 23:31:59.528228: Current learning rate: 0.00513 
2024-11-01 23:32:56.595986: train_loss -0.9366 
2024-11-01 23:32:56.596067: val_loss -0.8945 
2024-11-01 23:32:56.596101: Pseudo dice [0.9215, 0.9016, 0.96] 
2024-11-01 23:32:56.596131: Epoch time: 57.07 s 
2024-11-01 23:32:57.069804:  
2024-11-01 23:32:57.069895: Epoch 132 
2024-11-01 23:32:57.069932: Current learning rate: 0.00509 
2024-11-01 23:33:54.134590: train_loss -0.9377 
2024-11-01 23:33:54.134670: val_loss -0.8872 
2024-11-01 23:33:54.134696: Pseudo dice [0.9194, 0.8943, 0.9577] 
2024-11-01 23:33:54.134720: Epoch time: 57.07 s 
2024-11-01 23:33:54.610015:  
2024-11-01 23:33:54.610070: Epoch 133 
2024-11-01 23:33:54.610110: Current learning rate: 0.00505 
2024-11-01 23:34:51.693025: train_loss -0.9374 
2024-11-01 23:34:51.693104: val_loss -0.8935 
2024-11-01 23:34:51.693135: Pseudo dice [0.9215, 0.8999, 0.9628] 
2024-11-01 23:34:51.693164: Epoch time: 57.08 s 
2024-11-01 23:34:52.166789:  
2024-11-01 23:34:52.166842: Epoch 134 
2024-11-01 23:34:52.166876: Current learning rate: 0.00501 
2024-11-01 23:35:49.530580: train_loss -0.938 
2024-11-01 23:35:49.530660: val_loss -0.893 
2024-11-01 23:35:49.530712: Pseudo dice [0.9216, 0.9011, 0.9619] 
2024-11-01 23:35:49.530740: Epoch time: 57.36 s 
2024-11-01 23:35:50.008802:  
2024-11-01 23:35:50.008862: Epoch 135 
2024-11-01 23:35:50.008898: Current learning rate: 0.00497 
2024-11-01 23:36:47.115105: train_loss -0.9381 
2024-11-01 23:36:47.115187: val_loss -0.888 
2024-11-01 23:36:47.115221: Pseudo dice [0.9195, 0.9026, 0.9571] 
2024-11-01 23:36:47.115251: Epoch time: 57.11 s 
2024-11-01 23:36:47.591961:  
2024-11-01 23:36:47.592022: Epoch 136 
2024-11-01 23:36:47.592059: Current learning rate: 0.00493 
2024-11-01 23:37:44.662467: train_loss -0.9377 
2024-11-01 23:37:44.662552: val_loss -0.8966 
2024-11-01 23:37:44.662584: Pseudo dice [0.931, 0.903, 0.9598] 
2024-11-01 23:37:44.662613: Epoch time: 57.07 s 
2024-11-01 23:37:45.148614:  
2024-11-01 23:37:45.148694: Epoch 137 
2024-11-01 23:37:45.148732: Current learning rate: 0.00489 
2024-11-01 23:38:42.224971: train_loss -0.9388 
2024-11-01 23:38:42.225048: val_loss -0.8906 
2024-11-01 23:38:42.225080: Pseudo dice [0.9206, 0.9007, 0.9585] 
2024-11-01 23:38:42.225112: Epoch time: 57.08 s 
2024-11-01 23:38:42.703701:  
2024-11-01 23:38:42.703749: Epoch 138 
2024-11-01 23:38:42.703784: Current learning rate: 0.00485 
2024-11-01 23:39:39.779769: train_loss -0.938 
2024-11-01 23:39:39.779846: val_loss -0.8885 
2024-11-01 23:39:39.779877: Pseudo dice [0.9202, 0.9003, 0.9577] 
2024-11-01 23:39:39.779904: Epoch time: 57.08 s 
2024-11-01 23:39:40.258040:  
2024-11-01 23:39:40.258089: Epoch 139 
2024-11-01 23:39:40.258132: Current learning rate: 0.00482 
2024-11-01 23:40:37.332860: train_loss -0.9397 
2024-11-01 23:40:37.332992: val_loss -0.8912 
2024-11-01 23:40:37.333018: Pseudo dice [0.9223, 0.9006, 0.9595] 
2024-11-01 23:40:37.333041: Epoch time: 57.08 s 
2024-11-01 23:40:37.810129:  
2024-11-01 23:40:37.810199: Epoch 140 
2024-11-01 23:40:37.810238: Current learning rate: 0.00478 
2024-11-01 23:41:34.884491: train_loss -0.9397 
2024-11-01 23:41:34.884567: val_loss -0.8964 
2024-11-01 23:41:34.884591: Pseudo dice [0.9268, 0.9052, 0.9598] 
2024-11-01 23:41:34.884614: Epoch time: 57.07 s 
2024-11-01 23:41:35.364397:  
2024-11-01 23:41:35.364445: Epoch 141 
2024-11-01 23:41:35.364483: Current learning rate: 0.00474 
2024-11-01 23:42:32.430344: train_loss -0.9389 
2024-11-01 23:42:32.430417: val_loss -0.892 
2024-11-01 23:42:32.430450: Pseudo dice [0.9206, 0.9006, 0.9575] 
2024-11-01 23:42:32.430478: Epoch time: 57.07 s 
2024-11-01 23:42:32.906611:  
2024-11-01 23:42:32.906656: Epoch 142 
2024-11-01 23:42:32.906690: Current learning rate: 0.0047 
2024-11-01 23:43:29.983305: train_loss -0.9396 
2024-11-01 23:43:29.983388: val_loss -0.8956 
2024-11-01 23:43:29.983417: Pseudo dice [0.9241, 0.9027, 0.9607] 
2024-11-01 23:43:29.983440: Epoch time: 57.08 s 
2024-11-01 23:43:30.459522:  
2024-11-01 23:43:30.459566: Epoch 143 
2024-11-01 23:43:30.459602: Current learning rate: 0.00466 
2024-11-01 23:44:27.552422: train_loss -0.9395 
2024-11-01 23:44:27.552496: val_loss -0.8944 
2024-11-01 23:44:27.552543: Pseudo dice [0.9261, 0.8988, 0.959] 
2024-11-01 23:44:27.552570: Epoch time: 57.09 s 
2024-11-01 23:44:28.027081:  
2024-11-01 23:44:28.027129: Epoch 144 
2024-11-01 23:44:28.027164: Current learning rate: 0.00462 
2024-11-01 23:45:25.101349: train_loss -0.94 
2024-11-01 23:45:25.101422: val_loss -0.8955 
2024-11-01 23:45:25.101470: Pseudo dice [0.9255, 0.8998, 0.9609] 
2024-11-01 23:45:25.101498: Epoch time: 57.07 s 
2024-11-01 23:45:25.859919:  
2024-11-01 23:45:25.860003: Epoch 145 
2024-11-01 23:45:25.860058: Current learning rate: 0.00458 
2024-11-01 23:46:22.959936: train_loss -0.9403 
2024-11-01 23:46:22.960018: val_loss -0.8896 
2024-11-01 23:46:22.960052: Pseudo dice [0.9179, 0.9036, 0.9594] 
2024-11-01 23:46:22.960081: Epoch time: 57.1 s 
2024-11-01 23:46:23.438785:  
2024-11-01 23:46:23.438862: Epoch 146 
2024-11-01 23:46:23.438899: Current learning rate: 0.00454 
2024-11-01 23:47:20.545747: train_loss -0.9401 
2024-11-01 23:47:20.545829: val_loss -0.8891 
2024-11-01 23:47:20.545859: Pseudo dice [0.9176, 0.8999, 0.9578] 
2024-11-01 23:47:20.545883: Epoch time: 57.11 s 
2024-11-01 23:47:21.023587:  
2024-11-01 23:47:21.023664: Epoch 147 
2024-11-01 23:47:21.023706: Current learning rate: 0.0045 
2024-11-01 23:48:18.119585: train_loss -0.9397 
2024-11-01 23:48:18.119666: val_loss -0.8999 
2024-11-01 23:48:18.119699: Pseudo dice [0.932, 0.901, 0.9606] 
2024-11-01 23:48:18.119728: Epoch time: 57.1 s 
2024-11-01 23:48:18.598802:  
2024-11-01 23:48:18.598859: Epoch 148 
2024-11-01 23:48:18.598896: Current learning rate: 0.00446 
2024-11-01 23:49:15.698013: train_loss -0.9395 
2024-11-01 23:49:15.698089: val_loss -0.8906 
2024-11-01 23:49:15.698114: Pseudo dice [0.9176, 0.901, 0.9588] 
2024-11-01 23:49:15.698138: Epoch time: 57.1 s 
2024-11-01 23:49:16.177467:  
2024-11-01 23:49:16.177536: Epoch 149 
2024-11-01 23:49:16.177572: Current learning rate: 0.00442 
2024-11-01 23:50:13.276279: train_loss -0.941 
2024-11-01 23:50:13.276358: val_loss -0.8967 
2024-11-01 23:50:13.276390: Pseudo dice [0.9271, 0.9031, 0.9615] 
2024-11-01 23:50:13.276417: Epoch time: 57.1 s 
2024-11-01 23:50:13.877562:  
2024-11-01 23:50:13.877625: Epoch 150 
2024-11-01 23:50:13.877709: Current learning rate: 0.00438 
2024-11-01 23:51:10.819904: train_loss -0.9407 
2024-11-01 23:51:10.819978: val_loss -0.8954 
2024-11-01 23:51:10.820021: Pseudo dice [0.9248, 0.9038, 0.9618] 
2024-11-01 23:51:10.820051: Epoch time: 56.94 s 
2024-11-01 23:51:10.820067: Yayy! New best EMA pseudo Dice: 0.9282 
2024-11-01 23:51:11.426944:  
2024-11-01 23:51:11.426998: Epoch 151 
2024-11-01 23:51:11.427034: Current learning rate: 0.00434 
2024-11-01 23:52:08.285477: train_loss -0.9396 
2024-11-01 23:52:08.285545: val_loss -0.8924 
2024-11-01 23:52:08.285575: Pseudo dice [0.9236, 0.9002, 0.9598] 
2024-11-01 23:52:08.285598: Epoch time: 56.86 s 
2024-11-01 23:52:08.766191:  
2024-11-01 23:52:08.766248: Epoch 152 
2024-11-01 23:52:08.766283: Current learning rate: 0.0043 
2024-11-01 23:53:05.629001: train_loss -0.9378 
2024-11-01 23:53:05.629082: val_loss -0.8914 
2024-11-01 23:53:05.629114: Pseudo dice [0.9222, 0.9004, 0.9598] 
2024-11-01 23:53:05.629136: Epoch time: 56.86 s 
2024-11-01 23:53:06.110064:  
2024-11-01 23:53:06.110171: Epoch 153 
2024-11-01 23:53:06.110207: Current learning rate: 0.00427 
2024-11-01 23:54:02.931425: train_loss -0.9401 
2024-11-01 23:54:02.931503: val_loss -0.8925 
2024-11-01 23:54:02.931528: Pseudo dice [0.9215, 0.9033, 0.9605] 
2024-11-01 23:54:02.931551: Epoch time: 56.82 s 
2024-11-01 23:54:03.418926:  
2024-11-01 23:54:03.418998: Epoch 154 
2024-11-01 23:54:03.419040: Current learning rate: 0.00423 
2024-11-01 23:55:00.274723: train_loss -0.941 
2024-11-01 23:55:00.274802: val_loss -0.9015 
2024-11-01 23:55:00.274832: Pseudo dice [0.9318, 0.9054, 0.9655] 
2024-11-01 23:55:00.274854: Epoch time: 56.86 s 
2024-11-01 23:55:00.274870: Yayy! New best EMA pseudo Dice: 0.9287 
2024-11-01 23:55:00.888368:  
2024-11-01 23:55:00.888465: Epoch 155 
2024-11-01 23:55:00.888502: Current learning rate: 0.00419 
2024-11-01 23:55:57.704255: train_loss -0.9403 
2024-11-01 23:55:57.704336: val_loss -0.8919 
2024-11-01 23:55:57.704369: Pseudo dice [0.9236, 0.8992, 0.9598] 
2024-11-01 23:55:57.704397: Epoch time: 56.82 s 
2024-11-01 23:55:58.200671:  
2024-11-01 23:55:58.200759: Epoch 156 
2024-11-01 23:55:58.200803: Current learning rate: 0.00415 
2024-11-01 23:56:55.047079: train_loss -0.9415 
2024-11-01 23:56:55.047153: val_loss -0.884 
2024-11-01 23:56:55.047189: Pseudo dice [0.9101, 0.9015, 0.9595] 
2024-11-01 23:56:55.047217: Epoch time: 56.85 s 
2024-11-01 23:56:55.533535:  
2024-11-01 23:56:55.533598: Epoch 157 
2024-11-01 23:56:55.533634: Current learning rate: 0.00411 
2024-11-01 23:57:52.382595: train_loss -0.9408 
2024-11-01 23:57:52.382676: val_loss -0.8948 
2024-11-01 23:57:52.382709: Pseudo dice [0.9233, 0.9043, 0.9618] 
2024-11-01 23:57:52.382737: Epoch time: 56.85 s 
2024-11-01 23:57:52.870338:  
2024-11-01 23:57:52.870388: Epoch 158 
2024-11-01 23:57:52.870427: Current learning rate: 0.00407 
2024-11-01 23:58:49.713105: train_loss -0.9416 
2024-11-01 23:58:49.713235: val_loss -0.8953 
2024-11-01 23:58:49.713268: Pseudo dice [0.9268, 0.9016, 0.9614] 
2024-11-01 23:58:49.713296: Epoch time: 56.84 s 
2024-11-01 23:58:50.201270:  
2024-11-01 23:58:50.201347: Epoch 159 
2024-11-01 23:58:50.201387: Current learning rate: 0.00403 
2024-11-01 23:59:47.049594: train_loss -0.9419 
2024-11-01 23:59:47.049670: val_loss -0.8886 
2024-11-01 23:59:47.049698: Pseudo dice [0.9205, 0.8947, 0.9588] 
2024-11-01 23:59:47.049722: Epoch time: 56.85 s 
2024-11-01 23:59:47.539091:  
2024-11-01 23:59:47.539140: Epoch 160 
2024-11-01 23:59:47.539179: Current learning rate: 0.00399 
2024-11-02 00:00:44.390265: train_loss -0.9426 
2024-11-02 00:00:44.390340: val_loss -0.8913 
2024-11-02 00:00:44.390365: Pseudo dice [0.9203, 0.9022, 0.9595] 
2024-11-02 00:00:44.390387: Epoch time: 56.85 s 
2024-11-02 00:00:44.877150:  
2024-11-02 00:00:44.877235: Epoch 161 
2024-11-02 00:00:44.877279: Current learning rate: 0.00395 
2024-11-02 00:01:41.745791: train_loss -0.9427 
2024-11-02 00:01:41.745871: val_loss -0.889 
2024-11-02 00:01:41.745904: Pseudo dice [0.9179, 0.9018, 0.9598] 
2024-11-02 00:01:41.745933: Epoch time: 56.87 s 
2024-11-02 00:01:42.235789:  
2024-11-02 00:01:42.235847: Epoch 162 
2024-11-02 00:01:42.235886: Current learning rate: 0.00391 
2024-11-02 00:02:39.106054: train_loss -0.9423 
2024-11-02 00:02:39.106134: val_loss -0.8859 
2024-11-02 00:02:39.106166: Pseudo dice [0.917, 0.8988, 0.9592] 
2024-11-02 00:02:39.106194: Epoch time: 56.87 s 
2024-11-02 00:02:39.592468:  
2024-11-02 00:02:39.592513: Epoch 163 
2024-11-02 00:02:39.592548: Current learning rate: 0.00387 
2024-11-02 00:03:36.456321: train_loss -0.9428 
2024-11-02 00:03:36.456400: val_loss -0.8905 
2024-11-02 00:03:36.456430: Pseudo dice [0.9232, 0.8989, 0.9593] 
2024-11-02 00:03:36.456457: Epoch time: 56.86 s 
2024-11-02 00:03:37.227019:  
2024-11-02 00:03:37.227070: Epoch 164 
2024-11-02 00:03:37.227114: Current learning rate: 0.00383 
2024-11-02 00:04:34.106278: train_loss -0.9427 
2024-11-02 00:04:34.106354: val_loss -0.8973 
2024-11-02 00:04:34.106384: Pseudo dice [0.9241, 0.9044, 0.9617] 
2024-11-02 00:04:34.106407: Epoch time: 56.88 s 
2024-11-02 00:04:34.577641:  
2024-11-02 00:04:34.577705: Epoch 165 
2024-11-02 00:04:34.577742: Current learning rate: 0.00379 
2024-11-02 00:05:31.462945: train_loss -0.9428 
2024-11-02 00:05:31.463023: val_loss -0.8935 
2024-11-02 00:05:31.463055: Pseudo dice [0.925, 0.8977, 0.9605] 
2024-11-02 00:05:31.463084: Epoch time: 56.89 s 
2024-11-02 00:05:31.935708:  
2024-11-02 00:05:31.935769: Epoch 166 
2024-11-02 00:05:31.935806: Current learning rate: 0.00375 
2024-11-02 00:06:28.806195: train_loss -0.9426 
2024-11-02 00:06:28.806268: val_loss -0.8934 
2024-11-02 00:06:28.806295: Pseudo dice [0.9204, 0.9033, 0.9604] 
2024-11-02 00:06:28.806317: Epoch time: 56.87 s 
2024-11-02 00:06:29.283884:  
2024-11-02 00:06:29.283959: Epoch 167 
2024-11-02 00:06:29.283996: Current learning rate: 0.00371 
2024-11-02 00:07:26.148751: train_loss -0.9435 
2024-11-02 00:07:26.148832: val_loss -0.8911 
2024-11-02 00:07:26.148862: Pseudo dice [0.9218, 0.9023, 0.96] 
2024-11-02 00:07:26.148890: Epoch time: 56.87 s 
2024-11-02 00:07:26.628041:  
2024-11-02 00:07:26.628117: Epoch 168 
2024-11-02 00:07:26.628155: Current learning rate: 0.00367 
2024-11-02 00:08:23.479822: train_loss -0.9442 
2024-11-02 00:08:23.479912: val_loss -0.8917 
2024-11-02 00:08:23.479940: Pseudo dice [0.9247, 0.9039, 0.958] 
2024-11-02 00:08:23.479963: Epoch time: 56.85 s 
2024-11-02 00:08:23.961989:  
2024-11-02 00:08:23.962051: Epoch 169 
2024-11-02 00:08:23.962092: Current learning rate: 0.00363 
2024-11-02 00:09:20.835146: train_loss -0.9436 
2024-11-02 00:09:20.835222: val_loss -0.8971 
2024-11-02 00:09:20.835254: Pseudo dice [0.926, 0.9041, 0.9614] 
2024-11-02 00:09:20.835276: Epoch time: 56.87 s 
2024-11-02 00:09:21.320724:  
2024-11-02 00:09:21.320791: Epoch 170 
2024-11-02 00:09:21.320829: Current learning rate: 0.00359 
2024-11-02 00:10:18.197973: train_loss -0.9437 
2024-11-02 00:10:18.198053: val_loss -0.8977 
2024-11-02 00:10:18.198085: Pseudo dice [0.9191, 0.9057, 0.9625] 
2024-11-02 00:10:18.198117: Epoch time: 56.88 s 
2024-11-02 00:10:18.685139:  
2024-11-02 00:10:18.685195: Epoch 171 
2024-11-02 00:10:18.685234: Current learning rate: 0.00355 
2024-11-02 00:11:15.550174: train_loss -0.9447 
2024-11-02 00:11:15.550251: val_loss -0.8955 
2024-11-02 00:11:15.550283: Pseudo dice [0.9217, 0.9047, 0.9589] 
2024-11-02 00:11:15.550311: Epoch time: 56.87 s 
2024-11-02 00:11:16.031743:  
2024-11-02 00:11:16.031790: Epoch 172 
2024-11-02 00:11:16.031824: Current learning rate: 0.00351 
2024-11-02 00:12:12.889865: train_loss -0.9436 
2024-11-02 00:12:12.889930: val_loss -0.893 
2024-11-02 00:12:12.890011: Pseudo dice [0.9202, 0.9057, 0.9581] 
2024-11-02 00:12:12.890033: Epoch time: 56.86 s 
2024-11-02 00:12:13.373039:  
2024-11-02 00:12:13.373093: Epoch 173 
2024-11-02 00:12:13.373134: Current learning rate: 0.00346 
2024-11-02 00:13:10.239743: train_loss -0.9443 
2024-11-02 00:13:10.239826: val_loss -0.8905 
2024-11-02 00:13:10.239859: Pseudo dice [0.9167, 0.9036, 0.9604] 
2024-11-02 00:13:10.239885: Epoch time: 56.87 s 
2024-11-02 00:13:10.721001:  
2024-11-02 00:13:10.721077: Epoch 174 
2024-11-02 00:13:10.721119: Current learning rate: 0.00342 
2024-11-02 00:14:07.583045: train_loss -0.9438 
2024-11-02 00:14:07.583127: val_loss -0.8963 
2024-11-02 00:14:07.583160: Pseudo dice [0.9221, 0.9024, 0.963] 
2024-11-02 00:14:07.583187: Epoch time: 56.86 s 
2024-11-02 00:14:08.066821:  
2024-11-02 00:14:08.066870: Epoch 175 
2024-11-02 00:14:08.066905: Current learning rate: 0.00338 
2024-11-02 00:15:04.929142: train_loss -0.9434 
2024-11-02 00:15:04.929225: val_loss -0.9001 
2024-11-02 00:15:04.929256: Pseudo dice [0.9311, 0.9047, 0.9615] 
2024-11-02 00:15:04.929280: Epoch time: 56.86 s 
2024-11-02 00:15:05.408371:  
2024-11-02 00:15:05.408418: Epoch 176 
2024-11-02 00:15:05.408455: Current learning rate: 0.00334 
2024-11-02 00:16:02.262654: train_loss -0.9451 
2024-11-02 00:16:02.262733: val_loss -0.8986 
2024-11-02 00:16:02.262764: Pseudo dice [0.9321, 0.8999, 0.9639] 
2024-11-02 00:16:02.262794: Epoch time: 56.85 s 
2024-11-02 00:16:02.262818: Yayy! New best EMA pseudo Dice: 0.929 
2024-11-02 00:16:02.868786:  
2024-11-02 00:16:02.868838: Epoch 177 
2024-11-02 00:16:02.868880: Current learning rate: 0.0033 
2024-11-02 00:16:59.727658: train_loss -0.9453 
2024-11-02 00:16:59.727725: val_loss -0.8894 
2024-11-02 00:16:59.727750: Pseudo dice [0.9209, 0.8993, 0.9588] 
2024-11-02 00:16:59.727773: Epoch time: 56.86 s 
2024-11-02 00:17:00.209682:  
2024-11-02 00:17:00.209734: Epoch 178 
2024-11-02 00:17:00.209776: Current learning rate: 0.00326 
2024-11-02 00:17:57.061734: train_loss -0.9449 
2024-11-02 00:17:57.061825: val_loss -0.8905 
2024-11-02 00:17:57.061852: Pseudo dice [0.919, 0.8983, 0.9597] 
2024-11-02 00:17:57.061875: Epoch time: 56.85 s 
2024-11-02 00:17:57.542313:  
2024-11-02 00:17:57.542375: Epoch 179 
2024-11-02 00:17:57.542409: Current learning rate: 0.00322 
2024-11-02 00:18:54.400521: train_loss -0.9442 
2024-11-02 00:18:54.400600: val_loss -0.891 
2024-11-02 00:18:54.400630: Pseudo dice [0.9188, 0.8991, 0.9595] 
2024-11-02 00:18:54.400658: Epoch time: 56.86 s 
2024-11-02 00:18:54.882056:  
2024-11-02 00:18:54.882107: Epoch 180 
2024-11-02 00:18:54.882148: Current learning rate: 0.00318 
2024-11-02 00:19:51.730904: train_loss -0.9447 
2024-11-02 00:19:51.730997: val_loss -0.8927 
2024-11-02 00:19:51.731030: Pseudo dice [0.9212, 0.9059, 0.9613] 
2024-11-02 00:19:51.731058: Epoch time: 56.85 s 
2024-11-02 00:19:52.213881:  
2024-11-02 00:19:52.213929: Epoch 181 
2024-11-02 00:19:52.213966: Current learning rate: 0.00314 
2024-11-02 00:20:49.068255: train_loss -0.9448 
2024-11-02 00:20:49.068341: val_loss -0.8955 
2024-11-02 00:20:49.068379: Pseudo dice [0.9279, 0.9032, 0.9594] 
2024-11-02 00:20:49.068410: Epoch time: 56.85 s 
2024-11-02 00:20:49.547490:  
2024-11-02 00:20:49.547535: Epoch 182 
2024-11-02 00:20:49.547574: Current learning rate: 0.0031 
2024-11-02 00:21:46.404956: train_loss -0.9451 
2024-11-02 00:21:46.405035: val_loss -0.8862 
2024-11-02 00:21:46.405060: Pseudo dice [0.9152, 0.9028, 0.9573] 
2024-11-02 00:21:46.405082: Epoch time: 56.86 s 
2024-11-02 00:21:47.170687:  
2024-11-02 00:21:47.170754: Epoch 183 
2024-11-02 00:21:47.170800: Current learning rate: 0.00306 
2024-11-02 00:22:44.045844: train_loss -0.9459 
2024-11-02 00:22:44.045940: val_loss -0.8918 
2024-11-02 00:22:44.045967: Pseudo dice [0.924, 0.9017, 0.9576] 
2024-11-02 00:22:44.045990: Epoch time: 56.88 s 
2024-11-02 00:22:44.528788:  
2024-11-02 00:22:44.528845: Epoch 184 
2024-11-02 00:22:44.528881: Current learning rate: 0.00302 
2024-11-02 00:23:41.427986: train_loss -0.9452 
2024-11-02 00:23:41.428084: val_loss -0.8905 
2024-11-02 00:23:41.428112: Pseudo dice [0.9263, 0.8991, 0.9596] 
2024-11-02 00:23:41.428136: Epoch time: 56.9 s 
2024-11-02 00:23:41.917761:  
2024-11-02 00:23:41.917872: Epoch 185 
2024-11-02 00:23:41.917906: Current learning rate: 0.00297 
2024-11-02 00:24:38.796802: train_loss -0.9462 
2024-11-02 00:24:38.796891: val_loss -0.8945 
2024-11-02 00:24:38.796923: Pseudo dice [0.9231, 0.9009, 0.9591] 
2024-11-02 00:24:38.796952: Epoch time: 56.88 s 
2024-11-02 00:24:39.282391:  
2024-11-02 00:24:39.282470: Epoch 186 
2024-11-02 00:24:39.282509: Current learning rate: 0.00293 
2024-11-02 00:25:36.160232: train_loss -0.9461 
2024-11-02 00:25:36.160308: val_loss -0.8935 
2024-11-02 00:25:36.160354: Pseudo dice [0.9237, 0.9034, 0.9584] 
2024-11-02 00:25:36.160393: Epoch time: 56.88 s 
2024-11-02 00:25:36.642598:  
2024-11-02 00:25:36.642670: Epoch 187 
2024-11-02 00:25:36.642707: Current learning rate: 0.00289 
2024-11-02 00:26:33.517310: train_loss -0.9459 
2024-11-02 00:26:33.517392: val_loss -0.8928 
2024-11-02 00:26:33.517424: Pseudo dice [0.9222, 0.9005, 0.9615] 
2024-11-02 00:26:33.517453: Epoch time: 56.88 s 
2024-11-02 00:26:34.001314:  
2024-11-02 00:26:34.001378: Epoch 188 
2024-11-02 00:26:34.001417: Current learning rate: 0.00285 
2024-11-02 00:27:30.879047: train_loss -0.9454 
2024-11-02 00:27:30.879121: val_loss -0.8916 
2024-11-02 00:27:30.879146: Pseudo dice [0.9238, 0.9015, 0.9573] 
2024-11-02 00:27:30.879169: Epoch time: 56.88 s 
2024-11-02 00:27:31.362993:  
2024-11-02 00:27:31.363074: Epoch 189 
2024-11-02 00:27:31.363115: Current learning rate: 0.00281 
2024-11-02 00:28:28.232193: train_loss -0.9461 
2024-11-02 00:28:28.232267: val_loss -0.8871 
2024-11-02 00:28:28.232299: Pseudo dice [0.9218, 0.8992, 0.9589] 
2024-11-02 00:28:28.232332: Epoch time: 56.87 s 
2024-11-02 00:28:28.714352:  
2024-11-02 00:28:28.714405: Epoch 190 
2024-11-02 00:28:28.714439: Current learning rate: 0.00277 
2024-11-02 00:29:25.592108: train_loss -0.9454 
2024-11-02 00:29:25.592192: val_loss -0.8913 
2024-11-02 00:29:25.592225: Pseudo dice [0.9233, 0.9019, 0.9575] 
2024-11-02 00:29:25.592250: Epoch time: 56.88 s 
2024-11-02 00:29:26.076686:  
2024-11-02 00:29:26.076746: Epoch 191 
2024-11-02 00:29:26.076783: Current learning rate: 0.00273 
2024-11-02 00:30:22.942671: train_loss -0.9458 
2024-11-02 00:30:22.942740: val_loss -0.886 
2024-11-02 00:30:22.942765: Pseudo dice [0.9178, 0.8983, 0.9553] 
2024-11-02 00:30:22.942786: Epoch time: 56.87 s 
2024-11-02 00:30:23.432039:  
2024-11-02 00:30:23.432091: Epoch 192 
2024-11-02 00:30:23.432125: Current learning rate: 0.00268 
2024-11-02 00:31:20.295175: train_loss -0.9458 
2024-11-02 00:31:20.295256: val_loss -0.8923 
2024-11-02 00:31:20.295296: Pseudo dice [0.9269, 0.9005, 0.9602] 
2024-11-02 00:31:20.295319: Epoch time: 56.86 s 
2024-11-02 00:31:20.783878:  
2024-11-02 00:31:20.783929: Epoch 193 
2024-11-02 00:31:20.783972: Current learning rate: 0.00264 
2024-11-02 00:32:17.650017: train_loss -0.9461 
2024-11-02 00:32:17.650097: val_loss -0.8913 
2024-11-02 00:32:17.650129: Pseudo dice [0.9281, 0.8995, 0.9579] 
2024-11-02 00:32:17.650152: Epoch time: 56.87 s 
2024-11-02 00:32:18.137885:  
2024-11-02 00:32:18.137941: Epoch 194 
2024-11-02 00:32:18.137979: Current learning rate: 0.0026 
2024-11-02 00:33:14.999362: train_loss -0.9471 
2024-11-02 00:33:14.999445: val_loss -0.8934 
2024-11-02 00:33:14.999490: Pseudo dice [0.9235, 0.9005, 0.9594] 
2024-11-02 00:33:14.999524: Epoch time: 56.86 s 
2024-11-02 00:33:15.486578:  
2024-11-02 00:33:15.486653: Epoch 195 
2024-11-02 00:33:15.486692: Current learning rate: 0.00256 
2024-11-02 00:34:12.345684: train_loss -0.9466 
2024-11-02 00:34:12.345758: val_loss -0.8904 
2024-11-02 00:34:12.345790: Pseudo dice [0.9245, 0.9004, 0.9587] 
2024-11-02 00:34:12.345819: Epoch time: 56.86 s 
2024-11-02 00:34:12.834591:  
2024-11-02 00:34:12.834646: Epoch 196 
2024-11-02 00:34:12.834684: Current learning rate: 0.00252 
2024-11-02 00:35:09.726677: train_loss -0.9468 
2024-11-02 00:35:09.726755: val_loss -0.891 
2024-11-02 00:35:09.726786: Pseudo dice [0.9204, 0.9016, 0.9592] 
2024-11-02 00:35:09.726814: Epoch time: 56.89 s 
2024-11-02 00:35:10.223160:  
2024-11-02 00:35:10.223207: Epoch 197 
2024-11-02 00:35:10.223246: Current learning rate: 0.00248 
2024-11-02 00:36:07.075715: train_loss -0.9472 
2024-11-02 00:36:07.075786: val_loss -0.8909 
2024-11-02 00:36:07.075810: Pseudo dice [0.9229, 0.8986, 0.9581] 
2024-11-02 00:36:07.075833: Epoch time: 56.85 s 
2024-11-02 00:36:07.563243:  
2024-11-02 00:36:07.563291: Epoch 198 
2024-11-02 00:36:07.563330: Current learning rate: 0.00243 
2024-11-02 00:37:04.424005: train_loss -0.9467 
2024-11-02 00:37:04.424086: val_loss -0.8888 
2024-11-02 00:37:04.424120: Pseudo dice [0.9227, 0.8974, 0.9575] 
2024-11-02 00:37:04.424147: Epoch time: 56.86 s 
2024-11-02 00:37:04.912804:  
2024-11-02 00:37:04.912886: Epoch 199 
2024-11-02 00:37:04.912926: Current learning rate: 0.00239 
2024-11-02 00:38:01.780527: train_loss -0.9478 
2024-11-02 00:38:01.780615: val_loss -0.8946 
2024-11-02 00:38:01.780661: Pseudo dice [0.9176, 0.9059, 0.96] 
2024-11-02 00:38:01.780684: Epoch time: 56.87 s 
2024-11-02 00:38:02.394406:  
2024-11-02 00:38:02.394451: Epoch 200 
2024-11-02 00:38:02.394488: Current learning rate: 0.00235 
2024-11-02 00:38:59.244617: train_loss -0.9482 
2024-11-02 00:38:59.244693: val_loss -0.8951 
2024-11-02 00:38:59.244717: Pseudo dice [0.9282, 0.8997, 0.9623] 
2024-11-02 00:38:59.244740: Epoch time: 56.85 s 
2024-11-02 00:39:00.008855:  
2024-11-02 00:39:00.008912: Epoch 201 
2024-11-02 00:39:00.008955: Current learning rate: 0.00231 
2024-11-02 00:39:56.876366: train_loss -0.948 
2024-11-02 00:39:56.876450: val_loss -0.8918 
2024-11-02 00:39:56.876479: Pseudo dice [0.9201, 0.903, 0.9607] 
2024-11-02 00:39:56.876501: Epoch time: 56.87 s 
2024-11-02 00:39:57.366733:  
2024-11-02 00:39:57.366835: Epoch 202 
2024-11-02 00:39:57.366874: Current learning rate: 0.00226 
2024-11-02 00:40:54.252079: train_loss -0.9475 
2024-11-02 00:40:54.252154: val_loss -0.885 
2024-11-02 00:40:54.252188: Pseudo dice [0.9182, 0.8962, 0.9589] 
2024-11-02 00:40:54.252217: Epoch time: 56.89 s 
2024-11-02 00:40:54.743111:  
2024-11-02 00:40:54.743173: Epoch 203 
2024-11-02 00:40:54.743214: Current learning rate: 0.00222 
2024-11-02 00:41:51.618833: train_loss -0.9476 
2024-11-02 00:41:51.618906: val_loss -0.8822 
2024-11-02 00:41:51.618937: Pseudo dice [0.9154, 0.8975, 0.9533] 
2024-11-02 00:41:51.618967: Epoch time: 56.88 s 
2024-11-02 00:41:52.111208:  
2024-11-02 00:41:52.111290: Epoch 204 
2024-11-02 00:41:52.111326: Current learning rate: 0.00218 
2024-11-02 00:42:48.988474: train_loss -0.9481 
2024-11-02 00:42:48.988554: val_loss -0.8907 
2024-11-02 00:42:48.988581: Pseudo dice [0.9293, 0.8998, 0.958] 
2024-11-02 00:42:48.988614: Epoch time: 56.88 s 
2024-11-02 00:42:49.479830:  
2024-11-02 00:42:49.479900: Epoch 205 
2024-11-02 00:42:49.479935: Current learning rate: 0.00214 
2024-11-02 00:43:46.384768: train_loss -0.9482 
2024-11-02 00:43:46.384845: val_loss -0.8992 
2024-11-02 00:43:46.384877: Pseudo dice [0.9291, 0.9022, 0.9642] 
2024-11-02 00:43:46.384905: Epoch time: 56.91 s 
2024-11-02 00:43:46.845429:  
2024-11-02 00:43:46.845489: Epoch 206 
2024-11-02 00:43:46.845525: Current learning rate: 0.00209 
2024-11-02 00:44:43.687217: train_loss -0.9474 
2024-11-02 00:44:43.687294: val_loss -0.8885 
2024-11-02 00:44:43.687325: Pseudo dice [0.9245, 0.9005, 0.9556] 
2024-11-02 00:44:43.687358: Epoch time: 56.84 s 
2024-11-02 00:44:44.149535:  
2024-11-02 00:44:44.149590: Epoch 207 
2024-11-02 00:44:44.149629: Current learning rate: 0.00205 
2024-11-02 00:45:41.034887: train_loss -0.9483 
2024-11-02 00:45:41.034963: val_loss -0.8876 
2024-11-02 00:45:41.034990: Pseudo dice [0.9177, 0.9023, 0.9591] 
2024-11-02 00:45:41.035013: Epoch time: 56.89 s 
2024-11-02 00:45:41.497944:  
2024-11-02 00:45:41.498010: Epoch 208 
2024-11-02 00:45:41.498046: Current learning rate: 0.00201 
2024-11-02 00:46:38.363801: train_loss -0.9486 
2024-11-02 00:46:38.363877: val_loss -0.8934 
2024-11-02 00:46:38.363902: Pseudo dice [0.9205, 0.9038, 0.9615] 
2024-11-02 00:46:38.363929: Epoch time: 56.87 s 
2024-11-02 00:46:38.824786:  
2024-11-02 00:46:38.824843: Epoch 209 
2024-11-02 00:46:38.824886: Current learning rate: 0.00196 
2024-11-02 00:47:35.703146: train_loss -0.9494 
2024-11-02 00:47:35.703227: val_loss -0.8958 
2024-11-02 00:47:35.703256: Pseudo dice [0.9291, 0.9015, 0.9621] 
2024-11-02 00:47:35.703280: Epoch time: 56.88 s 
2024-11-02 00:47:36.161724:  
2024-11-02 00:47:36.161783: Epoch 210 
2024-11-02 00:47:36.161820: Current learning rate: 0.00192 
2024-11-02 00:48:33.036849: train_loss -0.9493 
2024-11-02 00:48:33.036920: val_loss -0.8978 
2024-11-02 00:48:33.036948: Pseudo dice [0.9294, 0.9022, 0.961] 
2024-11-02 00:48:33.036972: Epoch time: 56.88 s 
2024-11-02 00:48:33.494366:  
2024-11-02 00:48:33.494417: Epoch 211 
2024-11-02 00:48:33.494454: Current learning rate: 0.00188 
2024-11-02 00:49:30.365252: train_loss -0.9497 
2024-11-02 00:49:30.365332: val_loss -0.8846 
2024-11-02 00:49:30.365364: Pseudo dice [0.9208, 0.8981, 0.9578] 
2024-11-02 00:49:30.365392: Epoch time: 56.87 s 
2024-11-02 00:49:30.825594:  
2024-11-02 00:49:30.825667: Epoch 212 
2024-11-02 00:49:30.825711: Current learning rate: 0.00184 
2024-11-02 00:50:27.718592: train_loss -0.9491 
2024-11-02 00:50:27.718675: val_loss -0.8868 
2024-11-02 00:50:27.718701: Pseudo dice [0.9177, 0.8977, 0.956] 
2024-11-02 00:50:27.718723: Epoch time: 56.89 s 
2024-11-02 00:50:28.174141:  
2024-11-02 00:50:28.174190: Epoch 213 
2024-11-02 00:50:28.174226: Current learning rate: 0.00179 
2024-11-02 00:51:25.040215: train_loss -0.9497 
2024-11-02 00:51:25.040292: val_loss -0.8964 
2024-11-02 00:51:25.040319: Pseudo dice [0.9272, 0.9053, 0.9633] 
2024-11-02 00:51:25.040344: Epoch time: 56.87 s 
2024-11-02 00:51:25.495057:  
2024-11-02 00:51:25.495123: Epoch 214 
2024-11-02 00:51:25.495164: Current learning rate: 0.00175 
2024-11-02 00:52:22.387982: train_loss -0.9489 
2024-11-02 00:52:22.388057: val_loss -0.8991 
2024-11-02 00:52:22.388095: Pseudo dice [0.93, 0.9059, 0.9628] 
2024-11-02 00:52:22.388125: Epoch time: 56.89 s 
2024-11-02 00:52:22.841173:  
2024-11-02 00:52:22.841218: Epoch 215 
2024-11-02 00:52:22.841254: Current learning rate: 0.0017 
2024-11-02 00:53:19.744983: train_loss -0.9494 
2024-11-02 00:53:19.745083: val_loss -0.8906 
2024-11-02 00:53:19.745117: Pseudo dice [0.922, 0.9002, 0.9588] 
2024-11-02 00:53:19.745145: Epoch time: 56.9 s 
2024-11-02 00:53:20.200817:  
2024-11-02 00:53:20.200890: Epoch 216 
2024-11-02 00:53:20.200932: Current learning rate: 0.00166 
2024-11-02 00:54:17.058512: train_loss -0.9495 
2024-11-02 00:54:17.058586: val_loss -0.8887 
2024-11-02 00:54:17.058619: Pseudo dice [0.9249, 0.8976, 0.9561] 
2024-11-02 00:54:17.058663: Epoch time: 56.86 s 
2024-11-02 00:54:17.512372:  
2024-11-02 00:54:17.512425: Epoch 217 
2024-11-02 00:54:17.512459: Current learning rate: 0.00162 
2024-11-02 00:55:14.384331: train_loss -0.9497 
2024-11-02 00:55:14.384405: val_loss -0.893 
2024-11-02 00:55:14.384436: Pseudo dice [0.9212, 0.9018, 0.9629] 
2024-11-02 00:55:14.384460: Epoch time: 56.87 s 
2024-11-02 00:55:14.838078:  
2024-11-02 00:55:14.838127: Epoch 218 
2024-11-02 00:55:14.838168: Current learning rate: 0.00157 
2024-11-02 00:56:11.716456: train_loss -0.95 
2024-11-02 00:56:11.716537: val_loss -0.8943 
2024-11-02 00:56:11.716568: Pseudo dice [0.9245, 0.9041, 0.9596] 
2024-11-02 00:56:11.716598: Epoch time: 56.88 s 
2024-11-02 00:56:12.170009:  
2024-11-02 00:56:12.170058: Epoch 219 
2024-11-02 00:56:12.170096: Current learning rate: 0.00153 
2024-11-02 00:57:09.038630: train_loss -0.9503 
2024-11-02 00:57:09.038716: val_loss -0.8974 
2024-11-02 00:57:09.038748: Pseudo dice [0.9255, 0.9042, 0.9597] 
2024-11-02 00:57:09.038776: Epoch time: 56.87 s 
2024-11-02 00:57:09.490740:  
2024-11-02 00:57:09.490784: Epoch 220 
2024-11-02 00:57:09.490820: Current learning rate: 0.00148 
2024-11-02 00:58:06.365349: train_loss -0.9494 
2024-11-02 00:58:06.365424: val_loss -0.8969 
2024-11-02 00:58:06.365466: Pseudo dice [0.9273, 0.9018, 0.9619] 
2024-11-02 00:58:06.365497: Epoch time: 56.87 s 
2024-11-02 00:58:07.108891:  
2024-11-02 00:58:07.108945: Epoch 221 
2024-11-02 00:58:07.108986: Current learning rate: 0.00144 
2024-11-02 00:59:03.998770: train_loss -0.9497 
2024-11-02 00:59:03.998851: val_loss -0.8921 
2024-11-02 00:59:03.998883: Pseudo dice [0.9222, 0.8998, 0.9607] 
2024-11-02 00:59:03.998910: Epoch time: 56.89 s 
2024-11-02 00:59:04.452699:  
2024-11-02 00:59:04.452812: Epoch 222 
2024-11-02 00:59:04.452849: Current learning rate: 0.00139 
2024-11-02 01:00:01.338003: train_loss -0.9501 
2024-11-02 01:00:01.338078: val_loss -0.8948 
2024-11-02 01:00:01.338109: Pseudo dice [0.9238, 0.901, 0.9618] 
2024-11-02 01:00:01.338136: Epoch time: 56.89 s 
2024-11-02 01:00:01.790946:  
2024-11-02 01:00:01.791005: Epoch 223 
2024-11-02 01:00:01.791039: Current learning rate: 0.00135 
2024-11-02 01:00:58.683672: train_loss -0.9502 
2024-11-02 01:00:58.683747: val_loss -0.8921 
2024-11-02 01:00:58.683777: Pseudo dice [0.9255, 0.9024, 0.9557] 
2024-11-02 01:00:58.683805: Epoch time: 56.89 s 
2024-11-02 01:00:59.138629:  
2024-11-02 01:00:59.138720: Epoch 224 
2024-11-02 01:00:59.138761: Current learning rate: 0.0013 
2024-11-02 01:01:56.033156: train_loss -0.9504 
2024-11-02 01:01:56.033288: val_loss -0.894 
2024-11-02 01:01:56.033327: Pseudo dice [0.9272, 0.9003, 0.9601] 
2024-11-02 01:01:56.033351: Epoch time: 56.89 s 
2024-11-02 01:01:56.484914:  
2024-11-02 01:01:56.484976: Epoch 225 
2024-11-02 01:01:56.485012: Current learning rate: 0.00126 
2024-11-02 01:02:53.375682: train_loss -0.9505 
2024-11-02 01:02:53.375762: val_loss -0.8979 
2024-11-02 01:02:53.375795: Pseudo dice [0.9254, 0.904, 0.9616] 
2024-11-02 01:02:53.375824: Epoch time: 56.89 s 
2024-11-02 01:02:53.830569:  
2024-11-02 01:02:53.830632: Epoch 226 
2024-11-02 01:02:53.830666: Current learning rate: 0.00121 
2024-11-02 01:03:50.698442: train_loss -0.9502 
2024-11-02 01:03:50.698517: val_loss -0.8941 
2024-11-02 01:03:50.698548: Pseudo dice [0.9256, 0.9051, 0.9622] 
2024-11-02 01:03:50.698572: Epoch time: 56.87 s 
2024-11-02 01:03:51.155422:  
2024-11-02 01:03:51.155482: Epoch 227 
2024-11-02 01:03:51.155521: Current learning rate: 0.00117 
2024-11-02 01:04:48.058433: train_loss -0.9513 
2024-11-02 01:04:48.058523: val_loss -0.8934 
2024-11-02 01:04:48.058556: Pseudo dice [0.9232, 0.9037, 0.9605] 
2024-11-02 01:04:48.058584: Epoch time: 56.9 s 
2024-11-02 01:04:48.514795:  
2024-11-02 01:04:48.514856: Epoch 228 
2024-11-02 01:04:48.514892: Current learning rate: 0.00112 
2024-11-02 01:05:45.386805: train_loss -0.9514 
2024-11-02 01:05:45.386885: val_loss -0.8884 
2024-11-02 01:05:45.386916: Pseudo dice [0.9212, 0.9, 0.9561] 
2024-11-02 01:05:45.386943: Epoch time: 56.87 s 
2024-11-02 01:05:45.845108:  
2024-11-02 01:05:45.845165: Epoch 229 
2024-11-02 01:05:45.845208: Current learning rate: 0.00108 
2024-11-02 01:06:42.750441: train_loss -0.9512 
2024-11-02 01:06:42.750527: val_loss -0.8929 
2024-11-02 01:06:42.750560: Pseudo dice [0.927, 0.9, 0.9605] 
2024-11-02 01:06:42.750589: Epoch time: 56.91 s 
2024-11-02 01:06:43.205476:  
2024-11-02 01:06:43.205528: Epoch 230 
2024-11-02 01:06:43.205563: Current learning rate: 0.00103 
2024-11-02 01:07:40.083997: train_loss -0.9506 
2024-11-02 01:07:40.084072: val_loss -0.8913 
2024-11-02 01:07:40.084104: Pseudo dice [0.9222, 0.8989, 0.9577] 
2024-11-02 01:07:40.084133: Epoch time: 56.88 s 
2024-11-02 01:07:40.537483:  
2024-11-02 01:07:40.537542: Epoch 231 
2024-11-02 01:07:40.537579: Current learning rate: 0.00098 
2024-11-02 01:08:37.410113: train_loss -0.9518 
2024-11-02 01:08:37.410194: val_loss -0.8951 
2024-11-02 01:08:37.410227: Pseudo dice [0.9247, 0.9029, 0.9633] 
2024-11-02 01:08:37.410274: Epoch time: 56.87 s 
2024-11-02 01:08:37.865574:  
2024-11-02 01:08:37.865622: Epoch 232 
2024-11-02 01:08:37.865661: Current learning rate: 0.00094 
2024-11-02 01:09:34.735978: train_loss -0.9512 
2024-11-02 01:09:34.736080: val_loss -0.8892 
2024-11-02 01:09:34.736116: Pseudo dice [0.9194, 0.9027, 0.9612] 
2024-11-02 01:09:34.736146: Epoch time: 56.87 s 
2024-11-02 01:09:35.189630:  
2024-11-02 01:09:35.189707: Epoch 233 
2024-11-02 01:09:35.189742: Current learning rate: 0.00089 
2024-11-02 01:10:32.060961: train_loss -0.9518 
2024-11-02 01:10:32.061035: val_loss -0.8864 
2024-11-02 01:10:32.061068: Pseudo dice [0.9182, 0.9044, 0.9551] 
2024-11-02 01:10:32.061096: Epoch time: 56.87 s 
2024-11-02 01:10:32.514022:  
2024-11-02 01:10:32.514076: Epoch 234 
2024-11-02 01:10:32.514114: Current learning rate: 0.00084 
2024-11-02 01:11:29.380268: train_loss -0.9525 
2024-11-02 01:11:29.380348: val_loss -0.8917 
2024-11-02 01:11:29.380380: Pseudo dice [0.9241, 0.899, 0.9587] 
2024-11-02 01:11:29.380408: Epoch time: 56.87 s 
2024-11-02 01:11:29.835376:  
2024-11-02 01:11:29.835452: Epoch 235 
2024-11-02 01:11:29.835518: Current learning rate: 0.00079 
2024-11-02 01:12:26.701149: train_loss -0.9514 
2024-11-02 01:12:26.701229: val_loss -0.8923 
2024-11-02 01:12:26.701257: Pseudo dice [0.9192, 0.9013, 0.9608] 
2024-11-02 01:12:26.701281: Epoch time: 56.87 s 
2024-11-02 01:12:27.155128:  
2024-11-02 01:12:27.155194: Epoch 236 
2024-11-02 01:12:27.155230: Current learning rate: 0.00075 
2024-11-02 01:13:24.036687: train_loss -0.9524 
2024-11-02 01:13:24.036772: val_loss -0.8893 
2024-11-02 01:13:24.036798: Pseudo dice [0.9215, 0.9034, 0.9589] 
2024-11-02 01:13:24.036821: Epoch time: 56.88 s 
2024-11-02 01:13:24.492507:  
2024-11-02 01:13:24.492554: Epoch 237 
2024-11-02 01:13:24.492592: Current learning rate: 0.0007 
2024-11-02 01:14:21.359160: train_loss -0.9518 
2024-11-02 01:14:21.359241: val_loss -0.8884 
2024-11-02 01:14:21.359267: Pseudo dice [0.9176, 0.9012, 0.9601] 
2024-11-02 01:14:21.359291: Epoch time: 56.87 s 
2024-11-02 01:14:21.811151:  
2024-11-02 01:14:21.811214: Epoch 238 
2024-11-02 01:14:21.811253: Current learning rate: 0.00065 
2024-11-02 01:15:18.671543: train_loss -0.9512 
2024-11-02 01:15:18.671634: val_loss -0.894 
2024-11-02 01:15:18.671663: Pseudo dice [0.9292, 0.8988, 0.9619] 
2024-11-02 01:15:18.671686: Epoch time: 56.86 s 
2024-11-02 01:15:19.125687:  
2024-11-02 01:15:19.125732: Epoch 239 
2024-11-02 01:15:19.125767: Current learning rate: 0.0006 
2024-11-02 01:16:15.988415: train_loss -0.9524 
2024-11-02 01:16:15.988492: val_loss -0.8854 
2024-11-02 01:16:15.988523: Pseudo dice [0.9171, 0.8997, 0.9585] 
2024-11-02 01:16:15.988550: Epoch time: 56.86 s 
2024-11-02 01:16:16.449487:  
2024-11-02 01:16:16.449532: Epoch 240 
2024-11-02 01:16:16.449567: Current learning rate: 0.00055 
2024-11-02 01:17:13.334285: train_loss -0.9523 
2024-11-02 01:17:13.334360: val_loss -0.8867 
2024-11-02 01:17:13.334393: Pseudo dice [0.919, 0.8997, 0.9575] 
2024-11-02 01:17:13.334421: Epoch time: 56.89 s 
2024-11-02 01:17:13.795377:  
2024-11-02 01:17:13.795482: Epoch 241 
2024-11-02 01:17:13.795522: Current learning rate: 0.0005 
2024-11-02 01:18:10.654454: train_loss -0.9527 
2024-11-02 01:18:10.654532: val_loss -0.8972 
2024-11-02 01:18:10.654558: Pseudo dice [0.9236, 0.9019, 0.963] 
2024-11-02 01:18:10.654582: Epoch time: 56.86 s 
2024-11-02 01:18:11.399230:  
2024-11-02 01:18:11.399284: Epoch 242 
2024-11-02 01:18:11.399325: Current learning rate: 0.00045 
2024-11-02 01:19:08.266472: train_loss -0.952 
2024-11-02 01:19:08.266554: val_loss -0.8892 
2024-11-02 01:19:08.266585: Pseudo dice [0.9195, 0.9014, 0.958] 
2024-11-02 01:19:08.266612: Epoch time: 56.87 s 
2024-11-02 01:19:08.727552:  
2024-11-02 01:19:08.727614: Epoch 243 
2024-11-02 01:19:08.727650: Current learning rate: 0.0004 
2024-11-02 01:20:05.599801: train_loss -0.9525 
2024-11-02 01:20:05.599887: val_loss -0.8836 
2024-11-02 01:20:05.599922: Pseudo dice [0.9168, 0.8991, 0.957] 
2024-11-02 01:20:05.599947: Epoch time: 56.87 s 
2024-11-02 01:20:06.063567:  
2024-11-02 01:20:06.063638: Epoch 244 
2024-11-02 01:20:06.063681: Current learning rate: 0.00035 
2024-11-02 01:21:02.934018: train_loss -0.9515 
2024-11-02 01:21:02.934099: val_loss -0.8908 
2024-11-02 01:21:02.934131: Pseudo dice [0.9251, 0.9015, 0.9573] 
2024-11-02 01:21:02.934160: Epoch time: 56.87 s 
2024-11-02 01:21:03.397471:  
2024-11-02 01:21:03.397531: Epoch 245 
2024-11-02 01:21:03.397571: Current learning rate: 0.0003 
2024-11-02 01:22:00.297569: train_loss -0.9529 
2024-11-02 01:22:00.297654: val_loss -0.8962 
2024-11-02 01:22:00.297688: Pseudo dice [0.9319, 0.8978, 0.9601] 
2024-11-02 01:22:00.297717: Epoch time: 56.9 s 
2024-11-02 01:22:00.759922:  
2024-11-02 01:22:00.759992: Epoch 246 
2024-11-02 01:22:00.760031: Current learning rate: 0.00024 
2024-11-02 01:22:57.632778: train_loss -0.9529 
2024-11-02 01:22:57.632858: val_loss -0.8918 
2024-11-02 01:22:57.632883: Pseudo dice [0.924, 0.9017, 0.9571] 
2024-11-02 01:22:57.632905: Epoch time: 56.87 s 
2024-11-02 01:22:58.099496:  
2024-11-02 01:22:58.099567: Epoch 247 
2024-11-02 01:22:58.099603: Current learning rate: 0.00019 
2024-11-02 01:23:55.003451: train_loss -0.9528 
2024-11-02 01:23:55.003525: val_loss -0.8938 
2024-11-02 01:23:55.003564: Pseudo dice [0.9238, 0.9021, 0.9618] 
2024-11-02 01:23:55.003592: Epoch time: 56.9 s 
2024-11-02 01:23:55.470552:  
2024-11-02 01:23:55.470611: Epoch 248 
2024-11-02 01:23:55.470648: Current learning rate: 0.00013 
2024-11-02 01:24:52.346457: train_loss -0.9531 
2024-11-02 01:24:52.346537: val_loss -0.8928 
2024-11-02 01:24:52.346564: Pseudo dice [0.9242, 0.8956, 0.9594] 
2024-11-02 01:24:52.346588: Epoch time: 56.88 s 
2024-11-02 01:24:52.814053:  
2024-11-02 01:24:52.814110: Epoch 249 
2024-11-02 01:24:52.814151: Current learning rate: 7e-05 
2024-11-02 01:25:49.680292: train_loss -0.9524 
2024-11-02 01:25:49.680371: val_loss -0.8873 
2024-11-02 01:25:49.680404: Pseudo dice [0.9193, 0.9026, 0.9566] 
2024-11-02 01:25:49.680434: Epoch time: 56.87 s 
2024-11-02 01:25:50.307771: Training done. 
2024-11-02 01:25:50.312321: Using splits from existing split file: /media/pycad/DATA/Documents/dataset/medics/heart/ACDC/corrected_metadata/nnunet_data/nnUNet_preprocessed/Dataset100_HEART/splits_final.json 
2024-11-02 01:25:50.312443: The split file contains 5 splits. 
2024-11-02 01:25:50.312458: Desired fold for training: 0 
2024-11-02 01:25:50.312469: This split has 240 training and 60 validation cases. 
2024-11-02 01:25:50.312631: predicting HEART_010 
2024-11-02 01:25:50.312958: HEART_010, shape torch.Size([1, 16, 249, 187]), rank 0 
2024-11-02 01:25:57.087000: predicting HEART_011 
2024-11-02 01:25:57.087620: HEART_011, shape torch.Size([1, 20, 236, 198]), rank 0 
2024-11-02 01:25:57.214908: predicting HEART_016 
2024-11-02 01:25:57.215283: HEART_016, shape torch.Size([1, 14, 263, 222]), rank 0 
2024-11-02 01:25:59.928467: predicting HEART_018 
2024-11-02 01:25:59.929068: HEART_018, shape torch.Size([1, 12, 263, 213]), rank 0 
2024-11-02 01:26:00.180968: predicting HEART_020 
2024-11-02 01:26:00.181496: HEART_020, shape torch.Size([1, 20, 263, 197]), rank 0 
2024-11-02 01:26:00.428371: predicting HEART_030 
2024-11-02 01:26:00.428865: HEART_030, shape torch.Size([1, 16, 263, 263]), rank 0 
2024-11-02 01:26:03.736698: predicting HEART_033 
2024-11-02 01:26:03.737190: HEART_033, shape torch.Size([1, 16, 236, 198]), rank 0 
2024-11-02 01:26:03.861613: predicting HEART_035 
2024-11-02 01:26:03.862236: HEART_035, shape torch.Size([1, 16, 230, 194]), rank 0 
2024-11-02 01:26:03.987418: predicting HEART_040 
2024-11-02 01:26:03.987965: HEART_040, shape torch.Size([1, 16, 185, 230]), rank 0 
2024-11-02 01:26:04.234815: predicting HEART_047 
2024-11-02 01:26:04.235377: HEART_047, shape torch.Size([1, 20, 192, 230]), rank 0 
2024-11-02 01:26:04.481633: predicting HEART_050 
2024-11-02 01:26:04.482155: HEART_050, shape torch.Size([1, 22, 230, 194]), rank 0 
2024-11-02 01:26:10.761489: predicting HEART_052 
2024-11-02 01:26:10.762131: HEART_052, shape torch.Size([1, 20, 230, 194]), rank 0 
2024-11-02 01:26:10.888422: predicting HEART_054 
2024-11-02 01:26:10.889021: HEART_054, shape torch.Size([1, 20, 263, 222]), rank 0 
2024-11-02 01:26:11.135623: predicting HEART_055 
2024-11-02 01:26:11.136151: HEART_055, shape torch.Size([1, 20, 230, 194]), rank 0 
2024-11-02 01:26:11.261527: predicting HEART_057 
2024-11-02 01:26:11.262076: HEART_057, shape torch.Size([1, 20, 262, 230]), rank 0 
2024-11-02 01:26:11.749841: predicting HEART_067 
2024-11-02 01:26:11.750411: HEART_067, shape torch.Size([1, 20, 263, 222]), rank 0 
2024-11-02 01:26:11.997521: predicting HEART_073 
2024-11-02 01:26:11.998087: HEART_073, shape torch.Size([1, 16, 243, 205]), rank 0 
2024-11-02 01:26:12.123087: predicting HEART_075 
2024-11-02 01:26:12.123646: HEART_075, shape torch.Size([1, 14, 315, 266]), rank 0 
2024-11-02 01:26:12.614008: predicting HEART_085 
2024-11-02 01:26:12.614592: HEART_085, shape torch.Size([1, 14, 230, 185]), rank 0 
2024-11-02 01:26:12.739318: predicting HEART_087 
2024-11-02 01:26:12.739956: HEART_087, shape torch.Size([1, 20, 194, 230]), rank 0 
2024-11-02 01:26:12.988981: predicting HEART_099 
2024-11-02 01:26:12.989488: HEART_099, shape torch.Size([1, 16, 230, 185]), rank 0 
2024-11-02 01:26:13.115871: predicting HEART_100 
2024-11-02 01:26:13.116263: HEART_100, shape torch.Size([1, 16, 230, 185]), rank 0 
2024-11-02 01:26:13.241580: predicting HEART_103 
2024-11-02 01:26:13.242108: HEART_103, shape torch.Size([1, 14, 230, 185]), rank 0 
2024-11-02 01:26:13.368837: predicting HEART_106 
2024-11-02 01:26:13.369345: HEART_106, shape torch.Size([1, 10, 192, 230]), rank 0 
2024-11-02 01:26:13.617488: predicting HEART_113 
2024-11-02 01:26:13.618057: HEART_113, shape torch.Size([1, 20, 263, 189]), rank 0 
2024-11-02 01:26:13.865162: predicting HEART_120 
2024-11-02 01:26:13.865697: HEART_120, shape torch.Size([1, 20, 243, 182]), rank 0 
2024-11-02 01:26:13.990887: predicting HEART_127 
2024-11-02 01:26:13.991303: HEART_127, shape torch.Size([1, 19, 230, 179]), rank 0 
2024-11-02 01:26:14.116486: predicting HEART_128 
2024-11-02 01:26:14.116995: HEART_128, shape torch.Size([1, 19, 230, 179]), rank 0 
2024-11-02 01:26:14.245466: predicting HEART_130 
2024-11-02 01:26:14.245999: HEART_130, shape torch.Size([1, 18, 249, 210]), rank 0 
2024-11-02 01:26:14.376418: predicting HEART_132 
2024-11-02 01:26:14.377285: HEART_132, shape torch.Size([1, 17, 243, 167]), rank 0 
2024-11-02 01:26:14.508682: predicting HEART_141 
2024-11-02 01:26:14.509287: HEART_141, shape torch.Size([1, 16, 263, 213]), rank 0 
2024-11-02 01:26:14.759869: predicting HEART_144 
2024-11-02 01:26:14.760463: HEART_144, shape torch.Size([1, 14, 194, 230]), rank 0 
2024-11-02 01:26:15.009037: predicting HEART_147 
2024-11-02 01:26:15.009566: HEART_147, shape torch.Size([1, 20, 276, 241]), rank 0 
2024-11-02 01:26:15.497483: predicting HEART_148 
2024-11-02 01:26:15.498024: HEART_148, shape torch.Size([1, 20, 276, 241]), rank 0 
2024-11-02 01:26:15.987263: predicting HEART_151 
2024-11-02 01:26:15.987835: HEART_151, shape torch.Size([1, 14, 230, 194]), rank 0 
2024-11-02 01:26:16.112610: predicting HEART_161 
2024-11-02 01:26:16.113170: HEART_161, shape torch.Size([1, 18, 236, 199]), rank 0 
2024-11-02 01:26:16.238904: predicting HEART_165 
2024-11-02 01:26:16.239290: HEART_165, shape torch.Size([1, 18, 263, 222]), rank 0 
2024-11-02 01:26:16.486523: predicting HEART_168 
2024-11-02 01:26:16.487101: HEART_168, shape torch.Size([1, 20, 194, 230]), rank 0 
2024-11-02 01:26:16.733412: predicting HEART_175 
2024-11-02 01:26:16.733907: HEART_175, shape torch.Size([1, 16, 276, 257]), rank 0 
2024-11-02 01:26:17.223922: predicting HEART_181 
2024-11-02 01:26:17.224506: HEART_181, shape torch.Size([1, 18, 230, 192]), rank 0 
2024-11-02 01:26:17.349568: predicting HEART_183 
2024-11-02 01:26:17.349972: HEART_183, shape torch.Size([1, 16, 249, 210]), rank 0 
2024-11-02 01:26:17.475281: predicting HEART_186 
2024-11-02 01:26:17.475828: HEART_186, shape torch.Size([1, 14, 210, 177]), rank 0 
2024-11-02 01:26:17.600671: predicting HEART_188 
2024-11-02 01:26:17.601213: HEART_188, shape torch.Size([1, 16, 263, 181]), rank 0 
2024-11-02 01:26:17.849080: predicting HEART_191 
2024-11-02 01:26:17.849739: HEART_191, shape torch.Size([1, 20, 276, 250]), rank 0 
2024-11-02 01:26:18.338682: predicting HEART_195 
2024-11-02 01:26:18.339188: HEART_195, shape torch.Size([1, 18, 263, 222]), rank 0 
2024-11-02 01:26:18.585835: predicting HEART_207 
2024-11-02 01:26:18.586368: HEART_207, shape torch.Size([1, 20, 233, 276]), rank 0 
2024-11-02 01:26:18.834654: predicting HEART_221 
2024-11-02 01:26:18.835262: HEART_221, shape torch.Size([1, 22, 243, 205]), rank 0 
2024-11-02 01:26:19.081854: predicting HEART_222 
2024-11-02 01:26:19.082426: HEART_222, shape torch.Size([1, 16, 295, 240]), rank 0 
2024-11-02 01:26:19.571078: predicting HEART_230 
2024-11-02 01:26:19.571596: HEART_230, shape torch.Size([1, 16, 263, 212]), rank 0 
2024-11-02 01:26:19.819038: predicting HEART_233 
2024-11-02 01:26:19.819544: HEART_233, shape torch.Size([1, 18, 229, 230]), rank 0 
2024-11-02 01:26:20.065983: predicting HEART_239 
2024-11-02 01:26:20.066522: HEART_239, shape torch.Size([1, 17, 243, 167]), rank 0 
2024-11-02 01:26:20.191596: predicting HEART_245 
2024-11-02 01:26:20.192136: HEART_245, shape torch.Size([1, 12, 230, 187]), rank 0 
2024-11-02 01:26:20.318492: predicting HEART_254 
2024-11-02 01:26:20.319048: HEART_254, shape torch.Size([1, 20, 262, 263]), rank 0 
2024-11-02 01:26:20.810247: predicting HEART_269 
2024-11-02 01:26:20.810821: HEART_269, shape torch.Size([1, 17, 230, 192]), rank 0 
2024-11-02 01:26:20.935731: predicting HEART_273 
2024-11-02 01:26:20.936332: HEART_273, shape torch.Size([1, 16, 182, 263]), rank 0 
2024-11-02 01:26:21.184937: predicting HEART_275 
2024-11-02 01:26:21.185494: HEART_275, shape torch.Size([1, 18, 249, 200]), rank 0 
2024-11-02 01:26:21.311276: predicting HEART_277 
2024-11-02 01:26:21.311681: HEART_277, shape torch.Size([1, 16, 249, 210]), rank 0 
2024-11-02 01:26:21.437255: predicting HEART_291 
2024-11-02 01:26:21.437673: HEART_291, shape torch.Size([1, 16, 282, 219]), rank 0 
2024-11-02 01:26:21.685884: predicting HEART_292 
2024-11-02 01:26:21.686459: HEART_292, shape torch.Size([1, 16, 282, 219]), rank 0 
2024-11-02 01:26:21.934287: predicting HEART_299 
2024-11-02 01:26:21.934855: HEART_299, shape torch.Size([1, 18, 229, 282]), rank 0 
2024-11-02 01:26:23.926714: Validation complete 
2024-11-02 01:26:23.926756: Mean Validation Dice:  0.9183415897076016 
