
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-11 13:06:55.826642: do_dummy_2d_data_aug: True 
2025-01-11 13:06:55.826984: Creating new 5-fold cross-validation split... 
2025-01-11 13:06:55.827538: Desired fold for training: 0 
2025-01-11 13:06:55.827557: This split has 110 training and 28 validation cases. 
2025-01-11 13:06:59.272207: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 160], 'median_image_size_in_voxels': [160.0, 512.0, 512.0], 'spacing': [0.8000005483627319, 0.3125, 0.3125], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset224_KNEE', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.8000005483627319, 0.3125, 0.3125], 'original_median_shape_after_transp': [160, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 11164.0, 'mean': 1774.468017578125, 'median': 1654.0, 'min': 0.0, 'percentile_00_5': 439.0, 'percentile_99_5': 6255.0, 'std': 846.3786010742188}}} 
 
2025-01-11 13:07:00.002490: unpacking dataset... 
2025-01-11 13:07:13.960495: unpacking done... 
2025-01-11 13:07:13.961227: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-01-11 13:07:13.971947:  
2025-01-11 13:07:13.971993: Epoch 0 
2025-01-11 13:07:13.972069: Current learning rate: 0.01 
2025-01-11 13:08:36.023047: train_loss 0.2221 
2025-01-11 13:08:36.023123: val_loss 0.0706 
2025-01-11 13:08:36.023154: Pseudo dice [0.0, 0.2884, 0.0, 0.0, 0.0, 0.0] 
2025-01-11 13:08:36.023177: Epoch time: 82.05 s 
2025-01-11 13:08:36.023193: Yayy! New best EMA pseudo Dice: 0.0481 
2025-01-11 13:08:36.568364:  
2025-01-11 13:08:36.568406: Epoch 1 
2025-01-11 13:08:36.568442: Current learning rate: 0.00996 
2025-01-11 13:09:20.938100: train_loss 0.0339 
2025-01-11 13:09:20.938179: val_loss -0.005 
2025-01-11 13:09:20.938210: Pseudo dice [0.0, 0.5263, 0.0, 0.0, 0.0, 0.0] 
2025-01-11 13:09:20.938233: Epoch time: 44.37 s 
2025-01-11 13:09:20.938249: Yayy! New best EMA pseudo Dice: 0.052 
2025-01-11 13:09:21.583395:  
2025-01-11 13:09:21.583489: Epoch 2 
2025-01-11 13:09:21.583533: Current learning rate: 0.00993 
2025-01-11 13:10:05.154809: train_loss -0.0193 
2025-01-11 13:10:05.154891: val_loss -0.0591 
2025-01-11 13:10:05.154932: Pseudo dice [0.0, 0.5985, 0.0, 0.0, 0.0, 0.0] 
2025-01-11 13:10:05.154961: Epoch time: 43.57 s 
2025-01-11 13:10:05.154981: Yayy! New best EMA pseudo Dice: 0.0568 
2025-01-11 13:10:05.848718:  
2025-01-11 13:10:05.848782: Epoch 3 
2025-01-11 13:10:05.848825: Current learning rate: 0.00989 
2025-01-11 13:10:49.306777: train_loss -0.0606 
2025-01-11 13:10:49.306860: val_loss -0.1197 
2025-01-11 13:10:49.306898: Pseudo dice [0.0, 0.6403, 0.3673, 0.0, 0.1632, 0.0] 
2025-01-11 13:10:49.306926: Epoch time: 43.46 s 
2025-01-11 13:10:49.306943: Yayy! New best EMA pseudo Dice: 0.0706 
2025-01-11 13:10:49.979121:  
2025-01-11 13:10:49.979170: Epoch 4 
2025-01-11 13:10:49.979208: Current learning rate: 0.00986 
2025-01-11 13:11:33.481951: train_loss -0.1123 
2025-01-11 13:11:33.482035: val_loss -0.1575 
2025-01-11 13:11:33.482075: Pseudo dice [0.0067, 0.6581, 0.316, 0.2834, 0.5156, 0.0] 
2025-01-11 13:11:33.482100: Epoch time: 43.5 s 
2025-01-11 13:11:33.482116: Yayy! New best EMA pseudo Dice: 0.0932 
2025-01-11 13:11:34.183795:  
2025-01-11 13:11:34.183879: Epoch 5 
2025-01-11 13:11:34.183921: Current learning rate: 0.00982 
2025-01-11 13:12:17.680777: train_loss -0.1571 
2025-01-11 13:12:17.680869: val_loss -0.1802 
2025-01-11 13:12:17.680907: Pseudo dice [0.1158, 0.666, 0.3771, 0.0356, 0.396, 0.0018] 
2025-01-11 13:12:17.680932: Epoch time: 43.5 s 
2025-01-11 13:12:17.680948: Yayy! New best EMA pseudo Dice: 0.1104 
2025-01-11 13:12:18.346559:  
2025-01-11 13:12:18.346613: Epoch 6 
2025-01-11 13:12:18.346656: Current learning rate: 0.00978 
2025-01-11 13:13:01.837408: train_loss -0.1868 
2025-01-11 13:13:01.837502: val_loss -0.2384 
2025-01-11 13:13:01.837541: Pseudo dice [0.4451, 0.7686, 0.4095, 0.2331, 0.0, 0.5842] 
2025-01-11 13:13:01.837566: Epoch time: 43.49 s 
2025-01-11 13:13:01.837582: Yayy! New best EMA pseudo Dice: 0.1401 
2025-01-11 13:13:02.509832:  
2025-01-11 13:13:02.509883: Epoch 7 
2025-01-11 13:13:02.509924: Current learning rate: 0.00975 
2025-01-11 13:13:45.956771: train_loss -0.2023 
2025-01-11 13:13:45.956849: val_loss -0.2286 
2025-01-11 13:13:45.956895: Pseudo dice [0.3017, 0.7496, 0.5152, 0.1749, 0.5031, 0.255] 
2025-01-11 13:13:45.956925: Epoch time: 43.45 s 
2025-01-11 13:13:45.956946: Yayy! New best EMA pseudo Dice: 0.1677 
2025-01-11 13:13:46.628993:  
2025-01-11 13:13:46.629070: Epoch 8 
2025-01-11 13:13:46.629118: Current learning rate: 0.00971 
2025-01-11 13:14:30.087493: train_loss -0.2247 
2025-01-11 13:14:30.087566: val_loss -0.2344 
2025-01-11 13:14:30.087616: Pseudo dice [0.6125, 0.7529, 0.4267, 0.0109, 0.1075, 0.5288] 
2025-01-11 13:14:30.087646: Epoch time: 43.46 s 
2025-01-11 13:14:30.087664: Yayy! New best EMA pseudo Dice: 0.1916 
2025-01-11 13:14:30.769327:  
2025-01-11 13:14:30.769397: Epoch 9 
2025-01-11 13:14:30.769440: Current learning rate: 0.00968 
2025-01-11 13:15:14.230605: train_loss -0.2257 
2025-01-11 13:15:14.230682: val_loss -0.2957 
2025-01-11 13:15:14.230723: Pseudo dice [0.6484, 0.784, 0.5829, 0.1664, 0.5529, 0.0018] 
2025-01-11 13:15:14.230753: Epoch time: 43.46 s 
2025-01-11 13:15:14.230772: Yayy! New best EMA pseudo Dice: 0.2181 
2025-01-11 13:15:14.891324:  
2025-01-11 13:15:14.891383: Epoch 10 
2025-01-11 13:15:14.891424: Current learning rate: 0.00964 
2025-01-11 13:15:58.407866: train_loss -0.2377 
2025-01-11 13:15:58.407940: val_loss -0.2352 
2025-01-11 13:15:58.407980: Pseudo dice [0.4306, 0.7563, 0.439, 0.0309, 0.4522, 0.0226] 
2025-01-11 13:15:58.408006: Epoch time: 43.52 s 
2025-01-11 13:15:58.408024: Yayy! New best EMA pseudo Dice: 0.2318 
2025-01-11 13:15:59.060642:  
2025-01-11 13:15:59.060690: Epoch 11 
2025-01-11 13:15:59.060728: Current learning rate: 0.0096 
2025-01-11 13:16:42.520734: train_loss -0.246 
2025-01-11 13:16:42.520809: val_loss -0.2629 
2025-01-11 13:16:42.520850: Pseudo dice [0.5811, 0.7663, 0.5855, 0.2908, 0.3432, 0.4244] 
2025-01-11 13:16:42.520878: Epoch time: 43.46 s 
2025-01-11 13:16:42.520894: Yayy! New best EMA pseudo Dice: 0.2585 
2025-01-11 13:16:43.424978:  
2025-01-11 13:16:43.425031: Epoch 12 
2025-01-11 13:16:43.425071: Current learning rate: 0.00957 
2025-01-11 13:17:26.898406: train_loss -0.2641 
2025-01-11 13:17:26.898483: val_loss -0.273 
2025-01-11 13:17:26.898525: Pseudo dice [0.7263, 0.7919, 0.0, 0.4552, 0.5905, 0.0086] 
2025-01-11 13:17:26.898554: Epoch time: 43.47 s 
2025-01-11 13:17:26.898574: Yayy! New best EMA pseudo Dice: 0.2755 
2025-01-11 13:17:27.565832:  
2025-01-11 13:17:27.565887: Epoch 13 
2025-01-11 13:17:27.565928: Current learning rate: 0.00953 
2025-01-11 13:18:11.079904: train_loss -0.2711 
2025-01-11 13:18:11.079971: val_loss -0.3069 
2025-01-11 13:18:11.080004: Pseudo dice [0.6812, 0.7876, 0.5824, 0.415, 0.4937, 0.4229] 
2025-01-11 13:18:11.080028: Epoch time: 43.51 s 
2025-01-11 13:18:11.080044: Yayy! New best EMA pseudo Dice: 0.3043 
2025-01-11 13:18:11.746670:  
2025-01-11 13:18:11.746731: Epoch 14 
2025-01-11 13:18:11.746773: Current learning rate: 0.00949 
2025-01-11 13:18:55.233835: train_loss -0.281 
2025-01-11 13:18:55.233913: val_loss -0.3123 
2025-01-11 13:18:55.233949: Pseudo dice [0.7146, 0.8016, 0.618, 0.5267, 0.5436, 0.3647] 
2025-01-11 13:18:55.233974: Epoch time: 43.49 s 
2025-01-11 13:18:55.233991: Yayy! New best EMA pseudo Dice: 0.3334 
2025-01-11 13:18:55.912691:  
2025-01-11 13:18:55.912760: Epoch 15 
2025-01-11 13:18:55.912802: Current learning rate: 0.00946 
2025-01-11 13:19:39.430075: train_loss -0.3018 
2025-01-11 13:19:39.430152: val_loss -0.3067 
2025-01-11 13:19:39.430195: Pseudo dice [0.7868, 0.7971, 0.577, 0.5153, 0.542, 0.5169] 
2025-01-11 13:19:39.430227: Epoch time: 43.52 s 
2025-01-11 13:19:39.430247: Yayy! New best EMA pseudo Dice: 0.3623 
2025-01-11 13:19:40.100580:  
2025-01-11 13:19:40.100633: Epoch 16 
2025-01-11 13:19:40.100673: Current learning rate: 0.00942 
2025-01-11 13:20:23.613125: train_loss -0.3161 
2025-01-11 13:20:23.613207: val_loss -0.3475 
2025-01-11 13:20:23.613248: Pseudo dice [0.6709, 0.7986, 0.6287, 0.6903, 0.6118, 0.5767] 
2025-01-11 13:20:23.613277: Epoch time: 43.51 s 
2025-01-11 13:20:23.613297: Yayy! New best EMA pseudo Dice: 0.3923 
2025-01-11 13:20:24.297180:  
2025-01-11 13:20:24.297282: Epoch 17 
2025-01-11 13:20:24.297327: Current learning rate: 0.00939 
2025-01-11 13:21:07.813963: train_loss -0.3426 
2025-01-11 13:21:07.814038: val_loss -0.3691 
2025-01-11 13:21:07.814078: Pseudo dice [0.6365, 0.7913, 0.681, 0.7153, 0.672, 0.6854] 
2025-01-11 13:21:07.814107: Epoch time: 43.52 s 
2025-01-11 13:21:07.814127: Yayy! New best EMA pseudo Dice: 0.4228 
2025-01-11 13:21:08.493011:  
2025-01-11 13:21:08.493073: Epoch 18 
2025-01-11 13:21:08.493114: Current learning rate: 0.00935 
2025-01-11 13:21:52.006231: train_loss -0.3142 
2025-01-11 13:21:52.006303: val_loss -0.3339 
2025-01-11 13:21:52.006343: Pseudo dice [0.7525, 0.8008, 0.6616, 0.6519, 0.6193, 0.5199] 
2025-01-11 13:21:52.006371: Epoch time: 43.51 s 
2025-01-11 13:21:52.006392: Yayy! New best EMA pseudo Dice: 0.4473 
2025-01-11 13:21:52.686826:  
2025-01-11 13:21:52.686881: Epoch 19 
2025-01-11 13:21:52.686924: Current learning rate: 0.00931 
2025-01-11 13:22:36.199575: train_loss -0.3389 
2025-01-11 13:22:36.199666: val_loss -0.3963 
2025-01-11 13:22:36.199706: Pseudo dice [0.6889, 0.8125, 0.7041, 0.7253, 0.5889, 0.5865] 
2025-01-11 13:22:36.199734: Epoch time: 43.51 s 
2025-01-11 13:22:36.199762: Yayy! New best EMA pseudo Dice: 0.471 
2025-01-11 13:22:36.877341:  
2025-01-11 13:22:36.877394: Epoch 20 
2025-01-11 13:22:36.877444: Current learning rate: 0.00928 
2025-01-11 13:23:20.374344: train_loss -0.3339 
2025-01-11 13:23:20.374435: val_loss -0.3761 
2025-01-11 13:23:20.374478: Pseudo dice [0.788, 0.8227, 0.6766, 0.7806, 0.6176, 0.7198] 
2025-01-11 13:23:20.374510: Epoch time: 43.5 s 
2025-01-11 13:23:20.374527: Yayy! New best EMA pseudo Dice: 0.4973 
2025-01-11 13:23:21.061273:  
2025-01-11 13:23:21.061342: Epoch 21 
2025-01-11 13:23:21.061381: Current learning rate: 0.00924 
2025-01-11 13:24:04.570773: train_loss -0.3634 
2025-01-11 13:24:04.570852: val_loss -0.3417 
2025-01-11 13:24:04.570897: Pseudo dice [0.8426, 0.7613, 0.5134, 0.6363, 0.5289, 0.6192] 
2025-01-11 13:24:04.570924: Epoch time: 43.51 s 
2025-01-11 13:24:04.570940: Yayy! New best EMA pseudo Dice: 0.5126 
2025-01-11 13:24:05.221277:  
2025-01-11 13:24:05.221330: Epoch 22 
2025-01-11 13:24:05.221375: Current learning rate: 0.0092 
2025-01-11 13:24:48.718745: train_loss -0.3543 
2025-01-11 13:24:48.718827: val_loss -0.3824 
2025-01-11 13:24:48.718865: Pseudo dice [0.8174, 0.8093, 0.6928, 0.6316, 0.6641, 0.6145] 
2025-01-11 13:24:48.718893: Epoch time: 43.5 s 
2025-01-11 13:24:48.718909: Yayy! New best EMA pseudo Dice: 0.5318 
2025-01-11 13:24:49.374432:  
2025-01-11 13:24:49.374482: Epoch 23 
2025-01-11 13:24:49.374524: Current learning rate: 0.00917 
2025-01-11 13:25:33.201058: train_loss -0.3585 
2025-01-11 13:25:33.201132: val_loss -0.4146 
2025-01-11 13:25:33.201171: Pseudo dice [0.7529, 0.8204, 0.7224, 0.8174, 0.6614, 0.7171] 
2025-01-11 13:25:33.201201: Epoch time: 43.83 s 
2025-01-11 13:25:33.201219: Yayy! New best EMA pseudo Dice: 0.5535 
2025-01-11 13:25:33.851876:  
2025-01-11 13:25:33.851924: Epoch 24 
2025-01-11 13:25:33.851965: Current learning rate: 0.00913 
2025-01-11 13:26:17.370525: train_loss -0.3749 
2025-01-11 13:26:17.370603: val_loss -0.4093 
2025-01-11 13:26:17.370642: Pseudo dice [0.815, 0.7999, 0.6899, 0.7245, 0.6849, 0.6306] 
2025-01-11 13:26:17.370668: Epoch time: 43.52 s 
2025-01-11 13:26:17.370684: Yayy! New best EMA pseudo Dice: 0.5706 
2025-01-11 13:26:18.024241:  
2025-01-11 13:26:18.024302: Epoch 25 
2025-01-11 13:26:18.024352: Current learning rate: 0.0091 
2025-01-11 13:27:01.532899: train_loss -0.3931 
2025-01-11 13:27:01.532989: val_loss -0.4189 
2025-01-11 13:27:01.533029: Pseudo dice [0.8235, 0.8154, 0.7568, 0.7561, 0.7678, 0.7404] 
2025-01-11 13:27:01.533060: Epoch time: 43.51 s 
2025-01-11 13:27:01.533081: Yayy! New best EMA pseudo Dice: 0.5912 
2025-01-11 13:27:02.198205:  
2025-01-11 13:27:02.198258: Epoch 26 
2025-01-11 13:27:02.198353: Current learning rate: 0.00906 
2025-01-11 13:27:45.710991: train_loss -0.3951 
2025-01-11 13:27:45.711072: val_loss -0.4218 
2025-01-11 13:27:45.711115: Pseudo dice [0.8328, 0.8316, 0.6978, 0.7365, 0.7144, 0.6883] 
2025-01-11 13:27:45.711145: Epoch time: 43.51 s 
2025-01-11 13:27:45.711166: Yayy! New best EMA pseudo Dice: 0.6071 
2025-01-11 13:27:46.369047:  
2025-01-11 13:27:46.369098: Epoch 27 
2025-01-11 13:27:46.369138: Current learning rate: 0.00902 
2025-01-11 13:28:29.861921: train_loss -0.3822 
2025-01-11 13:28:29.862001: val_loss -0.3558 
2025-01-11 13:28:29.862041: Pseudo dice [0.8128, 0.795, 0.6766, 0.6919, 0.6881, 0.6725] 
2025-01-11 13:28:29.862087: Epoch time: 43.49 s 
2025-01-11 13:28:29.862123: Yayy! New best EMA pseudo Dice: 0.6187 
2025-01-11 13:28:30.523205:  
2025-01-11 13:28:30.523265: Epoch 28 
2025-01-11 13:28:30.523307: Current learning rate: 0.00899 
2025-01-11 13:29:13.993083: train_loss -0.3944 
2025-01-11 13:29:13.993166: val_loss -0.373 
2025-01-11 13:29:13.993220: Pseudo dice [0.8055, 0.8111, 0.7388, 0.7441, 0.7573, 0.7313] 
2025-01-11 13:29:13.993245: Epoch time: 43.47 s 
2025-01-11 13:29:13.993261: Yayy! New best EMA pseudo Dice: 0.6333 
2025-01-11 13:29:14.649238:  
2025-01-11 13:29:14.649292: Epoch 29 
2025-01-11 13:29:14.649331: Current learning rate: 0.00895 
2025-01-11 13:29:58.175774: train_loss -0.4073 
2025-01-11 13:29:58.175848: val_loss -0.4047 
2025-01-11 13:29:58.175882: Pseudo dice [0.7262, 0.8122, 0.7168, 0.6396, 0.7585, 0.6455] 
2025-01-11 13:29:58.175906: Epoch time: 43.53 s 
2025-01-11 13:29:58.175923: Yayy! New best EMA pseudo Dice: 0.6416 
2025-01-11 13:29:59.116477:  
2025-01-11 13:29:59.116560: Epoch 30 
2025-01-11 13:29:59.116603: Current learning rate: 0.00891 
2025-01-11 13:30:42.596634: train_loss -0.3931 
2025-01-11 13:30:42.596710: val_loss -0.4168 
2025-01-11 13:30:42.596745: Pseudo dice [0.7948, 0.8197, 0.7804, 0.7979, 0.7129, 0.7307] 
2025-01-11 13:30:42.596770: Epoch time: 43.48 s 
2025-01-11 13:30:42.596788: Yayy! New best EMA pseudo Dice: 0.6547 
2025-01-11 13:30:43.269862:  
2025-01-11 13:30:43.269997: Epoch 31 
2025-01-11 13:30:43.270036: Current learning rate: 0.00888 
2025-01-11 13:31:26.743203: train_loss -0.4135 
2025-01-11 13:31:26.743278: val_loss -0.4555 
2025-01-11 13:31:26.743310: Pseudo dice [0.7156, 0.8101, 0.78, 0.8231, 0.722, 0.722] 
2025-01-11 13:31:26.743334: Epoch time: 43.47 s 
2025-01-11 13:31:26.743351: Yayy! New best EMA pseudo Dice: 0.6654 
2025-01-11 13:31:27.413499:  
2025-01-11 13:31:27.413556: Epoch 32 
2025-01-11 13:31:27.413596: Current learning rate: 0.00884 
2025-01-11 13:32:10.944907: train_loss -0.4052 
2025-01-11 13:32:10.944979: val_loss -0.4003 
2025-01-11 13:32:10.945017: Pseudo dice [0.8242, 0.8288, 0.7391, 0.7008, 0.7319, 0.6612] 
2025-01-11 13:32:10.945044: Epoch time: 43.53 s 
2025-01-11 13:32:10.945064: Yayy! New best EMA pseudo Dice: 0.6737 
2025-01-11 13:32:11.615550:  
2025-01-11 13:32:11.615618: Epoch 33 
2025-01-11 13:32:11.615658: Current learning rate: 0.0088 
2025-01-11 13:32:55.085747: train_loss -0.4033 
2025-01-11 13:32:55.085835: val_loss -0.4475 
2025-01-11 13:32:55.085873: Pseudo dice [0.8347, 0.8286, 0.7712, 0.7875, 0.7474, 0.7355] 
2025-01-11 13:32:55.085902: Epoch time: 43.47 s 
2025-01-11 13:32:55.085925: Yayy! New best EMA pseudo Dice: 0.6847 
2025-01-11 13:32:55.754967:  
2025-01-11 13:32:55.755084: Epoch 34 
2025-01-11 13:32:55.755131: Current learning rate: 0.00877 
2025-01-11 13:33:39.276082: train_loss -0.4158 
2025-01-11 13:33:39.276163: val_loss -0.4501 
2025-01-11 13:33:39.276203: Pseudo dice [0.829, 0.8287, 0.8085, 0.8571, 0.7895, 0.7611] 
2025-01-11 13:33:39.276233: Epoch time: 43.52 s 
2025-01-11 13:33:39.276253: Yayy! New best EMA pseudo Dice: 0.6975 
2025-01-11 13:33:39.957021:  
2025-01-11 13:33:39.957088: Epoch 35 
2025-01-11 13:33:39.957129: Current learning rate: 0.00873 
2025-01-11 13:34:23.456835: train_loss -0.4269 
2025-01-11 13:34:23.456953: val_loss -0.4468 
2025-01-11 13:34:23.456985: Pseudo dice [0.8032, 0.8197, 0.7961, 0.8124, 0.7791, 0.7587] 
2025-01-11 13:34:23.457009: Epoch time: 43.5 s 
2025-01-11 13:34:23.457026: Yayy! New best EMA pseudo Dice: 0.7072 
2025-01-11 13:34:24.140713:  
2025-01-11 13:34:24.140768: Epoch 36 
2025-01-11 13:34:24.140809: Current learning rate: 0.00869 
2025-01-11 13:35:07.654790: train_loss -0.4211 
2025-01-11 13:35:07.654859: val_loss -0.4621 
2025-01-11 13:35:07.654891: Pseudo dice [0.8372, 0.8202, 0.7641, 0.8303, 0.785, 0.7688] 
2025-01-11 13:35:07.654913: Epoch time: 43.51 s 
2025-01-11 13:35:07.654929: Yayy! New best EMA pseudo Dice: 0.7166 
2025-01-11 13:35:08.335322:  
2025-01-11 13:35:08.335373: Epoch 37 
2025-01-11 13:35:08.335416: Current learning rate: 0.00866 
2025-01-11 13:35:51.827981: train_loss -0.4146 
2025-01-11 13:35:51.828069: val_loss -0.45 
2025-01-11 13:35:51.828109: Pseudo dice [0.8004, 0.8342, 0.802, 0.8338, 0.7439, 0.7457] 
2025-01-11 13:35:51.828135: Epoch time: 43.49 s 
2025-01-11 13:35:51.828151: Yayy! New best EMA pseudo Dice: 0.7243 
2025-01-11 13:35:52.516417:  
2025-01-11 13:35:52.516468: Epoch 38 
2025-01-11 13:35:52.516508: Current learning rate: 0.00862 
2025-01-11 13:36:36.040704: train_loss -0.4193 
2025-01-11 13:36:36.040785: val_loss -0.4864 
2025-01-11 13:36:36.040816: Pseudo dice [0.8419, 0.8196, 0.7733, 0.8274, 0.7773, 0.7612] 
2025-01-11 13:36:36.040839: Epoch time: 43.52 s 
2025-01-11 13:36:36.040854: Yayy! New best EMA pseudo Dice: 0.7319 
2025-01-11 13:36:36.723250:  
2025-01-11 13:36:36.723315: Epoch 39 
2025-01-11 13:36:36.723356: Current learning rate: 0.00858 
2025-01-11 13:37:20.207415: train_loss -0.447 
2025-01-11 13:37:20.207495: val_loss -0.4245 
2025-01-11 13:37:20.207530: Pseudo dice [0.809, 0.8288, 0.8058, 0.822, 0.804, 0.7342] 
2025-01-11 13:37:20.207555: Epoch time: 43.48 s 
2025-01-11 13:37:20.207571: Yayy! New best EMA pseudo Dice: 0.7387 
2025-01-11 13:37:20.903026:  
2025-01-11 13:37:20.903116: Epoch 40 
2025-01-11 13:37:20.903156: Current learning rate: 0.00855 
2025-01-11 13:38:04.416602: train_loss -0.4211 
2025-01-11 13:38:04.416679: val_loss -0.4365 
2025-01-11 13:38:04.416724: Pseudo dice [0.7943, 0.8367, 0.775, 0.8279, 0.804, 0.7919] 
2025-01-11 13:38:04.416750: Epoch time: 43.51 s 
2025-01-11 13:38:04.416766: Yayy! New best EMA pseudo Dice: 0.7454 
2025-01-11 13:38:05.103322:  
2025-01-11 13:38:05.103390: Epoch 41 
2025-01-11 13:38:05.103430: Current learning rate: 0.00851 
2025-01-11 13:38:48.580959: train_loss -0.4261 
2025-01-11 13:38:48.581033: val_loss -0.4371 
2025-01-11 13:38:48.581072: Pseudo dice [0.8554, 0.8396, 0.8272, 0.7898, 0.7717, 0.7075] 
2025-01-11 13:38:48.581100: Epoch time: 43.48 s 
2025-01-11 13:38:48.581119: Yayy! New best EMA pseudo Dice: 0.7507 
2025-01-11 13:38:49.237770:  
2025-01-11 13:38:49.237843: Epoch 42 
2025-01-11 13:38:49.237885: Current learning rate: 0.00847 
2025-01-11 13:39:32.752437: train_loss -0.4437 
2025-01-11 13:39:32.752517: val_loss -0.4374 
2025-01-11 13:39:32.752557: Pseudo dice [0.791, 0.8307, 0.7291, 0.7969, 0.7447, 0.7612] 
2025-01-11 13:39:32.752581: Epoch time: 43.52 s 
2025-01-11 13:39:32.752598: Yayy! New best EMA pseudo Dice: 0.7532 
2025-01-11 13:39:33.419393:  
2025-01-11 13:39:33.419466: Epoch 43 
2025-01-11 13:39:33.419513: Current learning rate: 0.00844 
2025-01-11 13:40:16.936994: train_loss -0.4174 
2025-01-11 13:40:16.937072: val_loss -0.44 
2025-01-11 13:40:16.937108: Pseudo dice [0.8574, 0.8494, 0.7165, 0.7697, 0.7267, 0.7498] 
2025-01-11 13:40:16.937132: Epoch time: 43.52 s 
2025-01-11 13:40:16.937148: Yayy! New best EMA pseudo Dice: 0.7557 
2025-01-11 13:40:17.592598:  
2025-01-11 13:40:17.592662: Epoch 44 
2025-01-11 13:40:17.592700: Current learning rate: 0.0084 
2025-01-11 13:41:00.964748: train_loss -0.453 
2025-01-11 13:41:00.964822: val_loss -0.4513 
2025-01-11 13:41:00.964870: Pseudo dice [0.8287, 0.8309, 0.8226, 0.8281, 0.8076, 0.7465] 
2025-01-11 13:41:00.964900: Epoch time: 43.37 s 
2025-01-11 13:41:00.964921: Yayy! New best EMA pseudo Dice: 0.7612 
2025-01-11 13:41:01.630942:  
2025-01-11 13:41:01.630991: Epoch 45 
2025-01-11 13:41:01.631032: Current learning rate: 0.00836 
2025-01-11 13:41:44.878108: train_loss -0.4336 
2025-01-11 13:41:44.878187: val_loss -0.4604 
2025-01-11 13:41:44.878218: Pseudo dice [0.8268, 0.8105, 0.8088, 0.8214, 0.7951, 0.7796] 
2025-01-11 13:41:44.878242: Epoch time: 43.25 s 
2025-01-11 13:41:44.878257: Yayy! New best EMA pseudo Dice: 0.7658 
2025-01-11 13:41:45.539360:  
2025-01-11 13:41:45.539416: Epoch 46 
2025-01-11 13:41:45.539455: Current learning rate: 0.00833 
2025-01-11 13:42:28.825013: train_loss -0.4354 
2025-01-11 13:42:28.825099: val_loss -0.4652 
2025-01-11 13:42:28.825140: Pseudo dice [0.7914, 0.8392, 0.8025, 0.8263, 0.8219, 0.7906] 
2025-01-11 13:42:28.825164: Epoch time: 43.29 s 
2025-01-11 13:42:28.825246: Yayy! New best EMA pseudo Dice: 0.7704 
2025-01-11 13:42:29.492608:  
2025-01-11 13:42:29.492662: Epoch 47 
2025-01-11 13:42:29.492701: Current learning rate: 0.00829 
2025-01-11 13:43:12.779007: train_loss -0.4489 
2025-01-11 13:43:12.779086: val_loss -0.4179 
2025-01-11 13:43:12.779117: Pseudo dice [0.8189, 0.8122, 0.7919, 0.8183, 0.7898, 0.7468] 
2025-01-11 13:43:12.779142: Epoch time: 43.29 s 
2025-01-11 13:43:12.779157: Yayy! New best EMA pseudo Dice: 0.773 
2025-01-11 13:43:13.708627:  
2025-01-11 13:43:13.708686: Epoch 48 
2025-01-11 13:43:13.708730: Current learning rate: 0.00825 
2025-01-11 13:43:57.021187: train_loss -0.4261 
2025-01-11 13:43:57.021253: val_loss -0.4439 
2025-01-11 13:43:57.021285: Pseudo dice [0.838, 0.8388, 0.7778, 0.8085, 0.7283, 0.7208] 
2025-01-11 13:43:57.021310: Epoch time: 43.31 s 
2025-01-11 13:43:57.021326: Yayy! New best EMA pseudo Dice: 0.7742 
2025-01-11 13:43:57.689292:  
2025-01-11 13:43:57.689370: Epoch 49 
2025-01-11 13:43:57.689411: Current learning rate: 0.00822 
2025-01-11 13:44:40.948695: train_loss -0.4646 
2025-01-11 13:44:40.948783: val_loss -0.4932 
2025-01-11 13:44:40.948815: Pseudo dice [0.8513, 0.854, 0.8116, 0.8211, 0.7947, 0.7603] 
2025-01-11 13:44:40.948839: Epoch time: 43.26 s 
2025-01-11 13:44:41.076616: Yayy! New best EMA pseudo Dice: 0.7783 
2025-01-11 13:44:41.752847:  
2025-01-11 13:44:41.752903: Epoch 50 
2025-01-11 13:44:41.752940: Current learning rate: 0.00818 
2025-01-11 13:45:25.062133: train_loss -0.4422 
2025-01-11 13:45:25.062217: val_loss -0.4884 
2025-01-11 13:45:25.062257: Pseudo dice [0.8369, 0.8485, 0.8236, 0.8424, 0.8191, 0.8165] 
2025-01-11 13:45:25.062287: Epoch time: 43.31 s 
2025-01-11 13:45:25.062305: Yayy! New best EMA pseudo Dice: 0.7836 
2025-01-11 13:45:25.731856:  
2025-01-11 13:45:25.731946: Epoch 51 
2025-01-11 13:45:25.732001: Current learning rate: 0.00814 
2025-01-11 13:46:08.992270: train_loss -0.4368 
2025-01-11 13:46:08.992349: val_loss -0.4722 
2025-01-11 13:46:08.992380: Pseudo dice [0.7737, 0.834, 0.8364, 0.8458, 0.7749, 0.7577] 
2025-01-11 13:46:08.992408: Epoch time: 43.26 s 
2025-01-11 13:46:08.992424: Yayy! New best EMA pseudo Dice: 0.7856 
2025-01-11 13:46:09.661948:  
2025-01-11 13:46:09.662018: Epoch 52 
2025-01-11 13:46:09.662058: Current learning rate: 0.00811 
2025-01-11 13:46:52.950294: train_loss -0.4605 
2025-01-11 13:46:52.950373: val_loss -0.4798 
2025-01-11 13:46:52.950405: Pseudo dice [0.8561, 0.8406, 0.8078, 0.8453, 0.7753, 0.7933] 
2025-01-11 13:46:52.950431: Epoch time: 43.29 s 
2025-01-11 13:46:52.950451: Yayy! New best EMA pseudo Dice: 0.7891 
2025-01-11 13:46:53.621096:  
2025-01-11 13:46:53.621160: Epoch 53 
2025-01-11 13:46:53.621207: Current learning rate: 0.00807 
2025-01-11 13:47:36.910182: train_loss -0.4553 
2025-01-11 13:47:36.910268: val_loss -0.441 
2025-01-11 13:47:36.910302: Pseudo dice [0.8404, 0.8508, 0.8089, 0.831, 0.8013, 0.7786] 
2025-01-11 13:47:36.910327: Epoch time: 43.29 s 
2025-01-11 13:47:36.910345: Yayy! New best EMA pseudo Dice: 0.792 
2025-01-11 13:47:37.577458:  
2025-01-11 13:47:37.577512: Epoch 54 
2025-01-11 13:47:37.577550: Current learning rate: 0.00803 
2025-01-11 13:48:20.847568: train_loss -0.4606 
2025-01-11 13:48:20.847649: val_loss -0.4833 
2025-01-11 13:48:20.847689: Pseudo dice [0.8223, 0.8508, 0.8384, 0.8585, 0.8302, 0.8212] 
2025-01-11 13:48:20.847723: Epoch time: 43.27 s 
2025-01-11 13:48:20.847743: Yayy! New best EMA pseudo Dice: 0.7965 
2025-01-11 13:48:21.519941:  
2025-01-11 13:48:21.520025: Epoch 55 
2025-01-11 13:48:21.520064: Current learning rate: 0.008 
2025-01-11 13:49:04.779460: train_loss -0.457 
2025-01-11 13:49:04.779535: val_loss -0.485 
2025-01-11 13:49:04.779572: Pseudo dice [0.7974, 0.8538, 0.8325, 0.8427, 0.8195, 0.7771] 
2025-01-11 13:49:04.779601: Epoch time: 43.26 s 
2025-01-11 13:49:04.779617: Yayy! New best EMA pseudo Dice: 0.7989 
2025-01-11 13:49:05.453287:  
2025-01-11 13:49:05.453339: Epoch 56 
2025-01-11 13:49:05.453383: Current learning rate: 0.00796 
2025-01-11 13:49:48.714312: train_loss -0.4341 
2025-01-11 13:49:48.714392: val_loss -0.4694 
2025-01-11 13:49:48.714425: Pseudo dice [0.7899, 0.8181, 0.8031, 0.8608, 0.8264, 0.8053] 
2025-01-11 13:49:48.714449: Epoch time: 43.26 s 
2025-01-11 13:49:48.714465: Yayy! New best EMA pseudo Dice: 0.8007 
2025-01-11 13:49:49.385234:  
2025-01-11 13:49:49.385334: Epoch 57 
2025-01-11 13:49:49.385375: Current learning rate: 0.00792 
2025-01-11 13:50:32.660355: train_loss -0.4516 
2025-01-11 13:50:32.660432: val_loss -0.4735 
2025-01-11 13:50:32.660473: Pseudo dice [0.8268, 0.8447, 0.7685, 0.8137, 0.7752, 0.7883] 
2025-01-11 13:50:32.660500: Epoch time: 43.28 s 
2025-01-11 13:50:32.660516: Yayy! New best EMA pseudo Dice: 0.8009 
2025-01-11 13:50:33.328106:  
2025-01-11 13:50:33.328155: Epoch 58 
2025-01-11 13:50:33.328194: Current learning rate: 0.00789 
2025-01-11 13:51:16.614590: train_loss -0.4248 
2025-01-11 13:51:16.614676: val_loss -0.4806 
2025-01-11 13:51:16.614716: Pseudo dice [0.8416, 0.8374, 0.7926, 0.8281, 0.7267, 0.7435] 
2025-01-11 13:51:16.614741: Epoch time: 43.29 s 
2025-01-11 13:51:17.102742:  
2025-01-11 13:51:17.102793: Epoch 59 
2025-01-11 13:51:17.102831: Current learning rate: 0.00785 
2025-01-11 13:52:00.394490: train_loss -0.4671 
2025-01-11 13:52:00.394571: val_loss -0.4651 
2025-01-11 13:52:00.394613: Pseudo dice [0.799, 0.8315, 0.7104, 0.7531, 0.7478, 0.755] 
2025-01-11 13:52:00.394644: Epoch time: 43.29 s 
2025-01-11 13:52:00.881018:  
2025-01-11 13:52:00.881089: Epoch 60 
2025-01-11 13:52:00.881128: Current learning rate: 0.00781 
2025-01-11 13:52:44.167885: train_loss -0.4334 
2025-01-11 13:52:44.167954: val_loss -0.4598 
2025-01-11 13:52:44.167985: Pseudo dice [0.8443, 0.8359, 0.8036, 0.8553, 0.7925, 0.7753] 
2025-01-11 13:52:44.168007: Epoch time: 43.29 s 
2025-01-11 13:52:44.652912:  
2025-01-11 13:52:44.652958: Epoch 61 
2025-01-11 13:52:44.652994: Current learning rate: 0.00777 
2025-01-11 13:53:27.940614: train_loss -0.4223 
2025-01-11 13:53:27.940691: val_loss -0.4717 
2025-01-11 13:53:27.940731: Pseudo dice [0.8238, 0.8296, 0.83, 0.8481, 0.8186, 0.7829] 
2025-01-11 13:53:27.940761: Epoch time: 43.29 s 
2025-01-11 13:53:27.940782: Yayy! New best EMA pseudo Dice: 0.8013 
2025-01-11 13:53:28.609054:  
2025-01-11 13:53:28.609111: Epoch 62 
2025-01-11 13:53:28.609154: Current learning rate: 0.00774 
2025-01-11 13:54:11.907648: train_loss -0.4333 
2025-01-11 13:54:11.907728: val_loss -0.4914 
2025-01-11 13:54:11.907760: Pseudo dice [0.8638, 0.8459, 0.8218, 0.8387, 0.8158, 0.7942] 
2025-01-11 13:54:11.907784: Epoch time: 43.3 s 
2025-01-11 13:54:11.907806: Yayy! New best EMA pseudo Dice: 0.8042 
2025-01-11 13:54:12.581267:  
2025-01-11 13:54:12.581318: Epoch 63 
2025-01-11 13:54:12.581355: Current learning rate: 0.0077 
2025-01-11 13:54:55.848658: train_loss -0.4491 
2025-01-11 13:54:55.848739: val_loss -0.4963 
2025-01-11 13:54:55.848770: Pseudo dice [0.8475, 0.8441, 0.7963, 0.8363, 0.8016, 0.7742] 
2025-01-11 13:54:55.848793: Epoch time: 43.27 s 
2025-01-11 13:54:55.848810: Yayy! New best EMA pseudo Dice: 0.8054 
2025-01-11 13:54:56.522893:  
2025-01-11 13:54:56.522957: Epoch 64 
2025-01-11 13:54:56.522997: Current learning rate: 0.00766 
2025-01-11 13:55:39.818666: train_loss -0.4681 
2025-01-11 13:55:39.818751: val_loss -0.4932 
2025-01-11 13:55:39.818791: Pseudo dice [0.8592, 0.8476, 0.8124, 0.8488, 0.7876, 0.7858] 
2025-01-11 13:55:39.818817: Epoch time: 43.3 s 
2025-01-11 13:55:39.818834: Yayy! New best EMA pseudo Dice: 0.8073 
2025-01-11 13:55:40.760292:  
2025-01-11 13:55:40.760365: Epoch 65 
2025-01-11 13:55:40.760427: Current learning rate: 0.00763 
2025-01-11 13:56:24.069441: train_loss -0.4666 
2025-01-11 13:56:24.069521: val_loss -0.49 
2025-01-11 13:56:24.069557: Pseudo dice [0.8484, 0.8426, 0.7998, 0.8567, 0.8206, 0.8128] 
2025-01-11 13:56:24.069580: Epoch time: 43.31 s 
2025-01-11 13:56:24.069597: Yayy! New best EMA pseudo Dice: 0.8095 
2025-01-11 13:56:24.743002:  
2025-01-11 13:56:24.743059: Epoch 66 
2025-01-11 13:56:24.743103: Current learning rate: 0.00759 
2025-01-11 13:57:08.020899: train_loss -0.4742 
2025-01-11 13:57:08.020974: val_loss -0.4598 
2025-01-11 13:57:08.021015: Pseudo dice [0.8314, 0.8425, 0.8362, 0.8447, 0.8245, 0.788] 
2025-01-11 13:57:08.021044: Epoch time: 43.28 s 
2025-01-11 13:57:08.021065: Yayy! New best EMA pseudo Dice: 0.8114 
2025-01-11 13:57:08.697555:  
2025-01-11 13:57:08.697612: Epoch 67 
2025-01-11 13:57:08.697650: Current learning rate: 0.00755 
2025-01-11 13:57:51.960926: train_loss -0.4731 
2025-01-11 13:57:51.961016: val_loss -0.4872 
2025-01-11 13:57:51.961059: Pseudo dice [0.8453, 0.8519, 0.8075, 0.8429, 0.8289, 0.7953] 
2025-01-11 13:57:51.961088: Epoch time: 43.26 s 
2025-01-11 13:57:51.961109: Yayy! New best EMA pseudo Dice: 0.8131 
2025-01-11 13:57:52.647263:  
2025-01-11 13:57:52.647318: Epoch 68 
2025-01-11 13:57:52.647354: Current learning rate: 0.00751 
2025-01-11 13:58:35.951206: train_loss -0.4602 
2025-01-11 13:58:35.951282: val_loss -0.4347 
2025-01-11 13:58:35.951322: Pseudo dice [0.8462, 0.8332, 0.7977, 0.8386, 0.7762, 0.7918] 
2025-01-11 13:58:35.951351: Epoch time: 43.3 s 
2025-01-11 13:58:35.951371: Yayy! New best EMA pseudo Dice: 0.8132 
2025-01-11 13:58:36.633100:  
2025-01-11 13:58:36.633219: Epoch 69 
2025-01-11 13:58:36.633256: Current learning rate: 0.00748 
2025-01-11 13:59:19.942044: train_loss -0.4814 
2025-01-11 13:59:19.942116: val_loss -0.4678 
2025-01-11 13:59:19.942148: Pseudo dice [0.8474, 0.8436, 0.8152, 0.8565, 0.8293, 0.796] 
2025-01-11 13:59:19.942188: Epoch time: 43.31 s 
2025-01-11 13:59:19.942208: Yayy! New best EMA pseudo Dice: 0.815 
2025-01-11 13:59:20.627609:  
2025-01-11 13:59:20.627695: Epoch 70 
2025-01-11 13:59:20.627739: Current learning rate: 0.00744 
2025-01-11 14:00:03.901067: train_loss -0.4749 
2025-01-11 14:00:03.901144: val_loss -0.484 
2025-01-11 14:00:03.901180: Pseudo dice [0.8365, 0.8477, 0.8244, 0.8501, 0.801, 0.7938] 
2025-01-11 14:00:03.901203: Epoch time: 43.27 s 
2025-01-11 14:00:03.901219: Yayy! New best EMA pseudo Dice: 0.8161 
2025-01-11 14:00:04.586083:  
2025-01-11 14:00:04.586138: Epoch 71 
2025-01-11 14:00:04.586181: Current learning rate: 0.0074 
2025-01-11 14:00:47.892170: train_loss -0.4683 
2025-01-11 14:00:47.892246: val_loss -0.4872 
2025-01-11 14:00:47.892277: Pseudo dice [0.8623, 0.8386, 0.8136, 0.826, 0.8067, 0.7771] 
2025-01-11 14:00:47.892300: Epoch time: 43.31 s 
2025-01-11 14:00:47.892317: Yayy! New best EMA pseudo Dice: 0.8165 
2025-01-11 14:00:48.573749:  
2025-01-11 14:00:48.573812: Epoch 72 
2025-01-11 14:00:48.573858: Current learning rate: 0.00737 
2025-01-11 14:01:31.867350: train_loss -0.4804 
2025-01-11 14:01:31.867442: val_loss -0.478 
2025-01-11 14:01:31.867484: Pseudo dice [0.8599, 0.8473, 0.826, 0.8562, 0.8419, 0.8241] 
2025-01-11 14:01:31.867514: Epoch time: 43.29 s 
2025-01-11 14:01:31.867535: Yayy! New best EMA pseudo Dice: 0.8191 
2025-01-11 14:01:32.552538:  
2025-01-11 14:01:32.552609: Epoch 73 
2025-01-11 14:01:32.552649: Current learning rate: 0.00733 
2025-01-11 14:02:15.853394: train_loss -0.4686 
2025-01-11 14:02:15.853483: val_loss -0.4846 
2025-01-11 14:02:15.853524: Pseudo dice [0.8711, 0.852, 0.8189, 0.8506, 0.8009, 0.7878] 
2025-01-11 14:02:15.853552: Epoch time: 43.3 s 
2025-01-11 14:02:15.853568: Yayy! New best EMA pseudo Dice: 0.8202 
2025-01-11 14:02:16.540230:  
2025-01-11 14:02:16.540290: Epoch 74 
2025-01-11 14:02:16.540332: Current learning rate: 0.00729 
2025-01-11 14:02:59.820519: train_loss -0.4758 
2025-01-11 14:02:59.820595: val_loss -0.4886 
2025-01-11 14:02:59.820634: Pseudo dice [0.8506, 0.8507, 0.8203, 0.8653, 0.8155, 0.8012] 
2025-01-11 14:02:59.820663: Epoch time: 43.28 s 
2025-01-11 14:02:59.820684: Yayy! New best EMA pseudo Dice: 0.8216 
2025-01-11 14:03:00.500816:  
2025-01-11 14:03:00.500867: Epoch 75 
2025-01-11 14:03:00.500907: Current learning rate: 0.00725 
2025-01-11 14:03:43.800313: train_loss -0.4674 
2025-01-11 14:03:43.800388: val_loss -0.42 
2025-01-11 14:03:43.800428: Pseudo dice [0.8705, 0.8221, 0.81, 0.8424, 0.8056, 0.7587] 
2025-01-11 14:03:43.800457: Epoch time: 43.3 s 
2025-01-11 14:03:44.298364:  
2025-01-11 14:03:44.298416: Epoch 76 
2025-01-11 14:03:44.298456: Current learning rate: 0.00722 
2025-01-11 14:04:27.948825: train_loss -0.4513 
2025-01-11 14:04:27.948898: val_loss -0.4913 
2025-01-11 14:04:27.948929: Pseudo dice [0.8517, 0.8581, 0.8209, 0.8502, 0.8035, 0.7912] 
2025-01-11 14:04:27.948952: Epoch time: 43.65 s 
2025-01-11 14:04:27.948969: Yayy! New best EMA pseudo Dice: 0.8221 
2025-01-11 14:04:28.627629:  
2025-01-11 14:04:28.627688: Epoch 77 
2025-01-11 14:04:28.627737: Current learning rate: 0.00718 
2025-01-11 14:05:12.829087: train_loss -0.4812 
2025-01-11 14:05:12.829178: val_loss -0.4933 
2025-01-11 14:05:12.829210: Pseudo dice [0.8194, 0.8569, 0.8431, 0.8502, 0.8296, 0.799] 
2025-01-11 14:05:12.829234: Epoch time: 44.2 s 
2025-01-11 14:05:12.829250: Yayy! New best EMA pseudo Dice: 0.8232 
2025-01-11 14:05:13.489468:  
2025-01-11 14:05:13.489534: Epoch 78 
2025-01-11 14:05:13.489579: Current learning rate: 0.00714 
2025-01-11 14:05:57.549767: train_loss -0.4627 
2025-01-11 14:05:57.549847: val_loss -0.4868 
2025-01-11 14:05:57.549890: Pseudo dice [0.8608, 0.8696, 0.8404, 0.849, 0.8068, 0.8117] 
2025-01-11 14:05:57.549918: Epoch time: 44.06 s 
2025-01-11 14:05:57.549935: Yayy! New best EMA pseudo Dice: 0.8248 
2025-01-11 14:05:58.241709:  
2025-01-11 14:05:58.241782: Epoch 79 
2025-01-11 14:05:58.241824: Current learning rate: 0.0071 
2025-01-11 14:06:42.666517: train_loss -0.4975 
2025-01-11 14:06:42.666602: val_loss -0.4977 
2025-01-11 14:06:42.666642: Pseudo dice [0.8213, 0.8502, 0.8136, 0.8609, 0.7966, 0.8221] 
2025-01-11 14:06:42.666672: Epoch time: 44.43 s 
2025-01-11 14:06:42.666693: Yayy! New best EMA pseudo Dice: 0.8251 
2025-01-11 14:06:43.355070:  
2025-01-11 14:06:43.355128: Epoch 80 
2025-01-11 14:06:43.355169: Current learning rate: 0.00707 
2025-01-11 14:07:26.979387: train_loss -0.4732 
2025-01-11 14:07:26.979480: val_loss -0.473 
2025-01-11 14:07:26.979520: Pseudo dice [0.8668, 0.8531, 0.7979, 0.8399, 0.77, 0.8199] 
2025-01-11 14:07:26.979549: Epoch time: 43.62 s 
2025-01-11 14:07:27.489343:  
2025-01-11 14:07:27.489395: Epoch 81 
2025-01-11 14:07:27.489430: Current learning rate: 0.00703 
2025-01-11 14:08:11.223381: train_loss -0.4969 
2025-01-11 14:08:11.223459: val_loss -0.4786 
2025-01-11 14:08:11.223491: Pseudo dice [0.835, 0.8509, 0.8389, 0.8506, 0.8294, 0.8235] 
2025-01-11 14:08:11.223516: Epoch time: 43.73 s 
2025-01-11 14:08:11.223533: Yayy! New best EMA pseudo Dice: 0.8263 
2025-01-11 14:08:11.918710:  
2025-01-11 14:08:11.918775: Epoch 82 
2025-01-11 14:08:11.918814: Current learning rate: 0.00699 
2025-01-11 14:08:56.032300: train_loss -0.4755 
2025-01-11 14:08:56.032375: val_loss -0.4585 
2025-01-11 14:08:56.032414: Pseudo dice [0.8391, 0.8329, 0.8303, 0.8539, 0.7637, 0.7505] 
2025-01-11 14:08:56.032443: Epoch time: 44.11 s 
2025-01-11 14:08:56.794155:  
2025-01-11 14:08:56.794234: Epoch 83 
2025-01-11 14:08:56.794276: Current learning rate: 0.00696 
2025-01-11 14:09:42.148279: train_loss -0.4722 
2025-01-11 14:09:42.148356: val_loss -0.5271 
2025-01-11 14:09:42.148397: Pseudo dice [0.8558, 0.848, 0.8367, 0.8558, 0.8194, 0.8095] 
2025-01-11 14:09:42.148427: Epoch time: 45.35 s 
2025-01-11 14:09:42.626966:  
2025-01-11 14:09:42.627039: Epoch 84 
2025-01-11 14:09:42.627087: Current learning rate: 0.00692 
2025-01-11 14:10:28.212493: train_loss -0.5009 
2025-01-11 14:10:28.212578: val_loss -0.5089 
2025-01-11 14:10:28.212618: Pseudo dice [0.8602, 0.8634, 0.8612, 0.883, 0.8252, 0.8316] 
2025-01-11 14:10:28.212648: Epoch time: 45.59 s 
2025-01-11 14:10:28.212669: Yayy! New best EMA pseudo Dice: 0.8289 
2025-01-11 14:10:28.878154:  
2025-01-11 14:10:28.878218: Epoch 85 
2025-01-11 14:10:28.878263: Current learning rate: 0.00688 
2025-01-11 14:11:13.252255: train_loss -0.4829 
2025-01-11 14:11:13.252338: val_loss -0.4721 
2025-01-11 14:11:13.252377: Pseudo dice [0.8146, 0.8527, 0.8221, 0.8504, 0.7883, 0.7746] 
2025-01-11 14:11:13.252401: Epoch time: 44.37 s 
2025-01-11 14:11:13.729126:  
2025-01-11 14:11:13.729187: Epoch 86 
2025-01-11 14:11:13.729225: Current learning rate: 0.00684 
2025-01-11 14:11:58.711112: train_loss -0.4703 
2025-01-11 14:11:58.711186: val_loss -0.5223 
2025-01-11 14:11:58.711218: Pseudo dice [0.8797, 0.8617, 0.8495, 0.8458, 0.8392, 0.8152] 
2025-01-11 14:11:58.711242: Epoch time: 44.98 s 
2025-01-11 14:11:58.711258: Yayy! New best EMA pseudo Dice: 0.8298 
2025-01-11 14:11:59.376582:  
2025-01-11 14:11:59.376649: Epoch 87 
2025-01-11 14:11:59.376694: Current learning rate: 0.0068 
2025-01-11 14:12:42.919914: train_loss -0.4907 
2025-01-11 14:12:42.919990: val_loss -0.4755 
2025-01-11 14:12:42.920038: Pseudo dice [0.8608, 0.8546, 0.8379, 0.8748, 0.8028, 0.8339] 
2025-01-11 14:12:42.920064: Epoch time: 43.54 s 
2025-01-11 14:12:42.920080: Yayy! New best EMA pseudo Dice: 0.8313 
2025-01-11 14:12:43.575736:  
2025-01-11 14:12:43.575798: Epoch 88 
2025-01-11 14:12:43.575838: Current learning rate: 0.00677 
2025-01-11 14:13:27.111270: train_loss -0.4747 
2025-01-11 14:13:27.111344: val_loss -0.51 
2025-01-11 14:13:27.111376: Pseudo dice [0.8863, 0.864, 0.8586, 0.8531, 0.8497, 0.7863] 
2025-01-11 14:13:27.111401: Epoch time: 43.54 s 
2025-01-11 14:13:27.111417: Yayy! New best EMA pseudo Dice: 0.8331 
2025-01-11 14:13:27.775028:  
2025-01-11 14:13:27.775097: Epoch 89 
2025-01-11 14:13:27.775141: Current learning rate: 0.00673 
2025-01-11 14:14:11.304335: train_loss -0.4693 
2025-01-11 14:14:11.304409: val_loss -0.5073 
2025-01-11 14:14:11.304450: Pseudo dice [0.8152, 0.8486, 0.834, 0.8354, 0.8293, 0.8104] 
2025-01-11 14:14:11.304485: Epoch time: 43.53 s 
2025-01-11 14:14:11.781891:  
2025-01-11 14:14:11.781956: Epoch 90 
2025-01-11 14:14:11.781993: Current learning rate: 0.00669 
2025-01-11 14:14:55.323853: train_loss -0.4674 
2025-01-11 14:14:55.323932: val_loss -0.4847 
2025-01-11 14:14:55.323972: Pseudo dice [0.8677, 0.8508, 0.8493, 0.8713, 0.833, 0.7898] 
2025-01-11 14:14:55.324002: Epoch time: 43.54 s 
2025-01-11 14:14:55.324022: Yayy! New best EMA pseudo Dice: 0.8338 
2025-01-11 14:14:55.984547:  
2025-01-11 14:14:55.984613: Epoch 91 
2025-01-11 14:14:55.984655: Current learning rate: 0.00665 
2025-01-11 14:15:39.488813: train_loss -0.481 
2025-01-11 14:15:39.488899: val_loss -0.4924 
2025-01-11 14:15:39.488940: Pseudo dice [0.8534, 0.836, 0.8335, 0.8341, 0.8092, 0.801] 
2025-01-11 14:15:39.488969: Epoch time: 43.5 s 
2025-01-11 14:15:39.968895:  
2025-01-11 14:15:39.968945: Epoch 92 
2025-01-11 14:15:39.968983: Current learning rate: 0.00662 
2025-01-11 14:16:23.500119: train_loss -0.4724 
2025-01-11 14:16:23.500191: val_loss -0.524 
2025-01-11 14:16:23.500238: Pseudo dice [0.859, 0.8627, 0.8469, 0.8539, 0.8261, 0.8151] 
2025-01-11 14:16:23.500263: Epoch time: 43.53 s 
2025-01-11 14:16:23.500280: Yayy! New best EMA pseudo Dice: 0.8343 
2025-01-11 14:16:24.171988:  
2025-01-11 14:16:24.172045: Epoch 93 
2025-01-11 14:16:24.172086: Current learning rate: 0.00658 
2025-01-11 14:17:07.706120: train_loss -0.4931 
2025-01-11 14:17:07.706202: val_loss -0.511 
2025-01-11 14:17:07.706241: Pseudo dice [0.8333, 0.8611, 0.8344, 0.8304, 0.8111, 0.8056] 
2025-01-11 14:17:07.706270: Epoch time: 43.53 s 
2025-01-11 14:17:08.182082:  
2025-01-11 14:17:08.182155: Epoch 94 
2025-01-11 14:17:08.182196: Current learning rate: 0.00654 
2025-01-11 14:17:51.715039: train_loss -0.4942 
2025-01-11 14:17:51.715126: val_loss -0.4679 
2025-01-11 14:17:51.715159: Pseudo dice [0.8478, 0.8498, 0.8157, 0.8283, 0.7838, 0.7567] 
2025-01-11 14:17:51.715187: Epoch time: 43.53 s 
2025-01-11 14:17:52.193926:  
2025-01-11 14:17:52.193978: Epoch 95 
2025-01-11 14:17:52.194016: Current learning rate: 0.0065 
2025-01-11 14:18:35.722795: train_loss -0.4755 
2025-01-11 14:18:35.722876: val_loss -0.5159 
2025-01-11 14:18:35.722914: Pseudo dice [0.8756, 0.849, 0.8029, 0.8676, 0.8056, 0.8227] 
2025-01-11 14:18:35.722938: Epoch time: 43.53 s 
2025-01-11 14:18:36.199638:  
2025-01-11 14:18:36.199689: Epoch 96 
2025-01-11 14:18:36.199726: Current learning rate: 0.00647 
2025-01-11 14:19:19.729807: train_loss -0.4712 
2025-01-11 14:19:19.729885: val_loss -0.4965 
2025-01-11 14:19:19.729926: Pseudo dice [0.8606, 0.8569, 0.8333, 0.8599, 0.8086, 0.7865] 
2025-01-11 14:19:19.729955: Epoch time: 43.53 s 
2025-01-11 14:19:20.220441:  
2025-01-11 14:19:20.220489: Epoch 97 
2025-01-11 14:19:20.220527: Current learning rate: 0.00643 
2025-01-11 14:20:03.746709: train_loss -0.4832 
2025-01-11 14:20:03.746787: val_loss -0.4901 
2025-01-11 14:20:03.746825: Pseudo dice [0.8583, 0.8527, 0.8428, 0.8753, 0.8137, 0.8036] 
2025-01-11 14:20:03.746852: Epoch time: 43.53 s 
2025-01-11 14:20:04.235213:  
2025-01-11 14:20:04.235265: Epoch 98 
2025-01-11 14:20:04.235302: Current learning rate: 0.00639 
2025-01-11 14:20:47.764576: train_loss -0.466 
2025-01-11 14:20:47.764650: val_loss -0.4844 
2025-01-11 14:20:47.764689: Pseudo dice [0.8686, 0.8396, 0.8203, 0.8244, 0.825, 0.7975] 
2025-01-11 14:20:47.764727: Epoch time: 43.53 s 
2025-01-11 14:20:48.249771:  
2025-01-11 14:20:48.249831: Epoch 99 
2025-01-11 14:20:48.249870: Current learning rate: 0.00635 
2025-01-11 14:21:31.781906: train_loss -0.486 
2025-01-11 14:21:31.781983: val_loss -0.4864 
2025-01-11 14:21:31.782023: Pseudo dice [0.8608, 0.8586, 0.8566, 0.8608, 0.8476, 0.8291] 
2025-01-11 14:21:31.782051: Epoch time: 43.53 s 
2025-01-11 14:21:31.970092: Yayy! New best EMA pseudo Dice: 0.8349 
2025-01-11 14:21:32.642250:  
2025-01-11 14:21:32.642303: Epoch 100 
2025-01-11 14:21:32.642348: Current learning rate: 0.00631 
2025-01-11 14:22:16.120112: train_loss -0.4923 
2025-01-11 14:22:16.120193: val_loss -0.5121 
2025-01-11 14:22:16.120239: Pseudo dice [0.8464, 0.8654, 0.8364, 0.8508, 0.8223, 0.8057] 
2025-01-11 14:22:16.120270: Epoch time: 43.48 s 
2025-01-11 14:22:16.120290: Yayy! New best EMA pseudo Dice: 0.8352 
2025-01-11 14:22:17.073225:  
2025-01-11 14:22:17.073290: Epoch 101 
2025-01-11 14:22:17.073331: Current learning rate: 0.00628 
2025-01-11 14:23:00.604253: train_loss -0.4962 
2025-01-11 14:23:00.604331: val_loss -0.5347 
2025-01-11 14:23:00.604364: Pseudo dice [0.871, 0.8646, 0.8427, 0.8716, 0.8504, 0.8306] 
2025-01-11 14:23:00.604388: Epoch time: 43.53 s 
2025-01-11 14:23:00.604405: Yayy! New best EMA pseudo Dice: 0.8372 
2025-01-11 14:23:01.277160:  
2025-01-11 14:23:01.277245: Epoch 102 
2025-01-11 14:23:01.277286: Current learning rate: 0.00624 
2025-01-11 14:23:44.822891: train_loss -0.4674 
2025-01-11 14:23:44.822971: val_loss -0.5211 
2025-01-11 14:23:44.823014: Pseudo dice [0.863, 0.8342, 0.8309, 0.8683, 0.8367, 0.806] 
2025-01-11 14:23:44.823050: Epoch time: 43.55 s 
2025-01-11 14:23:44.823072: Yayy! New best EMA pseudo Dice: 0.8374 
2025-01-11 14:23:45.492073:  
2025-01-11 14:23:45.492150: Epoch 103 
2025-01-11 14:23:45.492195: Current learning rate: 0.0062 
2025-01-11 14:24:29.023499: train_loss -0.4942 
2025-01-11 14:24:29.023589: val_loss -0.5051 
2025-01-11 14:24:29.023631: Pseudo dice [0.8498, 0.8526, 0.8478, 0.8579, 0.8324, 0.8257] 
2025-01-11 14:24:29.023661: Epoch time: 43.53 s 
2025-01-11 14:24:29.023678: Yayy! New best EMA pseudo Dice: 0.8381 
2025-01-11 14:24:29.698161:  
2025-01-11 14:24:29.698257: Epoch 104 
2025-01-11 14:24:29.698297: Current learning rate: 0.00616 
2025-01-11 14:25:13.233167: train_loss -0.4888 
2025-01-11 14:25:13.233243: val_loss -0.4901 
2025-01-11 14:25:13.233284: Pseudo dice [0.8336, 0.8593, 0.8537, 0.8741, 0.8532, 0.8316] 
2025-01-11 14:25:13.233312: Epoch time: 43.54 s 
2025-01-11 14:25:13.233328: Yayy! New best EMA pseudo Dice: 0.8394 
2025-01-11 14:25:13.906090:  
2025-01-11 14:25:13.906154: Epoch 105 
2025-01-11 14:25:13.906195: Current learning rate: 0.00612 
2025-01-11 14:25:57.428143: train_loss -0.5008 
2025-01-11 14:25:57.428229: val_loss -0.5185 
2025-01-11 14:25:57.428270: Pseudo dice [0.8646, 0.8687, 0.8449, 0.8439, 0.8276, 0.8152] 
2025-01-11 14:25:57.428300: Epoch time: 43.52 s 
2025-01-11 14:25:57.428321: Yayy! New best EMA pseudo Dice: 0.8399 
2025-01-11 14:25:58.100874:  
2025-01-11 14:25:58.100982: Epoch 106 
2025-01-11 14:25:58.101039: Current learning rate: 0.00609 
2025-01-11 14:26:41.602041: train_loss -0.5157 
2025-01-11 14:26:41.602113: val_loss -0.5015 
2025-01-11 14:26:41.602145: Pseudo dice [0.8555, 0.8611, 0.8696, 0.8738, 0.8334, 0.8422] 
2025-01-11 14:26:41.602169: Epoch time: 43.5 s 
2025-01-11 14:26:41.602185: Yayy! New best EMA pseudo Dice: 0.8415 
2025-01-11 14:26:42.280600:  
2025-01-11 14:26:42.280660: Epoch 107 
2025-01-11 14:26:42.280701: Current learning rate: 0.00605 
2025-01-11 14:27:26.127628: train_loss -0.4859 
2025-01-11 14:27:26.127704: val_loss -0.4883 
2025-01-11 14:27:26.127737: Pseudo dice [0.8749, 0.8667, 0.8289, 0.8468, 0.8198, 0.7884] 
2025-01-11 14:27:26.127761: Epoch time: 43.85 s 
2025-01-11 14:27:26.618301:  
2025-01-11 14:27:26.618355: Epoch 108 
2025-01-11 14:27:26.618397: Current learning rate: 0.00601 
2025-01-11 14:28:10.148248: train_loss -0.4821 
2025-01-11 14:28:10.148328: val_loss -0.5154 
2025-01-11 14:28:10.148360: Pseudo dice [0.8866, 0.8624, 0.8323, 0.8653, 0.8143, 0.7979] 
2025-01-11 14:28:10.148384: Epoch time: 43.53 s 
2025-01-11 14:28:10.637022:  
2025-01-11 14:28:10.637118: Epoch 109 
2025-01-11 14:28:10.637164: Current learning rate: 0.00597 
2025-01-11 14:28:54.189187: train_loss -0.4924 
2025-01-11 14:28:54.189262: val_loss -0.5033 
2025-01-11 14:28:54.189303: Pseudo dice [0.8904, 0.8684, 0.8524, 0.8693, 0.8435, 0.8282] 
2025-01-11 14:28:54.189329: Epoch time: 43.55 s 
2025-01-11 14:28:54.189346: Yayy! New best EMA pseudo Dice: 0.843 
2025-01-11 14:28:54.873589:  
2025-01-11 14:28:54.873646: Epoch 110 
2025-01-11 14:28:54.873688: Current learning rate: 0.00593 
2025-01-11 14:29:38.373812: train_loss -0.4834 
2025-01-11 14:29:38.373891: val_loss -0.5009 
2025-01-11 14:29:38.373931: Pseudo dice [0.8779, 0.8463, 0.8261, 0.8578, 0.815, 0.8151] 
2025-01-11 14:29:38.373962: Epoch time: 43.5 s 
2025-01-11 14:29:38.864411:  
2025-01-11 14:29:38.864457: Epoch 111 
2025-01-11 14:29:38.864494: Current learning rate: 0.0059 
2025-01-11 14:30:22.408960: train_loss -0.4849 
2025-01-11 14:30:22.409038: val_loss -0.5431 
2025-01-11 14:30:22.409080: Pseudo dice [0.8718, 0.8725, 0.8565, 0.8566, 0.8375, 0.8118] 
2025-01-11 14:30:22.409111: Epoch time: 43.54 s 
2025-01-11 14:30:22.409133: Yayy! New best EMA pseudo Dice: 0.8436 
2025-01-11 14:30:23.077331:  
2025-01-11 14:30:23.077384: Epoch 112 
2025-01-11 14:30:23.077425: Current learning rate: 0.00586 
2025-01-11 14:31:06.607910: train_loss -0.49 
2025-01-11 14:31:06.607988: val_loss -0.5436 
2025-01-11 14:31:06.608021: Pseudo dice [0.8742, 0.8634, 0.8459, 0.8594, 0.8383, 0.8362] 
2025-01-11 14:31:06.608045: Epoch time: 43.53 s 
2025-01-11 14:31:06.608062: Yayy! New best EMA pseudo Dice: 0.8445 
2025-01-11 14:31:07.274446:  
2025-01-11 14:31:07.274517: Epoch 113 
2025-01-11 14:31:07.274563: Current learning rate: 0.00582 
2025-01-11 14:31:50.802569: train_loss -0.4829 
2025-01-11 14:31:50.802641: val_loss -0.4989 
2025-01-11 14:31:50.802673: Pseudo dice [0.894, 0.8584, 0.8328, 0.8589, 0.8535, 0.8395] 
2025-01-11 14:31:50.802696: Epoch time: 43.53 s 
2025-01-11 14:31:50.802713: Yayy! New best EMA pseudo Dice: 0.8457 
2025-01-11 14:31:51.468356:  
2025-01-11 14:31:51.468407: Epoch 114 
2025-01-11 14:31:51.468448: Current learning rate: 0.00578 
2025-01-11 14:32:35.009850: train_loss -0.501 
2025-01-11 14:32:35.009922: val_loss -0.5393 
2025-01-11 14:32:35.009962: Pseudo dice [0.8692, 0.871, 0.8419, 0.8744, 0.8384, 0.8147] 
2025-01-11 14:32:35.010001: Epoch time: 43.54 s 
2025-01-11 14:32:35.010021: Yayy! New best EMA pseudo Dice: 0.8463 
2025-01-11 14:32:35.683745:  
2025-01-11 14:32:35.683798: Epoch 115 
2025-01-11 14:32:35.683836: Current learning rate: 0.00574 
2025-01-11 14:33:19.220071: train_loss -0.4975 
2025-01-11 14:33:19.220150: val_loss -0.5301 
2025-01-11 14:33:19.220192: Pseudo dice [0.8779, 0.8598, 0.8542, 0.8725, 0.8592, 0.8404] 
2025-01-11 14:33:19.220230: Epoch time: 43.54 s 
2025-01-11 14:33:19.220259: Yayy! New best EMA pseudo Dice: 0.8477 
2025-01-11 14:33:19.893638:  
2025-01-11 14:33:19.893705: Epoch 116 
2025-01-11 14:33:19.893750: Current learning rate: 0.0057 
2025-01-11 14:34:03.438295: train_loss -0.4946 
2025-01-11 14:34:03.438382: val_loss -0.5164 
2025-01-11 14:34:03.438413: Pseudo dice [0.8832, 0.865, 0.8506, 0.8816, 0.8269, 0.8265] 
2025-01-11 14:34:03.438442: Epoch time: 43.55 s 
2025-01-11 14:34:03.438457: Yayy! New best EMA pseudo Dice: 0.8485 
2025-01-11 14:34:04.118211:  
2025-01-11 14:34:04.118272: Epoch 117 
2025-01-11 14:34:04.118312: Current learning rate: 0.00567 
2025-01-11 14:34:47.655272: train_loss -0.5102 
2025-01-11 14:34:47.655347: val_loss -0.4614 
2025-01-11 14:34:47.655388: Pseudo dice [0.853, 0.8492, 0.8098, 0.8565, 0.8099, 0.8029] 
2025-01-11 14:34:47.655417: Epoch time: 43.54 s 
2025-01-11 14:34:48.427173:  
2025-01-11 14:34:48.427248: Epoch 118 
2025-01-11 14:34:48.427295: Current learning rate: 0.00563 
2025-01-11 14:35:31.997946: train_loss -0.4972 
2025-01-11 14:35:31.998030: val_loss -0.5092 
2025-01-11 14:35:31.998065: Pseudo dice [0.8648, 0.8686, 0.8334, 0.8722, 0.8109, 0.8212] 
2025-01-11 14:35:31.998088: Epoch time: 43.57 s 
2025-01-11 14:35:32.491800:  
2025-01-11 14:35:32.491867: Epoch 119 
2025-01-11 14:35:32.491904: Current learning rate: 0.00559 
2025-01-11 14:36:16.040929: train_loss -0.4896 
2025-01-11 14:36:16.041048: val_loss -0.4847 
2025-01-11 14:36:16.041083: Pseudo dice [0.8541, 0.8538, 0.807, 0.8542, 0.8151, 0.8355] 
2025-01-11 14:36:16.041106: Epoch time: 43.55 s 
2025-01-11 14:36:16.529951:  
2025-01-11 14:36:16.530020: Epoch 120 
2025-01-11 14:36:16.530056: Current learning rate: 0.00555 
2025-01-11 14:37:00.083598: train_loss -0.4725 
2025-01-11 14:37:00.083684: val_loss -0.4946 
2025-01-11 14:37:00.083731: Pseudo dice [0.8018, 0.8468, 0.8285, 0.8587, 0.8244, 0.8037] 
2025-01-11 14:37:00.083761: Epoch time: 43.55 s 
2025-01-11 14:37:00.577422:  
2025-01-11 14:37:00.577505: Epoch 121 
2025-01-11 14:37:00.577545: Current learning rate: 0.00551 
2025-01-11 14:37:44.121419: train_loss -0.4936 
2025-01-11 14:37:44.121499: val_loss -0.4897 
2025-01-11 14:37:44.121537: Pseudo dice [0.8545, 0.8516, 0.8014, 0.8139, 0.802, 0.8079] 
2025-01-11 14:37:44.121562: Epoch time: 43.54 s 
2025-01-11 14:37:44.615109:  
2025-01-11 14:37:44.615167: Epoch 122 
2025-01-11 14:37:44.615205: Current learning rate: 0.00547 
2025-01-11 14:38:28.168145: train_loss -0.4848 
2025-01-11 14:38:28.168225: val_loss -0.5274 
2025-01-11 14:38:28.168258: Pseudo dice [0.8142, 0.8654, 0.8407, 0.8299, 0.8308, 0.7817] 
2025-01-11 14:38:28.168283: Epoch time: 43.55 s 
2025-01-11 14:38:28.668997:  
2025-01-11 14:38:28.669064: Epoch 123 
2025-01-11 14:38:28.669114: Current learning rate: 0.00544 
2025-01-11 14:39:12.240470: train_loss -0.4851 
2025-01-11 14:39:12.240557: val_loss -0.5058 
2025-01-11 14:39:12.240597: Pseudo dice [0.8692, 0.866, 0.8574, 0.8633, 0.8465, 0.8163] 
2025-01-11 14:39:12.240631: Epoch time: 43.57 s 
2025-01-11 14:39:12.735863:  
2025-01-11 14:39:12.735961: Epoch 124 
2025-01-11 14:39:12.736011: Current learning rate: 0.0054 
2025-01-11 14:39:56.649546: train_loss -0.5093 
2025-01-11 14:39:56.649624: val_loss -0.5394 
2025-01-11 14:39:56.649674: Pseudo dice [0.8728, 0.8547, 0.842, 0.8582, 0.8343, 0.8312] 
2025-01-11 14:39:56.649710: Epoch time: 43.91 s 
2025-01-11 14:39:57.144397:  
2025-01-11 14:39:57.144455: Epoch 125 
2025-01-11 14:39:57.144493: Current learning rate: 0.00536 
2025-01-11 14:40:41.734064: train_loss -0.482 
2025-01-11 14:40:41.734142: val_loss -0.5243 
2025-01-11 14:40:41.734182: Pseudo dice [0.8626, 0.8514, 0.8374, 0.8834, 0.8357, 0.832] 
2025-01-11 14:40:41.734210: Epoch time: 44.59 s 
2025-01-11 14:40:42.228049:  
2025-01-11 14:40:42.228111: Epoch 126 
2025-01-11 14:40:42.228151: Current learning rate: 0.00532 
2025-01-11 14:41:26.413802: train_loss -0.4977 
2025-01-11 14:41:26.413880: val_loss -0.5176 
2025-01-11 14:41:26.413912: Pseudo dice [0.8823, 0.8677, 0.8261, 0.852, 0.8153, 0.8179] 
2025-01-11 14:41:26.413937: Epoch time: 44.19 s 
2025-01-11 14:41:26.916529:  
2025-01-11 14:41:26.916601: Epoch 127 
2025-01-11 14:41:26.916644: Current learning rate: 0.00528 
2025-01-11 14:42:11.930067: train_loss -0.4784 
2025-01-11 14:42:11.930153: val_loss -0.518 
2025-01-11 14:42:11.930192: Pseudo dice [0.8542, 0.8597, 0.847, 0.8708, 0.8571, 0.8444] 
2025-01-11 14:42:11.930220: Epoch time: 45.01 s 
2025-01-11 14:42:12.422997:  
2025-01-11 14:42:12.423056: Epoch 128 
2025-01-11 14:42:12.423096: Current learning rate: 0.00524 
2025-01-11 14:42:57.969687: train_loss -0.5002 
2025-01-11 14:42:57.969763: val_loss -0.5313 
2025-01-11 14:42:57.969794: Pseudo dice [0.8798, 0.8605, 0.8229, 0.8815, 0.8435, 0.8453] 
2025-01-11 14:42:57.969818: Epoch time: 45.55 s 
2025-01-11 14:42:58.470975:  
2025-01-11 14:42:58.471034: Epoch 129 
2025-01-11 14:42:58.471086: Current learning rate: 0.0052 
2025-01-11 14:43:45.283884: train_loss -0.5057 
2025-01-11 14:43:45.283960: val_loss -0.5474 
2025-01-11 14:43:45.283992: Pseudo dice [0.881, 0.867, 0.8489, 0.8637, 0.8433, 0.8047] 
2025-01-11 14:43:45.284016: Epoch time: 46.81 s 
2025-01-11 14:43:45.779286:  
2025-01-11 14:43:45.779348: Epoch 130 
2025-01-11 14:43:45.779390: Current learning rate: 0.00517 
2025-01-11 14:44:32.465266: train_loss -0.4942 
2025-01-11 14:44:32.465350: val_loss -0.5185 
2025-01-11 14:44:32.465389: Pseudo dice [0.8635, 0.8616, 0.8494, 0.8762, 0.8433, 0.8354] 
2025-01-11 14:44:32.465416: Epoch time: 46.69 s 
2025-01-11 14:44:32.961870:  
2025-01-11 14:44:32.961967: Epoch 131 
2025-01-11 14:44:32.962016: Current learning rate: 0.00513 
2025-01-11 14:45:19.763999: train_loss -0.5028 
2025-01-11 14:45:19.764089: val_loss -0.5194 
2025-01-11 14:45:19.764131: Pseudo dice [0.8654, 0.8678, 0.8652, 0.8869, 0.8559, 0.8523] 
2025-01-11 14:45:19.764162: Epoch time: 46.8 s 
2025-01-11 14:45:19.764189: Yayy! New best EMA pseudo Dice: 0.8488 
2025-01-11 14:45:20.447043:  
2025-01-11 14:45:20.447099: Epoch 132 
2025-01-11 14:45:20.447141: Current learning rate: 0.00509 
2025-01-11 14:46:07.187005: train_loss -0.5003 
2025-01-11 14:46:07.187084: val_loss -0.5402 
2025-01-11 14:46:07.187125: Pseudo dice [0.8855, 0.8674, 0.8284, 0.8767, 0.8319, 0.8275] 
2025-01-11 14:46:07.187154: Epoch time: 46.74 s 
2025-01-11 14:46:07.187173: Yayy! New best EMA pseudo Dice: 0.8492 
2025-01-11 14:46:07.875852:  
2025-01-11 14:46:07.875914: Epoch 133 
2025-01-11 14:46:07.875956: Current learning rate: 0.00505 
2025-01-11 14:46:54.664233: train_loss -0.5181 
2025-01-11 14:46:54.664312: val_loss -0.5162 
2025-01-11 14:46:54.664351: Pseudo dice [0.8602, 0.8602, 0.8501, 0.8748, 0.8373, 0.8303] 
2025-01-11 14:46:54.664381: Epoch time: 46.79 s 
2025-01-11 14:46:54.664402: Yayy! New best EMA pseudo Dice: 0.8495 
2025-01-11 14:46:55.356881:  
2025-01-11 14:46:55.356936: Epoch 134 
2025-01-11 14:46:55.356979: Current learning rate: 0.00501 
2025-01-11 14:47:41.355667: train_loss -0.4882 
2025-01-11 14:47:41.355746: val_loss -0.4878 
2025-01-11 14:47:41.355792: Pseudo dice [0.882, 0.8696, 0.8381, 0.8697, 0.8098, 0.8167] 
2025-01-11 14:47:41.355819: Epoch time: 46.0 s 
2025-01-11 14:47:41.859093:  
2025-01-11 14:47:41.859144: Epoch 135 
2025-01-11 14:47:41.859185: Current learning rate: 0.00497 
2025-01-11 14:48:26.836636: train_loss -0.5061 
2025-01-11 14:48:26.836739: val_loss -0.5636 
2025-01-11 14:48:26.836787: Pseudo dice [0.8907, 0.8774, 0.8612, 0.8881, 0.8391, 0.8497] 
2025-01-11 14:48:26.836817: Epoch time: 44.98 s 
2025-01-11 14:48:26.836838: Yayy! New best EMA pseudo Dice: 0.8511 
2025-01-11 14:48:27.830864:  
2025-01-11 14:48:27.830932: Epoch 136 
2025-01-11 14:48:27.830983: Current learning rate: 0.00493 
2025-01-11 14:49:14.470593: train_loss -0.4908 
2025-01-11 14:49:14.470662: val_loss -0.5037 
2025-01-11 14:49:14.470694: Pseudo dice [0.8668, 0.869, 0.8346, 0.8697, 0.8389, 0.817] 
2025-01-11 14:49:14.470718: Epoch time: 46.64 s 
2025-01-11 14:49:14.969426:  
2025-01-11 14:49:14.969502: Epoch 137 
2025-01-11 14:49:14.969547: Current learning rate: 0.00489 
2025-01-11 14:50:02.006179: train_loss -0.5007 
2025-01-11 14:50:02.006266: val_loss -0.487 
2025-01-11 14:50:02.006301: Pseudo dice [0.8861, 0.8594, 0.8453, 0.8729, 0.8301, 0.8286] 
2025-01-11 14:50:02.006327: Epoch time: 47.04 s 
2025-01-11 14:50:02.006345: Yayy! New best EMA pseudo Dice: 0.8512 
2025-01-11 14:50:02.694078:  
2025-01-11 14:50:02.694155: Epoch 138 
2025-01-11 14:50:02.694199: Current learning rate: 0.00485 
2025-01-11 14:50:49.172754: train_loss -0.5055 
2025-01-11 14:50:49.172819: val_loss -0.5481 
2025-01-11 14:50:49.172850: Pseudo dice [0.863, 0.8747, 0.8473, 0.8816, 0.8435, 0.8309] 
2025-01-11 14:50:49.172874: Epoch time: 46.48 s 
2025-01-11 14:50:49.172890: Yayy! New best EMA pseudo Dice: 0.8518 
2025-01-11 14:50:49.856659:  
2025-01-11 14:50:49.856716: Epoch 139 
2025-01-11 14:50:49.856754: Current learning rate: 0.00482 
2025-01-11 14:51:33.696756: train_loss -0.518 
2025-01-11 14:51:33.696832: val_loss -0.5056 
2025-01-11 14:51:33.696873: Pseudo dice [0.8645, 0.859, 0.8538, 0.8615, 0.8381, 0.8322] 
2025-01-11 14:51:33.696904: Epoch time: 43.84 s 
2025-01-11 14:51:34.195799:  
2025-01-11 14:51:34.195866: Epoch 140 
2025-01-11 14:51:34.195908: Current learning rate: 0.00478 
2025-01-11 14:52:17.677812: train_loss -0.5171 
2025-01-11 14:52:17.677888: val_loss -0.4926 
2025-01-11 14:52:17.677931: Pseudo dice [0.8767, 0.8583, 0.8464, 0.8492, 0.8452, 0.8152] 
2025-01-11 14:52:17.677960: Epoch time: 43.48 s 
2025-01-11 14:52:18.176746:  
2025-01-11 14:52:18.176805: Epoch 141 
2025-01-11 14:52:18.176842: Current learning rate: 0.00474 
2025-01-11 14:53:01.680639: train_loss -0.5057 
2025-01-11 14:53:01.680717: val_loss -0.5087 
2025-01-11 14:53:01.680764: Pseudo dice [0.8696, 0.8621, 0.8537, 0.8658, 0.8452, 0.8036] 
2025-01-11 14:53:01.680789: Epoch time: 43.5 s 
2025-01-11 14:53:02.179477:  
2025-01-11 14:53:02.179539: Epoch 142 
2025-01-11 14:53:02.179586: Current learning rate: 0.0047 
2025-01-11 14:53:46.397232: train_loss -0.5184 
2025-01-11 14:53:46.397307: val_loss -0.4916 
2025-01-11 14:53:46.397342: Pseudo dice [0.876, 0.8645, 0.8514, 0.8652, 0.8538, 0.8349] 
2025-01-11 14:53:46.397367: Epoch time: 44.22 s 
2025-01-11 14:53:46.397386: Yayy! New best EMA pseudo Dice: 0.8519 
2025-01-11 14:53:47.089717:  
2025-01-11 14:53:47.089779: Epoch 143 
2025-01-11 14:53:47.089820: Current learning rate: 0.00466 
2025-01-11 14:54:31.136794: train_loss -0.5136 
2025-01-11 14:54:31.136874: val_loss -0.4883 
2025-01-11 14:54:31.136918: Pseudo dice [0.8897, 0.8708, 0.8519, 0.8753, 0.8389, 0.8192] 
2025-01-11 14:54:31.136947: Epoch time: 44.05 s 
2025-01-11 14:54:31.136964: Yayy! New best EMA pseudo Dice: 0.8525 
2025-01-11 14:54:31.817259:  
2025-01-11 14:54:31.817324: Epoch 144 
2025-01-11 14:54:31.817361: Current learning rate: 0.00462 
2025-01-11 14:55:15.297390: train_loss -0.522 
2025-01-11 14:55:15.297467: val_loss -0.5279 
2025-01-11 14:55:15.297503: Pseudo dice [0.8646, 0.8626, 0.8217, 0.8379, 0.8074, 0.79] 
2025-01-11 14:55:15.297526: Epoch time: 43.48 s 
2025-01-11 14:55:15.792081:  
2025-01-11 14:55:15.792136: Epoch 145 
2025-01-11 14:55:15.792173: Current learning rate: 0.00458 
2025-01-11 14:55:59.301597: train_loss -0.5041 
2025-01-11 14:55:59.301686: val_loss -0.5201 
2025-01-11 14:55:59.301728: Pseudo dice [0.8606, 0.8731, 0.8486, 0.8905, 0.8509, 0.8381] 
2025-01-11 14:55:59.301755: Epoch time: 43.51 s 
2025-01-11 14:55:59.806369:  
2025-01-11 14:55:59.806463: Epoch 146 
2025-01-11 14:55:59.806517: Current learning rate: 0.00454 
2025-01-11 14:56:44.060332: train_loss -0.5074 
2025-01-11 14:56:44.060407: val_loss -0.5012 
2025-01-11 14:56:44.060447: Pseudo dice [0.8739, 0.8594, 0.8366, 0.8825, 0.8605, 0.8395] 
2025-01-11 14:56:44.060477: Epoch time: 44.25 s 
2025-01-11 14:56:44.559319:  
2025-01-11 14:56:44.559381: Epoch 147 
2025-01-11 14:56:44.559424: Current learning rate: 0.0045 
2025-01-11 14:57:28.122346: train_loss -0.5048 
2025-01-11 14:57:28.122424: val_loss -0.5714 
2025-01-11 14:57:28.122458: Pseudo dice [0.8957, 0.8766, 0.8662, 0.8857, 0.8622, 0.8441] 
2025-01-11 14:57:28.122483: Epoch time: 43.56 s 
2025-01-11 14:57:28.122501: Yayy! New best EMA pseudo Dice: 0.854 
2025-01-11 14:57:28.805799:  
2025-01-11 14:57:28.805844: Epoch 148 
2025-01-11 14:57:28.805879: Current learning rate: 0.00446 
2025-01-11 14:58:12.529966: train_loss -0.5268 
2025-01-11 14:58:12.530043: val_loss -0.5288 
2025-01-11 14:58:12.530075: Pseudo dice [0.8803, 0.869, 0.841, 0.874, 0.8438, 0.8378] 
2025-01-11 14:58:12.530098: Epoch time: 43.72 s 
2025-01-11 14:58:12.530114: Yayy! New best EMA pseudo Dice: 0.8544 
2025-01-11 14:58:13.215367:  
2025-01-11 14:58:13.215426: Epoch 149 
2025-01-11 14:58:13.215468: Current learning rate: 0.00442 
2025-01-11 14:58:58.118839: train_loss -0.5201 
2025-01-11 14:58:58.118921: val_loss -0.5286 
2025-01-11 14:58:58.118958: Pseudo dice [0.8826, 0.8715, 0.8662, 0.8809, 0.867, 0.829] 
2025-01-11 14:58:58.118987: Epoch time: 44.9 s 
2025-01-11 14:58:58.298788: Yayy! New best EMA pseudo Dice: 0.8556 
2025-01-11 14:58:58.989227:  
2025-01-11 14:58:58.989289: Epoch 150 
2025-01-11 14:58:58.989333: Current learning rate: 0.00438 
2025-01-11 14:59:43.005176: train_loss -0.5144 
2025-01-11 14:59:43.005249: val_loss -0.5507 
2025-01-11 14:59:43.005280: Pseudo dice [0.8665, 0.8596, 0.8492, 0.8541, 0.8498, 0.8273] 
2025-01-11 14:59:43.005305: Epoch time: 44.02 s 
2025-01-11 14:59:43.501523:  
2025-01-11 14:59:43.501578: Epoch 151 
2025-01-11 14:59:43.501618: Current learning rate: 0.00434 
2025-01-11 15:00:27.011393: train_loss -0.5327 
2025-01-11 15:00:27.011472: val_loss -0.5224 
2025-01-11 15:00:27.011504: Pseudo dice [0.8782, 0.8655, 0.8561, 0.8679, 0.8633, 0.8232] 
2025-01-11 15:00:27.011528: Epoch time: 43.51 s 
2025-01-11 15:00:27.509702:  
2025-01-11 15:00:27.509752: Epoch 152 
2025-01-11 15:00:27.509816: Current learning rate: 0.0043 
2025-01-11 15:01:12.140519: train_loss -0.5101 
2025-01-11 15:01:12.140594: val_loss -0.5013 
2025-01-11 15:01:12.140636: Pseudo dice [0.8739, 0.8631, 0.8622, 0.8811, 0.8734, 0.834] 
2025-01-11 15:01:12.140661: Epoch time: 44.63 s 
2025-01-11 15:01:12.140677: Yayy! New best EMA pseudo Dice: 0.8564 
2025-01-11 15:01:12.817523:  
2025-01-11 15:01:12.817575: Epoch 153 
2025-01-11 15:01:12.817613: Current learning rate: 0.00427 
2025-01-11 15:01:56.972570: train_loss -0.5014 
2025-01-11 15:01:56.972651: val_loss -0.5027 
2025-01-11 15:01:56.972693: Pseudo dice [0.8841, 0.8774, 0.8568, 0.8785, 0.8421, 0.8162] 
2025-01-11 15:01:56.972723: Epoch time: 44.16 s 
2025-01-11 15:01:56.972745: Yayy! New best EMA pseudo Dice: 0.8567 
2025-01-11 15:01:57.956370:  
2025-01-11 15:01:57.956445: Epoch 154 
2025-01-11 15:01:57.956497: Current learning rate: 0.00423 
2025-01-11 15:02:41.809758: train_loss -0.5198 
2025-01-11 15:02:41.809839: val_loss -0.5097 
2025-01-11 15:02:41.809886: Pseudo dice [0.885, 0.8634, 0.8532, 0.8649, 0.8507, 0.8163] 
2025-01-11 15:02:41.809910: Epoch time: 43.85 s 
2025-01-11 15:02:42.316912:  
2025-01-11 15:02:42.316985: Epoch 155 
2025-01-11 15:02:42.317025: Current learning rate: 0.00419 
2025-01-11 15:03:26.935159: train_loss -0.4955 
2025-01-11 15:03:26.935233: val_loss -0.4999 
2025-01-11 15:03:26.935273: Pseudo dice [0.8488, 0.8559, 0.8008, 0.8566, 0.7708, 0.7948] 
2025-01-11 15:03:26.935302: Epoch time: 44.62 s 
2025-01-11 15:03:27.442741:  
2025-01-11 15:03:27.442806: Epoch 156 
2025-01-11 15:03:27.442843: Current learning rate: 0.00415 
2025-01-11 15:04:11.636435: train_loss -0.4903 
2025-01-11 15:04:11.636526: val_loss -0.5071 
2025-01-11 15:04:11.636558: Pseudo dice [0.8839, 0.8654, 0.8614, 0.8813, 0.8608, 0.8366] 
2025-01-11 15:04:11.636581: Epoch time: 44.19 s 
2025-01-11 15:04:12.145349:  
2025-01-11 15:04:12.145449: Epoch 157 
2025-01-11 15:04:12.145497: Current learning rate: 0.00411 
2025-01-11 15:04:56.292728: train_loss -0.5038 
2025-01-11 15:04:56.292840: val_loss -0.5326 
2025-01-11 15:04:56.292881: Pseudo dice [0.8776, 0.8728, 0.8494, 0.8825, 0.8383, 0.8483] 
2025-01-11 15:04:56.292911: Epoch time: 44.15 s 
2025-01-11 15:04:56.798461:  
2025-01-11 15:04:56.798526: Epoch 158 
2025-01-11 15:04:56.798565: Current learning rate: 0.00407 
2025-01-11 15:05:41.795089: train_loss -0.5203 
2025-01-11 15:05:41.795166: val_loss -0.5192 
2025-01-11 15:05:41.795198: Pseudo dice [0.8883, 0.8702, 0.8701, 0.8909, 0.8492, 0.8438] 
2025-01-11 15:05:41.795222: Epoch time: 45.0 s 
2025-01-11 15:05:42.304987:  
2025-01-11 15:05:42.305065: Epoch 159 
2025-01-11 15:05:42.305108: Current learning rate: 0.00403 
2025-01-11 15:06:28.044977: train_loss -0.5096 
2025-01-11 15:06:28.045053: val_loss -0.4973 
2025-01-11 15:06:28.045084: Pseudo dice [0.8836, 0.8635, 0.8408, 0.8875, 0.8579, 0.8518] 
2025-01-11 15:06:28.045107: Epoch time: 45.74 s 
2025-01-11 15:06:28.045129: Yayy! New best EMA pseudo Dice: 0.8571 
2025-01-11 15:06:28.743496:  
2025-01-11 15:06:28.743567: Epoch 160 
2025-01-11 15:06:28.743616: Current learning rate: 0.00399 
2025-01-11 15:07:14.403346: train_loss -0.493 
2025-01-11 15:07:14.403435: val_loss -0.496 
2025-01-11 15:07:14.403475: Pseudo dice [0.8516, 0.8634, 0.8495, 0.8743, 0.8443, 0.82] 
2025-01-11 15:07:14.403504: Epoch time: 45.66 s 
2025-01-11 15:07:14.915004:  
2025-01-11 15:07:14.915076: Epoch 161 
2025-01-11 15:07:14.915118: Current learning rate: 0.00395 
2025-01-11 15:08:00.465746: train_loss -0.5077 
2025-01-11 15:08:00.465823: val_loss -0.5099 
2025-01-11 15:08:00.465871: Pseudo dice [0.8728, 0.8686, 0.8414, 0.8847, 0.8325, 0.8412] 
2025-01-11 15:08:00.465901: Epoch time: 45.55 s 
2025-01-11 15:08:00.977716:  
2025-01-11 15:08:00.977791: Epoch 162 
2025-01-11 15:08:00.977847: Current learning rate: 0.00391 
2025-01-11 15:08:45.794127: train_loss -0.5231 
2025-01-11 15:08:45.794198: val_loss -0.5295 
2025-01-11 15:08:45.794231: Pseudo dice [0.9017, 0.8726, 0.8431, 0.8795, 0.8402, 0.7917] 
2025-01-11 15:08:45.794261: Epoch time: 44.82 s 
2025-01-11 15:08:46.303359:  
2025-01-11 15:08:46.303425: Epoch 163 
2025-01-11 15:08:46.303467: Current learning rate: 0.00387 
2025-01-11 15:09:32.005120: train_loss -0.5075 
2025-01-11 15:09:32.005199: val_loss -0.5178 
2025-01-11 15:09:32.005245: Pseudo dice [0.8846, 0.8598, 0.8384, 0.882, 0.8503, 0.8285] 
2025-01-11 15:09:32.005274: Epoch time: 45.7 s 
2025-01-11 15:09:32.516812:  
2025-01-11 15:09:32.516873: Epoch 164 
2025-01-11 15:09:32.516915: Current learning rate: 0.00383 
2025-01-11 15:10:17.752886: train_loss -0.4934 
2025-01-11 15:10:17.752952: val_loss -0.486 
2025-01-11 15:10:17.752983: Pseudo dice [0.8973, 0.8736, 0.8467, 0.8942, 0.8451, 0.8551] 
2025-01-11 15:10:17.753007: Epoch time: 45.24 s 
2025-01-11 15:10:17.753022: Yayy! New best EMA pseudo Dice: 0.8577 
2025-01-11 15:10:18.429958:  
2025-01-11 15:10:18.430022: Epoch 165 
2025-01-11 15:10:18.430061: Current learning rate: 0.00379 
2025-01-11 15:11:03.976689: train_loss -0.5054 
2025-01-11 15:11:03.976771: val_loss -0.4866 
2025-01-11 15:11:03.976813: Pseudo dice [0.8664, 0.8646, 0.8187, 0.8408, 0.7823, 0.7822] 
2025-01-11 15:11:03.976840: Epoch time: 45.55 s 
2025-01-11 15:11:04.471696:  
2025-01-11 15:11:04.471772: Epoch 166 
2025-01-11 15:11:04.471820: Current learning rate: 0.00375 
2025-01-11 15:11:50.159533: train_loss -0.512 
2025-01-11 15:11:50.159633: val_loss -0.4889 
2025-01-11 15:11:50.159682: Pseudo dice [0.8823, 0.8697, 0.8537, 0.8425, 0.8252, 0.8117] 
2025-01-11 15:11:50.159711: Epoch time: 45.69 s 
2025-01-11 15:11:50.655037:  
2025-01-11 15:11:50.655091: Epoch 167 
2025-01-11 15:11:50.655134: Current learning rate: 0.00371 
2025-01-11 15:12:36.434319: train_loss -0.5235 
2025-01-11 15:12:36.434400: val_loss -0.527 
2025-01-11 15:12:36.434440: Pseudo dice [0.8884, 0.8692, 0.8534, 0.8688, 0.8444, 0.8193] 
2025-01-11 15:12:36.434469: Epoch time: 45.78 s 
2025-01-11 15:12:36.935494:  
2025-01-11 15:12:36.935547: Epoch 168 
2025-01-11 15:12:36.935595: Current learning rate: 0.00367 
2025-01-11 15:13:22.765945: train_loss -0.512 
2025-01-11 15:13:22.766032: val_loss -0.5111 
2025-01-11 15:13:22.766065: Pseudo dice [0.8761, 0.863, 0.8354, 0.88, 0.8487, 0.8254] 
2025-01-11 15:13:22.766089: Epoch time: 45.83 s 
2025-01-11 15:13:23.267567:  
2025-01-11 15:13:23.267668: Epoch 169 
2025-01-11 15:13:23.267719: Current learning rate: 0.00363 
2025-01-11 15:14:08.843946: train_loss -0.5331 
2025-01-11 15:14:08.844045: val_loss -0.5426 
2025-01-11 15:14:08.844079: Pseudo dice [0.8952, 0.8732, 0.8519, 0.8775, 0.8416, 0.8377] 
2025-01-11 15:14:08.844103: Epoch time: 45.58 s 
2025-01-11 15:14:09.345606:  
2025-01-11 15:14:09.345661: Epoch 170 
2025-01-11 15:14:09.345704: Current learning rate: 0.00359 
2025-01-11 15:14:54.895003: train_loss -0.5209 
2025-01-11 15:14:54.895082: val_loss -0.5249 
2025-01-11 15:14:54.895123: Pseudo dice [0.8384, 0.8691, 0.8399, 0.8787, 0.8543, 0.83] 
2025-01-11 15:14:54.895152: Epoch time: 45.55 s 
2025-01-11 15:14:55.395624:  
2025-01-11 15:14:55.395730: Epoch 171 
2025-01-11 15:14:55.395773: Current learning rate: 0.00355 
2025-01-11 15:15:39.765951: train_loss -0.5185 
2025-01-11 15:15:39.766030: val_loss -0.5006 
2025-01-11 15:15:39.766062: Pseudo dice [0.8653, 0.8718, 0.8518, 0.8755, 0.8346, 0.8088] 
2025-01-11 15:15:39.766086: Epoch time: 44.37 s 
2025-01-11 15:15:40.554010:  
2025-01-11 15:15:40.554070: Epoch 172 
2025-01-11 15:15:40.554109: Current learning rate: 0.00351 
2025-01-11 15:16:24.069641: train_loss -0.5375 
2025-01-11 15:16:24.069737: val_loss -0.4865 
2025-01-11 15:16:24.069784: Pseudo dice [0.8814, 0.8677, 0.8469, 0.8738, 0.8355, 0.8341] 
2025-01-11 15:16:24.069823: Epoch time: 43.52 s 
2025-01-11 15:16:24.570114:  
2025-01-11 15:16:24.570185: Epoch 173 
2025-01-11 15:16:24.570236: Current learning rate: 0.00346 
2025-01-11 15:17:08.941284: train_loss -0.4977 
2025-01-11 15:17:08.941363: val_loss -0.4728 
2025-01-11 15:17:08.941404: Pseudo dice [0.8916, 0.8711, 0.8451, 0.8794, 0.8445, 0.8272] 
2025-01-11 15:17:08.941435: Epoch time: 44.37 s 
2025-01-11 15:17:09.455226:  
2025-01-11 15:17:09.455294: Epoch 174 
2025-01-11 15:17:09.455337: Current learning rate: 0.00342 
2025-01-11 15:17:55.168772: train_loss -0.505 
2025-01-11 15:17:55.168856: val_loss -0.4748 
2025-01-11 15:17:55.168893: Pseudo dice [0.8797, 0.8655, 0.8211, 0.8705, 0.8062, 0.8122] 
2025-01-11 15:17:55.168933: Epoch time: 45.71 s 
2025-01-11 15:17:55.670691:  
2025-01-11 15:17:55.670769: Epoch 175 
2025-01-11 15:17:55.670809: Current learning rate: 0.00338 
2025-01-11 15:18:41.405671: train_loss -0.5018 
2025-01-11 15:18:41.405749: val_loss -0.5331 
2025-01-11 15:18:41.405792: Pseudo dice [0.8711, 0.8619, 0.8594, 0.8683, 0.862, 0.8366] 
2025-01-11 15:18:41.405823: Epoch time: 45.74 s 
2025-01-11 15:18:41.913881:  
2025-01-11 15:18:41.913949: Epoch 176 
2025-01-11 15:18:41.913992: Current learning rate: 0.00334 
2025-01-11 15:19:28.118669: train_loss -0.5094 
2025-01-11 15:19:28.118744: val_loss -0.5092 
2025-01-11 15:19:28.118776: Pseudo dice [0.8887, 0.874, 0.8513, 0.8677, 0.85, 0.8248] 
2025-01-11 15:19:28.118801: Epoch time: 46.21 s 
2025-01-11 15:19:28.624071:  
2025-01-11 15:19:28.624146: Epoch 177 
2025-01-11 15:19:28.624187: Current learning rate: 0.0033 
2025-01-11 15:20:12.795900: train_loss -0.5254 
2025-01-11 15:20:12.796085: val_loss -0.5126 
2025-01-11 15:20:12.796119: Pseudo dice [0.8842, 0.8622, 0.8276, 0.8847, 0.8306, 0.8429] 
2025-01-11 15:20:12.796144: Epoch time: 44.17 s 
2025-01-11 15:20:13.307362:  
2025-01-11 15:20:13.307486: Epoch 178 
2025-01-11 15:20:13.307529: Current learning rate: 0.00326 
2025-01-11 15:20:57.897057: train_loss -0.514 
2025-01-11 15:20:57.897135: val_loss -0.548 
2025-01-11 15:20:57.897176: Pseudo dice [0.8586, 0.8705, 0.8531, 0.8893, 0.8523, 0.8467] 
2025-01-11 15:20:57.897204: Epoch time: 44.59 s 
2025-01-11 15:20:58.396256:  
2025-01-11 15:20:58.396317: Epoch 179 
2025-01-11 15:20:58.396354: Current learning rate: 0.00322 
2025-01-11 15:21:42.106074: train_loss -0.5238 
2025-01-11 15:21:42.106157: val_loss -0.4818 
2025-01-11 15:21:42.106197: Pseudo dice [0.8711, 0.8581, 0.8245, 0.873, 0.8372, 0.8185] 
2025-01-11 15:21:42.106235: Epoch time: 43.71 s 
2025-01-11 15:21:42.608579:  
2025-01-11 15:21:42.608683: Epoch 180 
2025-01-11 15:21:42.608722: Current learning rate: 0.00318 
2025-01-11 15:22:27.226152: train_loss -0.5008 
2025-01-11 15:22:27.226239: val_loss -0.5309 
2025-01-11 15:22:27.226278: Pseudo dice [0.8689, 0.8747, 0.8123, 0.8401, 0.8122, 0.7999] 
2025-01-11 15:22:27.226307: Epoch time: 44.62 s 
2025-01-11 15:22:27.730987:  
2025-01-11 15:22:27.731067: Epoch 181 
2025-01-11 15:22:27.731129: Current learning rate: 0.00314 
2025-01-11 15:23:11.903137: train_loss -0.5229 
2025-01-11 15:23:11.903211: val_loss -0.4984 
2025-01-11 15:23:11.903250: Pseudo dice [0.8921, 0.8825, 0.8456, 0.8674, 0.8426, 0.8339] 
2025-01-11 15:23:11.903276: Epoch time: 44.17 s 
2025-01-11 15:23:12.406368:  
2025-01-11 15:23:12.406421: Epoch 182 
2025-01-11 15:23:12.406459: Current learning rate: 0.0031 
2025-01-11 15:23:55.909886: train_loss -0.5279 
2025-01-11 15:23:55.909969: val_loss -0.5413 
2025-01-11 15:23:55.910007: Pseudo dice [0.8799, 0.8727, 0.8533, 0.8724, 0.8484, 0.818] 
2025-01-11 15:23:55.910035: Epoch time: 43.5 s 
2025-01-11 15:23:56.412185:  
2025-01-11 15:23:56.412237: Epoch 183 
2025-01-11 15:23:56.412283: Current learning rate: 0.00306 
2025-01-11 15:24:39.933181: train_loss -0.5372 
2025-01-11 15:24:39.933254: val_loss -0.5037 
2025-01-11 15:24:39.933286: Pseudo dice [0.8804, 0.8619, 0.8266, 0.8841, 0.8414, 0.8494] 
2025-01-11 15:24:39.933311: Epoch time: 43.52 s 
2025-01-11 15:24:40.435352:  
2025-01-11 15:24:40.435410: Epoch 184 
2025-01-11 15:24:40.435456: Current learning rate: 0.00302 
2025-01-11 15:25:23.989985: train_loss -0.5387 
2025-01-11 15:25:23.990061: val_loss -0.5504 
2025-01-11 15:25:23.990102: Pseudo dice [0.8926, 0.8723, 0.8698, 0.8794, 0.8639, 0.8354] 
2025-01-11 15:25:23.990130: Epoch time: 43.56 s 
2025-01-11 15:25:24.489250:  
2025-01-11 15:25:24.489313: Epoch 185 
2025-01-11 15:25:24.489358: Current learning rate: 0.00297 
2025-01-11 15:26:07.986739: train_loss -0.5285 
2025-01-11 15:26:07.986818: val_loss -0.5332 
2025-01-11 15:26:07.986858: Pseudo dice [0.8837, 0.8715, 0.8501, 0.875, 0.8692, 0.8431] 
2025-01-11 15:26:07.986889: Epoch time: 43.5 s 
2025-01-11 15:26:08.491490:  
2025-01-11 15:26:08.491540: Epoch 186 
2025-01-11 15:26:08.491577: Current learning rate: 0.00293 
2025-01-11 15:26:52.004966: train_loss -0.5337 
2025-01-11 15:26:52.005040: val_loss -0.5165 
2025-01-11 15:26:52.005080: Pseudo dice [0.8878, 0.8707, 0.848, 0.8688, 0.8442, 0.8229] 
2025-01-11 15:26:52.005110: Epoch time: 43.51 s 
2025-01-11 15:26:52.505727:  
2025-01-11 15:26:52.505812: Epoch 187 
2025-01-11 15:26:52.505851: Current learning rate: 0.00289 
2025-01-11 15:27:36.002072: train_loss -0.5252 
2025-01-11 15:27:36.002149: val_loss -0.5112 
2025-01-11 15:27:36.002193: Pseudo dice [0.8917, 0.8668, 0.8654, 0.8836, 0.8695, 0.8558] 
2025-01-11 15:27:36.002222: Epoch time: 43.5 s 
2025-01-11 15:27:36.002242: Yayy! New best EMA pseudo Dice: 0.8583 
2025-01-11 15:27:36.690185:  
2025-01-11 15:27:36.690235: Epoch 188 
2025-01-11 15:27:36.690272: Current learning rate: 0.00285 
2025-01-11 15:28:20.179458: train_loss -0.5309 
2025-01-11 15:28:20.179538: val_loss -0.5482 
2025-01-11 15:28:20.179571: Pseudo dice [0.9038, 0.8641, 0.8452, 0.8541, 0.8377, 0.7991] 
2025-01-11 15:28:20.179600: Epoch time: 43.49 s 
2025-01-11 15:28:20.678533:  
2025-01-11 15:28:20.678584: Epoch 189 
2025-01-11 15:28:20.678619: Current learning rate: 0.00281 
2025-01-11 15:29:04.189023: train_loss -0.5131 
2025-01-11 15:29:04.189092: val_loss -0.5178 
2025-01-11 15:29:04.189124: Pseudo dice [0.874, 0.8722, 0.8675, 0.8835, 0.8566, 0.8228] 
2025-01-11 15:29:04.189148: Epoch time: 43.51 s 
2025-01-11 15:29:04.976551:  
2025-01-11 15:29:04.976626: Epoch 190 
2025-01-11 15:29:04.976668: Current learning rate: 0.00277 
2025-01-11 15:29:48.498463: train_loss -0.5245 
2025-01-11 15:29:48.498539: val_loss -0.5377 
2025-01-11 15:29:48.498572: Pseudo dice [0.8968, 0.8659, 0.8513, 0.887, 0.8644, 0.8178] 
2025-01-11 15:29:48.498597: Epoch time: 43.52 s 
2025-01-11 15:29:48.498614: Yayy! New best EMA pseudo Dice: 0.8586 
2025-01-11 15:29:49.191129:  
2025-01-11 15:29:49.191191: Epoch 191 
2025-01-11 15:29:49.191232: Current learning rate: 0.00273 
2025-01-11 15:30:32.710396: train_loss -0.5217 
2025-01-11 15:30:32.710463: val_loss -0.4854 
2025-01-11 15:30:32.710494: Pseudo dice [0.8865, 0.8752, 0.8409, 0.8885, 0.8407, 0.8504] 
2025-01-11 15:30:32.710516: Epoch time: 43.52 s 
2025-01-11 15:30:32.710532: Yayy! New best EMA pseudo Dice: 0.8591 
2025-01-11 15:30:33.405905:  
2025-01-11 15:30:33.406013: Epoch 192 
2025-01-11 15:30:33.406051: Current learning rate: 0.00268 
2025-01-11 15:31:16.924143: train_loss -0.5193 
2025-01-11 15:31:16.924220: val_loss -0.4689 
2025-01-11 15:31:16.924261: Pseudo dice [0.9006, 0.8712, 0.8645, 0.8828, 0.8543, 0.837] 
2025-01-11 15:31:16.924290: Epoch time: 43.52 s 
2025-01-11 15:31:16.924310: Yayy! New best EMA pseudo Dice: 0.8601 
2025-01-11 15:31:17.616548:  
2025-01-11 15:31:17.616628: Epoch 193 
2025-01-11 15:31:17.616665: Current learning rate: 0.00264 
2025-01-11 15:32:01.120289: train_loss -0.5475 
2025-01-11 15:32:01.120364: val_loss -0.4998 
2025-01-11 15:32:01.120406: Pseudo dice [0.8936, 0.8626, 0.8476, 0.8696, 0.8674, 0.8295] 
2025-01-11 15:32:01.120436: Epoch time: 43.5 s 
2025-01-11 15:32:01.120456: Yayy! New best EMA pseudo Dice: 0.8602 
2025-01-11 15:32:01.823366:  
2025-01-11 15:32:01.823429: Epoch 194 
2025-01-11 15:32:01.823465: Current learning rate: 0.0026 
2025-01-11 15:32:45.333346: train_loss -0.5262 
2025-01-11 15:32:45.333420: val_loss -0.517 
2025-01-11 15:32:45.333459: Pseudo dice [0.8854, 0.862, 0.8401, 0.884, 0.8494, 0.8336] 
2025-01-11 15:32:45.333490: Epoch time: 43.51 s 
2025-01-11 15:32:45.842794:  
2025-01-11 15:32:45.842855: Epoch 195 
2025-01-11 15:32:45.842891: Current learning rate: 0.00256 
2025-01-11 15:33:29.346938: train_loss -0.5212 
2025-01-11 15:33:29.347022: val_loss -0.5157 
2025-01-11 15:33:29.347057: Pseudo dice [0.9039, 0.8814, 0.8637, 0.8976, 0.8693, 0.8421] 
2025-01-11 15:33:29.347082: Epoch time: 43.5 s 
2025-01-11 15:33:29.347098: Yayy! New best EMA pseudo Dice: 0.8617 
2025-01-11 15:33:30.045700:  
2025-01-11 15:33:30.045762: Epoch 196 
2025-01-11 15:33:30.045801: Current learning rate: 0.00252 
2025-01-11 15:34:13.554965: train_loss -0.5338 
2025-01-11 15:34:13.555041: val_loss -0.5565 
2025-01-11 15:34:13.555080: Pseudo dice [0.9035, 0.8714, 0.8419, 0.881, 0.8491, 0.8371] 
2025-01-11 15:34:13.555109: Epoch time: 43.51 s 
2025-01-11 15:34:13.555128: Yayy! New best EMA pseudo Dice: 0.862 
2025-01-11 15:34:14.254206:  
2025-01-11 15:34:14.254287: Epoch 197 
2025-01-11 15:34:14.254326: Current learning rate: 0.00248 
2025-01-11 15:34:57.756211: train_loss -0.5416 
2025-01-11 15:34:57.756284: val_loss -0.5061 
2025-01-11 15:34:57.756315: Pseudo dice [0.9017, 0.8712, 0.8549, 0.882, 0.867, 0.839] 
2025-01-11 15:34:57.756340: Epoch time: 43.5 s 
2025-01-11 15:34:57.756356: Yayy! New best EMA pseudo Dice: 0.8627 
2025-01-11 15:34:58.450812:  
2025-01-11 15:34:58.450874: Epoch 198 
2025-01-11 15:34:58.450913: Current learning rate: 0.00243 
2025-01-11 15:35:41.941575: train_loss -0.537 
2025-01-11 15:35:41.941650: val_loss -0.5407 
2025-01-11 15:35:41.941688: Pseudo dice [0.8948, 0.8688, 0.8582, 0.8916, 0.8532, 0.8519] 
2025-01-11 15:35:41.941723: Epoch time: 43.49 s 
2025-01-11 15:35:41.941743: Yayy! New best EMA pseudo Dice: 0.8634 
2025-01-11 15:35:42.634493:  
2025-01-11 15:35:42.634551: Epoch 199 
2025-01-11 15:35:42.634586: Current learning rate: 0.00239 
2025-01-11 15:36:26.145449: train_loss -0.5433 
2025-01-11 15:36:26.145531: val_loss -0.5126 
2025-01-11 15:36:26.145570: Pseudo dice [0.9014, 0.8878, 0.8587, 0.8536, 0.862, 0.8116] 
2025-01-11 15:36:26.145599: Epoch time: 43.51 s 
2025-01-11 15:36:26.839645:  
2025-01-11 15:36:26.839696: Epoch 200 
2025-01-11 15:36:26.839736: Current learning rate: 0.00235 
2025-01-11 15:37:10.335844: train_loss -0.5289 
2025-01-11 15:37:10.335919: val_loss -0.4976 
2025-01-11 15:37:10.335959: Pseudo dice [0.8782, 0.8706, 0.8555, 0.8652, 0.846, 0.8331] 
2025-01-11 15:37:10.335984: Epoch time: 43.5 s 
2025-01-11 15:37:10.846325:  
2025-01-11 15:37:10.846415: Epoch 201 
2025-01-11 15:37:10.846460: Current learning rate: 0.00231 
2025-01-11 15:37:54.363039: train_loss -0.5233 
2025-01-11 15:37:54.363110: val_loss -0.5275 
2025-01-11 15:37:54.363141: Pseudo dice [0.8907, 0.8716, 0.8639, 0.8815, 0.846, 0.8339] 
2025-01-11 15:37:54.363164: Epoch time: 43.52 s 
2025-01-11 15:37:54.874893:  
2025-01-11 15:37:54.874958: Epoch 202 
2025-01-11 15:37:54.874993: Current learning rate: 0.00226 
2025-01-11 15:38:38.374887: train_loss -0.5043 
2025-01-11 15:38:38.374989: val_loss -0.5297 
2025-01-11 15:38:38.375029: Pseudo dice [0.8901, 0.8704, 0.8526, 0.902, 0.8604, 0.8638] 
2025-01-11 15:38:38.375056: Epoch time: 43.5 s 
2025-01-11 15:38:38.375072: Yayy! New best EMA pseudo Dice: 0.864 
2025-01-11 15:38:39.071557:  
2025-01-11 15:38:39.071618: Epoch 203 
2025-01-11 15:38:39.071654: Current learning rate: 0.00222 
2025-01-11 15:39:22.556569: train_loss -0.5517 
2025-01-11 15:39:22.556656: val_loss -0.5001 
2025-01-11 15:39:22.556697: Pseudo dice [0.8872, 0.8736, 0.8499, 0.8908, 0.8457, 0.8425] 
2025-01-11 15:39:22.556728: Epoch time: 43.49 s 
2025-01-11 15:39:22.556749: Yayy! New best EMA pseudo Dice: 0.8641 
2025-01-11 15:39:23.252385:  
2025-01-11 15:39:23.252460: Epoch 204 
2025-01-11 15:39:23.252509: Current learning rate: 0.00218 
2025-01-11 15:40:07.028915: train_loss -0.5393 
2025-01-11 15:40:07.028990: val_loss -0.5241 
2025-01-11 15:40:07.029025: Pseudo dice [0.8827, 0.8792, 0.8787, 0.8863, 0.8689, 0.8418] 
2025-01-11 15:40:07.029049: Epoch time: 43.78 s 
2025-01-11 15:40:07.029065: Yayy! New best EMA pseudo Dice: 0.865 
2025-01-11 15:40:07.730282:  
2025-01-11 15:40:07.730344: Epoch 205 
2025-01-11 15:40:07.730381: Current learning rate: 0.00214 
2025-01-11 15:40:51.726874: train_loss -0.5408 
2025-01-11 15:40:51.726964: val_loss -0.5215 
2025-01-11 15:40:51.727007: Pseudo dice [0.8922, 0.8702, 0.8598, 0.8992, 0.8515, 0.8719] 
2025-01-11 15:40:51.727037: Epoch time: 44.0 s 
2025-01-11 15:40:51.727057: Yayy! New best EMA pseudo Dice: 0.8659 
2025-01-11 15:40:52.392360:  
2025-01-11 15:40:52.392423: Epoch 206 
2025-01-11 15:40:52.392468: Current learning rate: 0.00209 
2025-01-11 15:41:35.883200: train_loss -0.5358 
2025-01-11 15:41:35.883279: val_loss -0.5376 
2025-01-11 15:41:35.883318: Pseudo dice [0.8861, 0.8621, 0.8587, 0.8785, 0.8445, 0.834] 
2025-01-11 15:41:35.883348: Epoch time: 43.49 s 
2025-01-11 15:41:36.642820:  
2025-01-11 15:41:36.642882: Epoch 207 
2025-01-11 15:41:36.642918: Current learning rate: 0.00205 
2025-01-11 15:42:20.165508: train_loss -0.5341 
2025-01-11 15:42:20.165574: val_loss -0.543 
2025-01-11 15:42:20.165606: Pseudo dice [0.885, 0.8741, 0.8708, 0.887, 0.8747, 0.8525] 
2025-01-11 15:42:20.165630: Epoch time: 43.52 s 
2025-01-11 15:42:20.165646: Yayy! New best EMA pseudo Dice: 0.8662 
2025-01-11 15:42:20.829519:  
2025-01-11 15:42:20.829584: Epoch 208 
2025-01-11 15:42:20.829623: Current learning rate: 0.00201 
2025-01-11 15:43:04.333506: train_loss -0.5226 
2025-01-11 15:43:04.333588: val_loss -0.5484 
2025-01-11 15:43:04.333783: Pseudo dice [0.9002, 0.8737, 0.8263, 0.8517, 0.8419, 0.789] 
2025-01-11 15:43:04.333807: Epoch time: 43.5 s 
2025-01-11 15:43:04.812670:  
2025-01-11 15:43:04.812752: Epoch 209 
2025-01-11 15:43:04.812789: Current learning rate: 0.00196 
2025-01-11 15:43:48.319664: train_loss -0.5248 
2025-01-11 15:43:48.319747: val_loss -0.5372 
2025-01-11 15:43:48.319789: Pseudo dice [0.9052, 0.8868, 0.8722, 0.8985, 0.8748, 0.8411] 
2025-01-11 15:43:48.319818: Epoch time: 43.51 s 
2025-01-11 15:43:48.799115:  
2025-01-11 15:43:48.799175: Epoch 210 
2025-01-11 15:43:48.799212: Current learning rate: 0.00192 
2025-01-11 15:44:32.317368: train_loss -0.534 
2025-01-11 15:44:32.317458: val_loss -0.5173 
2025-01-11 15:44:32.317499: Pseudo dice [0.8955, 0.8692, 0.8645, 0.8837, 0.8713, 0.8297] 
2025-01-11 15:44:32.317528: Epoch time: 43.52 s 
2025-01-11 15:44:32.798714:  
2025-01-11 15:44:32.798780: Epoch 211 
2025-01-11 15:44:32.798823: Current learning rate: 0.00188 
2025-01-11 15:45:16.312203: train_loss -0.5462 
2025-01-11 15:45:16.312281: val_loss -0.5061 
2025-01-11 15:45:16.312320: Pseudo dice [0.8827, 0.8791, 0.837, 0.8901, 0.8158, 0.8477] 
2025-01-11 15:45:16.312349: Epoch time: 43.51 s 
2025-01-11 15:45:16.795338:  
2025-01-11 15:45:16.795440: Epoch 212 
2025-01-11 15:45:16.795485: Current learning rate: 0.00184 
2025-01-11 15:46:00.293908: train_loss -0.5344 
2025-01-11 15:46:00.293993: val_loss -0.5397 
2025-01-11 15:46:00.294033: Pseudo dice [0.8925, 0.8795, 0.8683, 0.8784, 0.8613, 0.8329] 
2025-01-11 15:46:00.294062: Epoch time: 43.5 s 
2025-01-11 15:46:00.772087:  
2025-01-11 15:46:00.772148: Epoch 213 
2025-01-11 15:46:00.772185: Current learning rate: 0.00179 
2025-01-11 15:46:44.282516: train_loss -0.5205 
2025-01-11 15:46:44.282591: val_loss -0.515 
2025-01-11 15:46:44.282634: Pseudo dice [0.8836, 0.8679, 0.8587, 0.8848, 0.8651, 0.8464] 
2025-01-11 15:46:44.282663: Epoch time: 43.51 s 
2025-01-11 15:46:44.756930:  
2025-01-11 15:46:44.756989: Epoch 214 
2025-01-11 15:46:44.757028: Current learning rate: 0.00175 
2025-01-11 15:47:28.244308: train_loss -0.5292 
2025-01-11 15:47:28.244387: val_loss -0.5429 
2025-01-11 15:47:28.244426: Pseudo dice [0.8963, 0.8707, 0.8672, 0.889, 0.8677, 0.8402] 
2025-01-11 15:47:28.244456: Epoch time: 43.49 s 
2025-01-11 15:47:28.244476: Yayy! New best EMA pseudo Dice: 0.8666 
2025-01-11 15:47:28.902701:  
2025-01-11 15:47:28.902763: Epoch 215 
2025-01-11 15:47:28.902805: Current learning rate: 0.0017 
2025-01-11 15:48:12.384801: train_loss -0.5276 
2025-01-11 15:48:12.384882: val_loss -0.5448 
2025-01-11 15:48:12.384927: Pseudo dice [0.87, 0.8821, 0.8664, 0.8842, 0.8775, 0.8457] 
2025-01-11 15:48:12.384958: Epoch time: 43.48 s 
2025-01-11 15:48:12.384979: Yayy! New best EMA pseudo Dice: 0.867 
2025-01-11 15:48:13.051389:  
2025-01-11 15:48:13.051449: Epoch 216 
2025-01-11 15:48:13.051495: Current learning rate: 0.00166 
2025-01-11 15:48:56.544888: train_loss -0.5354 
2025-01-11 15:48:56.544958: val_loss -0.5382 
2025-01-11 15:48:56.544991: Pseudo dice [0.8849, 0.8746, 0.8558, 0.8846, 0.8532, 0.8523] 
2025-01-11 15:48:56.545016: Epoch time: 43.49 s 
2025-01-11 15:48:56.545037: Yayy! New best EMA pseudo Dice: 0.8671 
2025-01-11 15:48:57.201102:  
2025-01-11 15:48:57.201161: Epoch 217 
2025-01-11 15:48:57.201197: Current learning rate: 0.00162 
2025-01-11 15:49:40.682508: train_loss -0.5371 
2025-01-11 15:49:40.682582: val_loss -0.5044 
2025-01-11 15:49:40.682622: Pseudo dice [0.8981, 0.8792, 0.8616, 0.8894, 0.8282, 0.8551] 
2025-01-11 15:49:40.682652: Epoch time: 43.48 s 
2025-01-11 15:49:40.682671: Yayy! New best EMA pseudo Dice: 0.8672 
2025-01-11 15:49:41.345780:  
2025-01-11 15:49:41.345851: Epoch 218 
2025-01-11 15:49:41.345888: Current learning rate: 0.00157 
2025-01-11 15:50:24.852783: train_loss -0.5277 
2025-01-11 15:50:24.852864: val_loss -0.5158 
2025-01-11 15:50:24.852902: Pseudo dice [0.8853, 0.8723, 0.8552, 0.8773, 0.8613, 0.8553] 
2025-01-11 15:50:24.852931: Epoch time: 43.51 s 
2025-01-11 15:50:24.852950: Yayy! New best EMA pseudo Dice: 0.8673 
2025-01-11 15:50:25.514599:  
2025-01-11 15:50:25.514656: Epoch 219 
2025-01-11 15:50:25.514693: Current learning rate: 0.00153 
2025-01-11 15:51:09.001853: train_loss -0.5344 
2025-01-11 15:51:09.001952: val_loss -0.4963 
2025-01-11 15:51:09.001997: Pseudo dice [0.8909, 0.8779, 0.8728, 0.8855, 0.8767, 0.8195] 
2025-01-11 15:51:09.002028: Epoch time: 43.49 s 
2025-01-11 15:51:09.002050: Yayy! New best EMA pseudo Dice: 0.8676 
2025-01-11 15:51:09.663962:  
2025-01-11 15:51:09.664026: Epoch 220 
2025-01-11 15:51:09.664065: Current learning rate: 0.00148 
2025-01-11 15:51:53.150771: train_loss -0.525 
2025-01-11 15:51:53.150846: val_loss -0.5577 
2025-01-11 15:51:53.150886: Pseudo dice [0.8847, 0.8796, 0.8532, 0.8827, 0.8418, 0.8502] 
2025-01-11 15:51:53.150915: Epoch time: 43.49 s 
2025-01-11 15:51:53.625293:  
2025-01-11 15:51:53.625353: Epoch 221 
2025-01-11 15:51:53.625391: Current learning rate: 0.00144 
2025-01-11 15:52:37.114316: train_loss -0.5349 
2025-01-11 15:52:37.114387: val_loss -0.5662 
2025-01-11 15:52:37.114419: Pseudo dice [0.9058, 0.8778, 0.8572, 0.8782, 0.8581, 0.8504] 
2025-01-11 15:52:37.114443: Epoch time: 43.49 s 
2025-01-11 15:52:37.114459: Yayy! New best EMA pseudo Dice: 0.8678 
2025-01-11 15:52:37.775492:  
2025-01-11 15:52:37.775539: Epoch 222 
2025-01-11 15:52:37.775575: Current learning rate: 0.00139 
2025-01-11 15:53:21.252987: train_loss -0.5468 
2025-01-11 15:53:21.253060: val_loss -0.5432 
2025-01-11 15:53:21.253101: Pseudo dice [0.9098, 0.8815, 0.8411, 0.868, 0.8491, 0.8187] 
2025-01-11 15:53:21.253129: Epoch time: 43.48 s 
2025-01-11 15:53:21.727714:  
2025-01-11 15:53:21.727772: Epoch 223 
2025-01-11 15:53:21.727808: Current learning rate: 0.00135 
2025-01-11 15:54:05.215160: train_loss -0.533 
2025-01-11 15:54:05.215235: val_loss -0.5206 
2025-01-11 15:54:05.215275: Pseudo dice [0.8876, 0.8797, 0.8593, 0.8678, 0.8629, 0.846] 
2025-01-11 15:54:05.215310: Epoch time: 43.49 s 
2025-01-11 15:54:05.685719:  
2025-01-11 15:54:05.685782: Epoch 224 
2025-01-11 15:54:05.685822: Current learning rate: 0.0013 
2025-01-11 15:54:49.174003: train_loss -0.548 
2025-01-11 15:54:49.174084: val_loss -0.532 
2025-01-11 15:54:49.174115: Pseudo dice [0.8932, 0.874, 0.8632, 0.8665, 0.8621, 0.8215] 
2025-01-11 15:54:49.174139: Epoch time: 43.49 s 
2025-01-11 15:54:49.931049:  
2025-01-11 15:54:49.931109: Epoch 225 
2025-01-11 15:54:49.931151: Current learning rate: 0.00126 
2025-01-11 15:55:33.467541: train_loss -0.5448 
2025-01-11 15:55:33.467629: val_loss -0.5079 
2025-01-11 15:55:33.467673: Pseudo dice [0.8902, 0.8573, 0.8567, 0.8877, 0.8505, 0.8465] 
2025-01-11 15:55:33.467702: Epoch time: 43.54 s 
2025-01-11 15:55:33.943135:  
2025-01-11 15:55:33.943197: Epoch 226 
2025-01-11 15:55:33.943235: Current learning rate: 0.00121 
2025-01-11 15:56:18.302561: train_loss -0.54 
2025-01-11 15:56:18.302639: val_loss -0.5272 
2025-01-11 15:56:18.302679: Pseudo dice [0.8817, 0.8688, 0.8388, 0.8706, 0.8508, 0.8434] 
2025-01-11 15:56:18.302707: Epoch time: 44.36 s 
2025-01-11 15:56:18.774858:  
2025-01-11 15:56:18.774919: Epoch 227 
2025-01-11 15:56:18.774955: Current learning rate: 0.00117 
2025-01-11 15:57:02.527655: train_loss -0.5246 
2025-01-11 15:57:02.527731: val_loss -0.5351 
2025-01-11 15:57:02.527775: Pseudo dice [0.8764, 0.8774, 0.8615, 0.8865, 0.8469, 0.8324] 
2025-01-11 15:57:02.527803: Epoch time: 43.75 s 
2025-01-11 15:57:03.003887:  
2025-01-11 15:57:03.003956: Epoch 228 
2025-01-11 15:57:03.003997: Current learning rate: 0.00112 
2025-01-11 15:57:48.824526: train_loss -0.5398 
2025-01-11 15:57:48.824606: val_loss -0.5444 
2025-01-11 15:57:48.824637: Pseudo dice [0.8925, 0.8744, 0.8461, 0.8947, 0.8376, 0.8594] 
2025-01-11 15:57:48.824662: Epoch time: 45.82 s 
2025-01-11 15:57:49.300343:  
2025-01-11 15:57:49.300418: Epoch 229 
2025-01-11 15:57:49.300461: Current learning rate: 0.00108 
2025-01-11 15:58:35.120175: train_loss -0.5263 
2025-01-11 15:58:35.120253: val_loss -0.5297 
2025-01-11 15:58:35.120285: Pseudo dice [0.8951, 0.8727, 0.8723, 0.8725, 0.8812, 0.8339] 
2025-01-11 15:58:35.120309: Epoch time: 45.82 s 
2025-01-11 15:58:35.596906:  
2025-01-11 15:58:35.596977: Epoch 230 
2025-01-11 15:58:35.597020: Current learning rate: 0.00103 
2025-01-11 15:59:21.035029: train_loss -0.541 
2025-01-11 15:59:21.035110: val_loss -0.5123 
2025-01-11 15:59:21.035161: Pseudo dice [0.8999, 0.8644, 0.8607, 0.8845, 0.8589, 0.8427] 
2025-01-11 15:59:21.035186: Epoch time: 45.44 s 
2025-01-11 15:59:21.514227:  
2025-01-11 15:59:21.514305: Epoch 231 
2025-01-11 15:59:21.514348: Current learning rate: 0.00098 
2025-01-11 16:00:06.968538: train_loss -0.5205 
2025-01-11 16:00:06.968614: val_loss -0.5009 
2025-01-11 16:00:06.968645: Pseudo dice [0.8658, 0.872, 0.8637, 0.8694, 0.8686, 0.8019] 
2025-01-11 16:00:06.968668: Epoch time: 45.45 s 
2025-01-11 16:00:07.446974:  
2025-01-11 16:00:07.447031: Epoch 232 
2025-01-11 16:00:07.447072: Current learning rate: 0.00094 
2025-01-11 16:00:52.374608: train_loss -0.5255 
2025-01-11 16:00:52.374681: val_loss -0.5374 
2025-01-11 16:00:52.374714: Pseudo dice [0.887, 0.8857, 0.8468, 0.8859, 0.8532, 0.8362] 
2025-01-11 16:00:52.374738: Epoch time: 44.93 s 
2025-01-11 16:00:52.853979:  
2025-01-11 16:00:52.854041: Epoch 233 
2025-01-11 16:00:52.854082: Current learning rate: 0.00089 
2025-01-11 16:01:37.982971: train_loss -0.5535 
2025-01-11 16:01:37.983059: val_loss -0.5523 
2025-01-11 16:01:37.983097: Pseudo dice [0.8901, 0.8772, 0.8603, 0.8734, 0.8547, 0.8409] 
2025-01-11 16:01:37.983121: Epoch time: 45.13 s 
2025-01-11 16:01:38.461135:  
2025-01-11 16:01:38.461199: Epoch 234 
2025-01-11 16:01:38.461265: Current learning rate: 0.00084 
2025-01-11 16:02:23.585143: train_loss -0.5523 
2025-01-11 16:02:23.585217: val_loss -0.5571 
2025-01-11 16:02:23.585249: Pseudo dice [0.8971, 0.8829, 0.8593, 0.888, 0.8612, 0.8538] 
2025-01-11 16:02:23.585272: Epoch time: 45.12 s 
2025-01-11 16:02:24.059001:  
2025-01-11 16:02:24.059062: Epoch 235 
2025-01-11 16:02:24.059099: Current learning rate: 0.00079 
2025-01-11 16:03:09.011328: train_loss -0.5404 
2025-01-11 16:03:09.011403: val_loss -0.5323 
2025-01-11 16:03:09.011443: Pseudo dice [0.8851, 0.8787, 0.8554, 0.8837, 0.8516, 0.8455] 
2025-01-11 16:03:09.011472: Epoch time: 44.95 s 
2025-01-11 16:03:09.486283:  
2025-01-11 16:03:09.486343: Epoch 236 
2025-01-11 16:03:09.486381: Current learning rate: 0.00075 
2025-01-11 16:03:54.671552: train_loss -0.524 
2025-01-11 16:03:54.671638: val_loss -0.5768 
2025-01-11 16:03:54.671679: Pseudo dice [0.8916, 0.8741, 0.8564, 0.8905, 0.8418, 0.8539] 
2025-01-11 16:03:54.671712: Epoch time: 45.19 s 
2025-01-11 16:03:55.148032:  
2025-01-11 16:03:55.148119: Epoch 237 
2025-01-11 16:03:55.148162: Current learning rate: 0.0007 
2025-01-11 16:04:40.136645: train_loss -0.5392 
2025-01-11 16:04:40.136717: val_loss -0.5577 
2025-01-11 16:04:40.136748: Pseudo dice [0.8848, 0.8777, 0.8733, 0.8789, 0.8692, 0.8343] 
2025-01-11 16:04:40.136772: Epoch time: 44.99 s 
2025-01-11 16:04:40.613199:  
2025-01-11 16:04:40.613266: Epoch 238 
2025-01-11 16:04:40.613308: Current learning rate: 0.00065 
2025-01-11 16:05:25.477285: train_loss -0.5265 
2025-01-11 16:05:25.477361: val_loss -0.5414 
2025-01-11 16:05:25.477395: Pseudo dice [0.9051, 0.8777, 0.8611, 0.8829, 0.8657, 0.8502] 
2025-01-11 16:05:25.477424: Epoch time: 44.86 s 
2025-01-11 16:05:25.953616:  
2025-01-11 16:05:25.953679: Epoch 239 
2025-01-11 16:05:25.953722: Current learning rate: 0.0006 
2025-01-11 16:06:10.965725: train_loss -0.5479 
2025-01-11 16:06:10.965803: val_loss -0.5452 
2025-01-11 16:06:10.965842: Pseudo dice [0.8682, 0.873, 0.8587, 0.8983, 0.844, 0.8636] 
2025-01-11 16:06:10.965872: Epoch time: 45.01 s 
2025-01-11 16:06:11.449785:  
2025-01-11 16:06:11.449833: Epoch 240 
2025-01-11 16:06:11.449871: Current learning rate: 0.00055 
2025-01-11 16:06:56.510187: train_loss -0.5388 
2025-01-11 16:06:56.510258: val_loss -0.5751 
2025-01-11 16:06:56.510290: Pseudo dice [0.8983, 0.876, 0.8598, 0.8777, 0.8658, 0.8361] 
2025-01-11 16:06:56.510314: Epoch time: 45.06 s 
2025-01-11 16:06:56.992431:  
2025-01-11 16:06:56.992517: Epoch 241 
2025-01-11 16:06:56.992578: Current learning rate: 0.0005 
2025-01-11 16:07:41.965027: train_loss -0.5322 
2025-01-11 16:07:41.965101: val_loss -0.5547 
2025-01-11 16:07:41.965133: Pseudo dice [0.8967, 0.8787, 0.8673, 0.89, 0.8613, 0.848] 
2025-01-11 16:07:41.965156: Epoch time: 44.97 s 
2025-01-11 16:07:41.965173: Yayy! New best EMA pseudo Dice: 0.8683 
2025-01-11 16:07:42.639020:  
2025-01-11 16:07:42.639072: Epoch 242 
2025-01-11 16:07:42.639115: Current learning rate: 0.00045 
2025-01-11 16:08:27.618596: train_loss -0.5458 
2025-01-11 16:08:27.618670: val_loss -0.5478 
2025-01-11 16:08:27.618703: Pseudo dice [0.9024, 0.8847, 0.8473, 0.889, 0.8457, 0.8333] 
2025-01-11 16:08:27.618728: Epoch time: 44.98 s 
2025-01-11 16:08:28.103496:  
2025-01-11 16:08:28.103567: Epoch 243 
2025-01-11 16:08:28.103616: Current learning rate: 0.0004 
2025-01-11 16:09:13.194098: train_loss -0.5379 
2025-01-11 16:09:13.194179: val_loss -0.5123 
2025-01-11 16:09:13.194213: Pseudo dice [0.8934, 0.8673, 0.8658, 0.8865, 0.8758, 0.8356] 
2025-01-11 16:09:13.194238: Epoch time: 45.09 s 
2025-01-11 16:09:13.194256: Yayy! New best EMA pseudo Dice: 0.8685 
2025-01-11 16:09:14.163330:  
2025-01-11 16:09:14.163428: Epoch 244 
2025-01-11 16:09:14.163481: Current learning rate: 0.00035 
2025-01-11 16:09:58.723334: train_loss -0.5349 
2025-01-11 16:09:58.723411: val_loss -0.5411 
2025-01-11 16:09:58.723444: Pseudo dice [0.8945, 0.8683, 0.8583, 0.8723, 0.8514, 0.8473] 
2025-01-11 16:09:58.723468: Epoch time: 44.56 s 
2025-01-11 16:09:59.210416:  
2025-01-11 16:09:59.210493: Epoch 245 
2025-01-11 16:09:59.210541: Current learning rate: 0.0003 
2025-01-11 16:10:43.701667: train_loss -0.5351 
2025-01-11 16:10:43.701744: val_loss -0.56 
2025-01-11 16:10:43.701786: Pseudo dice [0.9031, 0.8752, 0.856, 0.8953, 0.8618, 0.8553] 
2025-01-11 16:10:43.701816: Epoch time: 44.49 s 
2025-01-11 16:10:43.701836: Yayy! New best EMA pseudo Dice: 0.8688 
2025-01-11 16:10:44.377585:  
2025-01-11 16:10:44.377662: Epoch 246 
2025-01-11 16:10:44.377710: Current learning rate: 0.00024 
2025-01-11 16:11:29.502220: train_loss -0.531 
2025-01-11 16:11:29.502296: val_loss -0.5476 
2025-01-11 16:11:29.502328: Pseudo dice [0.8859, 0.875, 0.8679, 0.902, 0.8725, 0.8606] 
2025-01-11 16:11:29.502352: Epoch time: 45.13 s 
2025-01-11 16:11:29.502368: Yayy! New best EMA pseudo Dice: 0.8696 
2025-01-11 16:11:30.174917:  
2025-01-11 16:11:30.174988: Epoch 247 
2025-01-11 16:11:30.175029: Current learning rate: 0.00019 
2025-01-11 16:12:15.322110: train_loss -0.5552 
2025-01-11 16:12:15.322198: val_loss -0.5241 
2025-01-11 16:12:15.322231: Pseudo dice [0.8999, 0.874, 0.8429, 0.8817, 0.8445, 0.849] 
2025-01-11 16:12:15.322259: Epoch time: 45.15 s 
2025-01-11 16:12:15.809103:  
2025-01-11 16:12:15.809170: Epoch 248 
2025-01-11 16:12:15.809209: Current learning rate: 0.00013 
2025-01-11 16:13:00.831853: train_loss -0.5329 
2025-01-11 16:13:00.831931: val_loss -0.5481 
2025-01-11 16:13:00.831969: Pseudo dice [0.886, 0.8749, 0.8511, 0.8956, 0.8713, 0.8317] 
2025-01-11 16:13:00.831993: Epoch time: 45.02 s 
2025-01-11 16:13:01.317937:  
2025-01-11 16:13:01.318014: Epoch 249 
2025-01-11 16:13:01.318057: Current learning rate: 7e-05 
2025-01-11 16:13:46.342330: train_loss -0.5342 
2025-01-11 16:13:46.342413: val_loss -0.5502 
2025-01-11 16:13:46.342454: Pseudo dice [0.8933, 0.8759, 0.859, 0.886, 0.8527, 0.8521] 
2025-01-11 16:13:46.342504: Epoch time: 45.02 s 
2025-01-11 16:13:46.998712: Training done. 
2025-01-11 16:13:47.003392: Using splits from existing split file: /home/pycad/Documents/amine/code/spine-segmentation-nnunet/datasets/nnUNet_preprocessed/Dataset224_KNEE/splits_final.json 
2025-01-11 16:13:47.003555: The split file contains 5 splits. 
2025-01-11 16:13:47.003587: Desired fold for training: 0 
2025-01-11 16:13:47.003879: This split has 110 training and 28 validation cases. 
2025-01-11 16:13:47.004066: predicting KNEE_004 
2025-01-11 16:13:47.004860: KNEE_004, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:14:24.366809: predicting KNEE_013 
2025-01-11 16:14:24.368869: KNEE_013, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:14:52.506981: predicting KNEE_016 
2025-01-11 16:14:52.508841: KNEE_016, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:15:20.674198: predicting KNEE_017 
2025-01-11 16:15:20.676056: KNEE_017, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:15:49.427358: predicting KNEE_019 
2025-01-11 16:15:49.429003: KNEE_019, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:16:18.101515: predicting KNEE_024 
2025-01-11 16:16:18.103271: KNEE_024, shape torch.Size([1, 160, 576, 576]), rank 0 
2025-01-11 16:16:51.493515: predicting KNEE_025 
2025-01-11 16:16:51.495572: KNEE_025, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:17:20.135152: predicting KNEE_033 
2025-01-11 16:17:20.137345: KNEE_033, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:17:48.306679: predicting KNEE_039 
2025-01-11 16:17:48.308550: KNEE_039, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:18:16.472192: predicting KNEE_051 
2025-01-11 16:18:16.473875: KNEE_051, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:18:44.754931: predicting KNEE_052 
2025-01-11 16:18:44.756677: KNEE_052, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:19:14.770999: predicting KNEE_054 
2025-01-11 16:19:14.772786: KNEE_054, shape torch.Size([1, 160, 512, 498]), rank 0 
2025-01-11 16:19:44.616183: predicting KNEE_060 
2025-01-11 16:19:44.617909: KNEE_060, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:20:14.600178: predicting KNEE_068 
2025-01-11 16:20:14.602181: KNEE_068, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:20:44.664605: predicting KNEE_070 
2025-01-11 16:20:44.666410: KNEE_070, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:21:13.753218: predicting KNEE_078 
2025-01-11 16:21:13.755038: KNEE_078, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:21:42.876018: predicting KNEE_090 
2025-01-11 16:21:42.877772: KNEE_090, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:22:12.844438: predicting KNEE_092 
2025-01-11 16:22:12.846020: KNEE_092, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:22:43.254660: predicting KNEE_094 
2025-01-11 16:22:43.256608: KNEE_094, shape torch.Size([1, 160, 576, 576]), rank 0 
2025-01-11 16:23:15.705965: predicting KNEE_102 
2025-01-11 16:23:15.708222: KNEE_102, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:23:43.755760: predicting KNEE_104 
2025-01-11 16:23:43.757696: KNEE_104, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:24:11.558216: predicting KNEE_106 
2025-01-11 16:24:11.560699: KNEE_106, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:24:40.660719: predicting KNEE_108 
2025-01-11 16:24:40.662633: KNEE_108, shape torch.Size([1, 160, 512, 508]), rank 0 
2025-01-11 16:25:08.438110: predicting KNEE_109 
2025-01-11 16:25:08.439998: KNEE_109, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:25:37.022220: predicting KNEE_111 
2025-01-11 16:25:37.024167: KNEE_111, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:26:05.592156: predicting KNEE_115 
2025-01-11 16:26:05.594096: KNEE_115, shape torch.Size([1, 160, 512, 510]), rank 0 
2025-01-11 16:26:33.421857: predicting KNEE_117 
2025-01-11 16:26:33.423754: KNEE_117, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:27:01.316863: predicting KNEE_135 
2025-01-11 16:27:01.318816: KNEE_135, shape torch.Size([1, 160, 512, 512]), rank 0 
2025-01-11 16:27:38.823100: Validation complete 
2025-01-11 16:27:38.823143: Mean Validation Dice:  0.8669610787329606 
